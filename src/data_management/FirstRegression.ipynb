{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Regression (Turnover intention ~ unfair treatment x neg. reciprocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Read in SOEP Data:\n",
    "- vp : 2005 data : main variables of interest: questions on negative reciprocity\n",
    "- wp: 2006 data : main variables of interest: question on perceived recognition for work\n",
    "- xp: 2007 data : main variables of interest: turnover intentions, controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"/Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>syear</th>\n",
       "      <th>take_revenge</th>\n",
       "      <th>similar_problems</th>\n",
       "      <th>insult_back</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th>hid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <th>27</th>\n",
       "      <td>2005</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <th>60313</th>\n",
       "      <td>2005</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <th>60</th>\n",
       "      <td>2005</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[4] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           syear                    take_revenge similar_problems  \\\n",
       "pid hid                                                             \n",
       "201 27      2005  [1] Trifft ueberhaupt nicht zu    [5] Skala 1-7   \n",
       "203 60313   2005                   [2] Skala 1-7    [3] Skala 1-7   \n",
       "602 60      2005                   [5] Skala 1-7    [4] Skala 1-7   \n",
       "\n",
       "                              insult_back  rec1  rec2  rec3  rec4  rec5  rec6  \\\n",
       "pid hid                                                                         \n",
       "201 27     [1] Trifft ueberhaupt nicht zu     0     0     0     0     1     0   \n",
       "203 60313                   [2] Skala 1-7     0     0     1     0     0     0   \n",
       "602 60                      [3] Skala 1-7     0     0     0     1     0     0   \n",
       "\n",
       "           rec7  \n",
       "pid hid          \n",
       "201 27        0  \n",
       "203 60313     0  \n",
       "602 60        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\", \"syear\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_2005 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})\n",
    "# create dummies for take_revenge question\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(df_2005['similar_problems'])\n",
    "\n",
    "# Join the dummy variables to the original dataframe\n",
    "df_2005 = pd.concat([df_2005, dummies], axis=1)\n",
    "# rename dummy\n",
    "df_05 = df_2005.rename(columns = {'[1] Trifft ueberhaupt nicht zu' : 'rec1' , '[2] Skala 1-7' : 'rec2' , '[3] Skala 1-7' : 'rec3' ,'[4] Skala 1-7' : 'rec4' ,'[5] Skala 1-7' : 'rec5' ,'[6] Skala 1-7' : 'rec6' ,'[7] Trifft voll zu' : 'rec7'})\n",
    "df_05 = df_05.drop(columns = [\"[-1] keine Angabe\"])\n",
    "df_05.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", \"syear\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08' ]).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2007 data\n",
    "# here left out 'xp8601' for school degree since we have it in another module also 'xp0102' : 'work_satisfaction' for the beginning\n",
    "#for outcome and all controls\n",
    "data3= pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\", \"syear\", 'xp13101' , 'xp13102', 'xp2701', 'xp7302','xp7202','xp28', 'xp3001' ,  'xp5701' , 'xp0102']).set_index(['pid', 'hid'])\n",
    "df_07 = data3.rename(columns= {'xp13101':'gender','xp13102': 'year_birth' ,'xp2701': 'turnover_intention' , 'xp7302': 'wage_lastmonth','xp7202': 'overtime','xp28': 'new_job', 'xp3001': 'reason_new_job',  'xp5701' : 'commute_distance' , \"xp0102\" : \"work_satisfaction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2007 data from work module\n",
    "\n",
    "# adapt path and merge\n",
    "hours07 = pd.read_stata(file_paths_2[2], columns=[\"pid\",\"hid\", \"syear\", \"xvebzeit\", \"xpsbil\", \"betr07\", \"xerwzeit\", \"xbilzeit\"]).set_index(['pid', 'hid'])\n",
    "work07 = hours07.rename(columns={'xvebzeit': 'working_hours', \"xpsbil\": \"school_degree\", \"betr07\": \"firmsize\", \"xerwzeit\": \"tenure\" , \"xbilzeit\" : \"years_educ\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Define Functions and mappings for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbststÃ¤ndig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for turnover intention: split up into binary with roughly equal value counts for simplicity: might change that later to categories\n",
    "satisfaction_mapping = {\n",
    "    '[0] 0 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[1] 1 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[2] 2 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[3] 3 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[4] 4 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[5] 5 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[6] 6 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[7] 7 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[8] 8 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[9] 9 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[10] 10 Zufrieden: Skala 0-Niedrig bis 10-Hoc': 1,\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention robustness check: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "# mapping for binary reciprocity measure\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 2:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group\n",
    "\n",
    "## function for recoding values and dropping missing\n",
    "\n",
    "def recode_categoricals(inputdf,rc_cardinal = 0):\n",
    "    \"\"\"\n",
    "        merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode job satisfaction\n",
    "    merged['work_satisfaction']= merged['work_satisfaction'].map(satisfaction_mapping)\n",
    "    # recode turnover intention variable\n",
    "    if rc_cardinal == 1:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping_cardinal)\n",
    "    else:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping)\n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output\n",
    "\n",
    "# Merge dataframes: a bit tough to read as its nested, merges 4 dataframes: 2005,2006,2007 and 2007gen\n",
    "\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df,rc_cardinal).astype('int')\n",
    "\n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan) \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    \n",
    "    recoded[\"tenure_squared\"] = (recoded[\"tenure\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"turnover_intention\", \"new_job\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add Mincer Wage Regression and adds its residuals to the Dataframe\n",
    "\n",
    "def add_mincer_residuals(cleaneddata):\n",
    "    \n",
    "    df_cleaned = cleaneddata\n",
    "    # specify which columns to drop from our dataframe\n",
    "    df_mincer = cleaneddata.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup', 'commute_distance', 'recog_effort', 'working_hours', 'age', 'turnover_intention', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "    # Convert 'gender' and 'sector' columns to categorical data type\n",
    "    for col in ['gender']:\n",
    "        df_mincer[col] = df_mincer[col].astype('category')\n",
    "    df_mincer = df_mincer.dropna()\n",
    "    # Define the dependent variable\n",
    "    y = df_mincer['wage_lastmonth']\n",
    "    # Define the independent variables\n",
    "    X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "    # Add a constant term to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the Mincer wage regression model\n",
    "    mincer_model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Create a new column in the dataframe with the same name as the residuals array/ delete relative wage entries\n",
    "    df_cleaned['mincer_residuals'] = None\n",
    "    # Match the rows of the dataframe with the values in the residuals array using the index\n",
    "    df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlcude People who switched their jobs in 2006-2007 with 2006 controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_jobchangers(data07,onlynewemployer=False,worksatisfaction=False,rc_cardinal = False):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "            df: finished 2007 dataframe\n",
    "            onlynewemployer: optional argument: If True only includes those who switched jobs to a new employer\n",
    "            worksatisfaction: if True drops observations where job satisfaction between 2006 and 2007 changed to check for our Assumption\n",
    "    \n",
    "    \"\"\"\n",
    "    df = data07\n",
    "    # read in cleaned 2006 dataset:\n",
    "    #  change path here : Maxie: '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv'\n",
    "    #                     Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv'  \n",
    "    observations_2006 = pd.read_csv('/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv')\n",
    "    # some initial datamanagement\n",
    "    observations_2006.reset_index(inplace=True)\n",
    "    observations_2006.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "    observations_2006.drop(columns=observations_2006.filter(regex='^syear').columns, inplace=True)\n",
    "    observations_2006.drop(\"index\",axis=1 ,inplace =True)\n",
    "    # If cardinal turnover intentions are coded to 100\n",
    "    if rc_cardinal == True:\n",
    "        observations_2006[\"turnover_intention\"] = 100\n",
    "    # drop s year columns from both dataframes\n",
    "    df.drop(columns=df.filter(regex='^syear').columns, inplace=True)\n",
    "    \n",
    "    # optional worksatisfaction robustness check\n",
    "    if worksatisfaction == True:\n",
    "        satisfaction = pd.DataFrame(df['work_satisfaction']).join(pd.DataFrame(observations_2006['work_satisfaction']), on = [\"pid\", \"hid\"], lsuffix = \"_07\" , rsuffix =\"_06\")\n",
    "        ID_keep_satis = satisfaction[satisfaction[\"work_satisfaction_07\"] == satisfaction[\"work_satisfaction_06\"]].index\n",
    "        df.drop(df[~df.index.isin(ID_keep_satis)].index, inplace=True)\n",
    "    \n",
    "    # create list of IDs of people who switched to a new employer in the last year in 2007\n",
    "    if onlynewemployer == True:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1) & (df[\"reason_new_job\"] == '[3] Stelle bei neuen Arbeitgeber')].index\n",
    "    # if True drops people whose work satisfaction changed between 2006 and 2007\n",
    "    else:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1)].index\n",
    "    \n",
    "    # drop all who changed their job in 2007 dataframe and replace 2007 controls with 2006 controls\n",
    "    df.drop(df[df[\"new_job\"] == 1].index, inplace = True)\n",
    "    observations_2006.drop(observations_2006[~observations_2006.index.isin(IDs_tokeep)].index, inplace=True)\n",
    "    #concat both dataframes\n",
    "    dfconcat = pd.concat([df,observations_2006])\n",
    "    \n",
    "    return dfconcat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis\n",
    "#### 1.Probit Regression\n",
    "\n",
    "- Probit Estimation: TurnoverIntention_{2005} = Constant + Neg-Rec + Unfair + Rec X Unfair + Controls + Error\n",
    "\n",
    "- As the measure for unfair treatment in the first regression i first used recog_effort -> decide for one later\n",
    "    - \"When I consider all my accomplishments and efforts, the recognition of I've received seems about right to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    }
   ],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS = df_OLS.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "df_OLS[\"recXrecog_effort\"] = df_OLS[\"recog_effort\"] * df_OLS[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_OLS.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592118\n",
      "         Iterations 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>turnover_intention</td> <th>  No. Observations:  </th>   <td>  5407</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Probit</td>       <th>  Df Residuals:      </th>   <td>  5392</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>   <td>    14</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Jan 2023</td>  <th>  Pseudo R-squ.:     </th>   <td>0.1454</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:59:44</td>      <th>  Log-Likelihood:    </th>  <td> -3201.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th>  <td> -3746.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.084e-223</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   -0.0594</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.5180</td> <td>    0.093</td> <td>    5.580</td> <td> 0.000</td> <td>    0.336</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0020</td> <td>    0.003</td> <td>   -0.784</td> <td> 0.433</td> <td>   -0.007</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0342</td> <td>    0.007</td> <td>   -5.192</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0421</td> <td>    0.007</td> <td>   -5.949</td> <td> 0.000</td> <td>   -0.056</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0589</td> <td>    0.007</td> <td>    8.496</td> <td> 0.000</td> <td>    0.045</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.1470</td> <td>    0.043</td> <td>    3.390</td> <td> 0.001</td> <td>    0.062</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0012</td> <td>    0.000</td> <td>    2.841</td> <td> 0.005</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0745</td> <td>    0.016</td> <td>    4.522</td> <td> 0.000</td> <td>    0.042</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>   -0.0392</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0030</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.1784</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0472</td> <td>    0.020</td> <td>    2.390</td> <td> 0.017</td> <td>    0.008</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-4.209e-05</td> <td> 2.81e-05</td> <td>   -1.500</td> <td> 0.134</td> <td>-9.71e-05</td> <td> 1.29e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0586</td> <td>    0.027</td> <td>   -2.193</td> <td> 0.028</td> <td>   -0.111</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   No. Observations:                 5407\n",
       "Model:                         Probit   Df Residuals:                     5392\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Mon, 09 Jan 2023   Pseudo R-squ.:                  0.1454\n",
       "Time:                        17:59:44   Log-Likelihood:                -3201.6\n",
       "converged:                       True   LL-Null:                       -3746.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.084e-223\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   -0.0594        nan        nan        nan         nan         nan\n",
       "recog_effort             0.5180      0.093      5.580      0.000       0.336       0.700\n",
       "working_hours           -0.0020      0.003     -0.784      0.433      -0.007       0.003\n",
       "firmsize                -0.0342      0.007     -5.192      0.000      -0.047      -0.021\n",
       "tenure                  -0.0421      0.007     -5.949      0.000      -0.056      -0.028\n",
       "years_educ               0.0589      0.007      8.496      0.000       0.045       0.072\n",
       "gender                   0.1470      0.043      3.390      0.001       0.062       0.232\n",
       "commute_distance         0.0012      0.000      2.841      0.005       0.000       0.002\n",
       "avg_rec                  0.0745      0.016      4.522      0.000       0.042       0.107\n",
       "age                     -0.0392        nan        nan        nan         nan         nan\n",
       "potential_experience    -0.0030        nan        nan        nan         nan         nan\n",
       "age_squared              0.1784        nan        nan        nan         nan         nan\n",
       "tenure_squared           0.0472      0.020      2.390      0.017       0.008       0.086\n",
       "mincer_residuals     -4.209e-05   2.81e-05     -1.500      0.134   -9.71e-05    1.29e-05\n",
       "recXrecog_effort        -0.0586      0.027     -2.193      0.028      -0.111      -0.006\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit\n",
    "# Define Outcome variable\n",
    "Y = df_OLS[\"turnover_intention\"]\n",
    "# define X matrix\n",
    "X = df_OLS.drop(columns=[\"turnover_intention\"])\n",
    "# add constant \n",
    "X = sm.add_constant(X)\n",
    "# build model\n",
    "model = Probit(Y, X.astype(float))\n",
    "# estimate model\n",
    "probit_model = model.fit()\n",
    "# print summary table\n",
    "probit_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. OLS\n",
    "Now, instead of using a probit model, we use OLS.  linear probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   539.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:01:23</td>      <th>  Log-Likelihood:    </th> <td> -3376.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6782.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5393</td>       <th>  BIC:               </th> <td>   6874.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0383</td> <td>    0.008</td> <td>    4.942</td> <td> 0.000</td> <td>    0.023</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1736</td> <td>    0.031</td> <td>    5.597</td> <td> 0.000</td> <td>    0.113</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0009</td> <td>    0.001</td> <td>   -1.064</td> <td> 0.288</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0115</td> <td>    0.002</td> <td>   -5.097</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0160</td> <td>    0.002</td> <td>   -7.182</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0203</td> <td>    0.002</td> <td>    9.139</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0519</td> <td>    0.015</td> <td>    3.569</td> <td> 0.000</td> <td>    0.023</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.026</td> <td> 0.002</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0248</td> <td>    0.006</td> <td>    4.472</td> <td> 0.000</td> <td>    0.014</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0445</td> <td>    0.006</td> <td>    7.073</td> <td> 0.000</td> <td>    0.032</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0007</td> <td>    0.000</td> <td>    2.705</td> <td> 0.007</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1081</td> <td>    0.023</td> <td>   -4.721</td> <td> 0.000</td> <td>   -0.153</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0208</td> <td>    0.006</td> <td>    3.763</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.234e-05</td> <td> 9.32e-06</td> <td>   -1.324</td> <td> 0.185</td> <td>-3.06e-05</td> <td> 5.92e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0188</td> <td>    0.009</td> <td>   -2.091</td> <td> 0.037</td> <td>   -0.036</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>93366.838</td> <th>  Durbin-Watson:     </th> <td>   1.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 401.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.035</td>   <th>  Prob(JB):          </th> <td>5.93e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.667</td>   <th>  Cond. No.          </th> <td>1.91e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.183\n",
       "Model:                            OLS   Adj. R-squared:                  0.181\n",
       "Method:                 Least Squares   F-statistic:                     539.1\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:01:23   Log-Likelihood:                -3376.8\n",
       "No. Observations:                5407   AIC:                             6782.\n",
       "Df Residuals:                    5393   BIC:                             6874.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0383      0.008      4.942      0.000       0.023       0.054\n",
       "recog_effort             0.1736      0.031      5.597      0.000       0.113       0.234\n",
       "working_hours           -0.0009      0.001     -1.064      0.288      -0.003       0.001\n",
       "firmsize                -0.0115      0.002     -5.097      0.000      -0.016      -0.007\n",
       "tenure                  -0.0160      0.002     -7.182      0.000      -0.020      -0.012\n",
       "years_educ               0.0203      0.002      9.139      0.000       0.016       0.025\n",
       "gender                   0.0519      0.015      3.569      0.000       0.023       0.080\n",
       "commute_distance         0.0004      0.000      3.026      0.002       0.000       0.001\n",
       "avg_rec                  0.0248      0.006      4.472      0.000       0.014       0.036\n",
       "age                      0.0445      0.006      7.073      0.000       0.032       0.057\n",
       "potential_experience     0.0007      0.000      2.705      0.007       0.000       0.001\n",
       "age_squared             -0.1081      0.023     -4.721      0.000      -0.153      -0.063\n",
       "tenure_squared           0.0208      0.006      3.763      0.000       0.010       0.032\n",
       "mincer_residuals     -1.234e-05   9.32e-06     -1.324      0.185   -3.06e-05    5.92e-06\n",
       "recXrecog_effort        -0.0188      0.009     -2.091      0.037      -0.036      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                    93366.838   Durbin-Watson:                   1.836\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              401.695\n",
       "Skew:                          -0.035   Prob(JB):                     5.93e-88\n",
       "Kurtosis:                       1.667   Cond. No.                     1.91e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Checks\n",
    "\n",
    "\n",
    "#### 1. Recode turnover variable into cardinal variable: Optional argument in recode_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.199</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.198</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   251.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:02:36</td>      <th>  Log-Likelihood:    </th> <td> -25233.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>5.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5393</td>       <th>  BIC:               </th> <td>5.059e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    5.2245</td> <td>    0.565</td> <td>    9.246</td> <td> 0.000</td> <td>    4.117</td> <td>    6.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    9.0918</td> <td>    1.814</td> <td>    5.013</td> <td> 0.000</td> <td>    5.537</td> <td>   12.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.1266</td> <td>    0.053</td> <td>   -2.400</td> <td> 0.016</td> <td>   -0.230</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.3369</td> <td>    0.134</td> <td>   -2.523</td> <td> 0.012</td> <td>   -0.599</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -1.5232</td> <td>    0.129</td> <td>  -11.784</td> <td> 0.000</td> <td>   -1.777</td> <td>   -1.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.9726</td> <td>    0.127</td> <td>    7.648</td> <td> 0.000</td> <td>    0.723</td> <td>    1.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    2.7628</td> <td>    0.839</td> <td>    3.291</td> <td> 0.001</td> <td>    1.118</td> <td>    4.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0262</td> <td>    0.009</td> <td>    3.071</td> <td> 0.002</td> <td>    0.009</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.8241</td> <td>    0.306</td> <td>    2.691</td> <td> 0.007</td> <td>    0.224</td> <td>    1.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    4.6960</td> <td>    0.444</td> <td>   10.569</td> <td> 0.000</td> <td>    3.825</td> <td>    5.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.1530</td> <td>    0.019</td> <td>    7.847</td> <td> 0.000</td> <td>    0.115</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>  -15.2354</td> <td>    1.673</td> <td>   -9.106</td> <td> 0.000</td> <td>  -18.514</td> <td>  -11.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    2.7897</td> <td>    0.301</td> <td>    9.258</td> <td> 0.000</td> <td>    2.199</td> <td>    3.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0011</td> <td>    0.001</td> <td>   -2.099</td> <td> 0.036</td> <td>   -0.002</td> <td>-7.15e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.4527</td> <td>    0.530</td> <td>   -0.854</td> <td> 0.393</td> <td>   -1.491</td> <td>    0.586</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>881.074</td> <th>  Durbin-Watson:     </th> <td>   1.918</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1404.202</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.124</td>  <th>  Prob(JB):          </th> <td>1.21e-305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.088</td>  <th>  Cond. No.          </th> <td>1.91e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.199\n",
       "Model:                            OLS   Adj. R-squared:                  0.198\n",
       "Method:                 Least Squares   F-statistic:                     251.8\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:02:36   Log-Likelihood:                -25233.\n",
       "No. Observations:                5407   AIC:                         5.049e+04\n",
       "Df Residuals:                    5393   BIC:                         5.059e+04\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    5.2245      0.565      9.246      0.000       4.117       6.332\n",
       "recog_effort             9.0918      1.814      5.013      0.000       5.537      12.647\n",
       "working_hours           -0.1266      0.053     -2.400      0.016      -0.230      -0.023\n",
       "firmsize                -0.3369      0.134     -2.523      0.012      -0.599      -0.075\n",
       "tenure                  -1.5232      0.129    -11.784      0.000      -1.777      -1.270\n",
       "years_educ               0.9726      0.127      7.648      0.000       0.723       1.222\n",
       "gender                   2.7628      0.839      3.291      0.001       1.118       4.408\n",
       "commute_distance         0.0262      0.009      3.071      0.002       0.009       0.043\n",
       "avg_rec                  0.8241      0.306      2.691      0.007       0.224       1.424\n",
       "age                      4.6960      0.444     10.569      0.000       3.825       5.567\n",
       "potential_experience     0.1530      0.019      7.847      0.000       0.115       0.191\n",
       "age_squared            -15.2354      1.673     -9.106      0.000     -18.514     -11.956\n",
       "tenure_squared           2.7897      0.301      9.258      0.000       2.199       3.380\n",
       "mincer_residuals        -0.0011      0.001     -2.099      0.036      -0.002   -7.15e-05\n",
       "recXrecog_effort        -0.4527      0.530     -0.854      0.393      -1.491       0.586\n",
       "==============================================================================\n",
       "Omnibus:                      881.074   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1404.202\n",
       "Skew:                           1.124   Prob(JB):                    1.21e-305\n",
       "Kurtosis:                       4.088   Cond. No.                     1.91e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional argument ==1\n",
    "dfrc1 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal=1)),rc_cardinal=True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_cardinal = dfrc1.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth','rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "dfrc_cardinal[\"recXrecog_effort\"] = dfrc_cardinal[\"recog_effort\"] * dfrc_cardinal[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_cardinal = dfrc_cardinal.dropna()\n",
    "\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_cardinal[\"turnover_intention\"]\n",
    "X = dfrc_cardinal.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not change much. Coefficient on the interaction term becomes insignificant.\n",
    "\n",
    "#### 2. Different Reciprocity Specifications\n",
    "\n",
    "    1. Split into binary: High/ Low reciprocal\n",
    "    2. create dummies for each category and estimate regression for those\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   545.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:04:42</td>      <th>  Log-Likelihood:    </th> <td> -3360.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6750.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5393</td>       <th>  BIC:               </th> <td>   6842.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>    0.0357</td> <td>    0.008</td> <td>    4.677</td> <td> 0.000</td> <td>    0.021</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>           <td>    0.1363</td> <td>    0.030</td> <td>    4.487</td> <td> 0.000</td> <td>    0.077</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>          <td>   -0.0009</td> <td>    0.001</td> <td>   -1.086</td> <td> 0.277</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>               <td>   -0.0116</td> <td>    0.002</td> <td>   -5.161</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>                 <td>   -0.0160</td> <td>    0.002</td> <td>   -7.230</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>             <td>    0.0195</td> <td>    0.002</td> <td>    8.893</td> <td> 0.000</td> <td>    0.015</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                 <td>    0.0497</td> <td>    0.014</td> <td>    3.451</td> <td> 0.001</td> <td>    0.021</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>       <td>    0.0004</td> <td>    0.000</td> <td>    2.990</td> <td> 0.003</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>             <td>    0.1256</td> <td>    0.019</td> <td>    6.442</td> <td> 0.000</td> <td>    0.087</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                    <td>    0.0422</td> <td>    0.006</td> <td>    6.848</td> <td> 0.000</td> <td>    0.030</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th>   <td>    0.0006</td> <td>    0.000</td> <td>    2.435</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>            <td>   -0.1006</td> <td>    0.023</td> <td>   -4.454</td> <td> 0.000</td> <td>   -0.145</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>         <td>    0.0208</td> <td>    0.006</td> <td>    3.752</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>       <td>-1.281e-05</td> <td> 9.18e-06</td> <td>   -1.395</td> <td> 0.163</td> <td>-3.08e-05</td> <td> 5.19e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binaryrecXrecog_effort</th> <td>   -0.0286</td> <td>    0.033</td> <td>   -0.858</td> <td> 0.391</td> <td>   -0.094</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>29610.657</td> <th>  Durbin-Watson:     </th> <td>   1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 391.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.038</td>   <th>  Prob(JB):          </th> <td>1.00e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.684</td>   <th>  Cond. No.          </th> <td>1.91e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.36e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.188\n",
       "Model:                            OLS   Adj. R-squared:                  0.186\n",
       "Method:                 Least Squares   F-statistic:                     545.1\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:04:42   Log-Likelihood:                -3360.9\n",
       "No. Observations:                5407   AIC:                             6750.\n",
       "Df Residuals:                    5393   BIC:                             6842.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                      0.0357      0.008      4.677      0.000       0.021       0.051\n",
       "recog_effort               0.1363      0.030      4.487      0.000       0.077       0.196\n",
       "working_hours             -0.0009      0.001     -1.086      0.277      -0.003       0.001\n",
       "firmsize                  -0.0116      0.002     -5.161      0.000      -0.016      -0.007\n",
       "tenure                    -0.0160      0.002     -7.230      0.000      -0.020      -0.012\n",
       "years_educ                 0.0195      0.002      8.893      0.000       0.015       0.024\n",
       "gender                     0.0497      0.014      3.451      0.001       0.021       0.078\n",
       "commute_distance           0.0004      0.000      2.990      0.003       0.000       0.001\n",
       "binary_rec                 0.1256      0.019      6.442      0.000       0.087       0.164\n",
       "age                        0.0422      0.006      6.848      0.000       0.030       0.054\n",
       "potential_experience       0.0006      0.000      2.435      0.015       0.000       0.001\n",
       "age_squared               -0.1006      0.023     -4.454      0.000      -0.145      -0.056\n",
       "tenure_squared             0.0208      0.006      3.752      0.000       0.010       0.032\n",
       "mincer_residuals       -1.281e-05   9.18e-06     -1.395      0.163   -3.08e-05    5.19e-06\n",
       "binaryrecXrecog_effort    -0.0286      0.033     -0.858      0.391      -0.094       0.037\n",
       "==============================================================================\n",
       "Omnibus:                    29610.657   Durbin-Watson:                   1.837\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              391.440\n",
       "Skew:                          -0.038   Prob(JB):                     1.00e-85\n",
       "Kurtosis:                       1.684   Cond. No.                     1.91e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.36e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1 . Split up from when average bigger than 3\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_binary = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth','avg_rec', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "# add interaction term\n",
    "dfrc_binary[\"binaryrecXrecog_effort\"] = dfrc_binary[\"recog_effort\"] * dfrc_binary[\"binary_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_binary = dfrc_binary.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_binary[\"turnover_intention\"]\n",
    "X = dfrc_binary.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### also does not change a lot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating dummies and include 7 interaction terms : Decide for one of the 3 questions for simplicity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When treating the categories as numerical: we are making assumptions about the differences between the scale items. If those distances can be considered equal at all levels, then it is reasonable to treat reciprocity as numerical. (i.e a one unit change from 1 to 2 is equivalent to a one unit change from 6 to 7)\n",
    "\n",
    "\n",
    "For dummy coding we need to exclude one of the categories in the dataframe and make it the reference category: This will be the lowest level of reciprocity 1 and will be coded as zero.  so rec2 rec3 rec4 , ... and their interaction terms with unfair treatment stay in the regression.\n",
    "\n",
    "rec2 is then interpreted as the mean of turnover intentions in the rec2 group - the mean of turnover intentions in the rec1 group (reference group) holding everything else constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   321.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:07:48</td>      <th>  Log-Likelihood:    </th> <td> -3339.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6728.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5383</td>       <th>  BIC:               </th> <td>   6886.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    23</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0376</td> <td>    0.008</td> <td>    4.993</td> <td> 0.000</td> <td>    0.023</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2</th>                 <td>    0.1519</td> <td>    0.022</td> <td>    6.938</td> <td> 0.000</td> <td>    0.109</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3</th>                 <td>    0.1482</td> <td>    0.024</td> <td>    6.140</td> <td> 0.000</td> <td>    0.101</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4</th>                 <td>    0.1223</td> <td>    0.026</td> <td>    4.790</td> <td> 0.000</td> <td>    0.072</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5</th>                 <td>    0.1637</td> <td>    0.030</td> <td>    5.374</td> <td> 0.000</td> <td>    0.104</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6</th>                 <td>    0.1758</td> <td>    0.046</td> <td>    3.818</td> <td> 0.000</td> <td>    0.086</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7</th>                 <td>    0.0484</td> <td>    0.045</td> <td>    1.067</td> <td> 0.286</td> <td>   -0.041</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1508</td> <td>    0.027</td> <td>    5.590</td> <td> 0.000</td> <td>    0.098</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0010</td> <td>    0.001</td> <td>   -1.146</td> <td> 0.252</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0118</td> <td>    0.002</td> <td>   -5.256</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0160</td> <td>    0.002</td> <td>   -7.223</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0183</td> <td>    0.002</td> <td>    8.251</td> <td> 0.000</td> <td>    0.014</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0484</td> <td>    0.014</td> <td>    3.353</td> <td> 0.001</td> <td>    0.020</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.314</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0438</td> <td>    0.006</td> <td>    7.239</td> <td> 0.000</td> <td>    0.032</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0007</td> <td>    0.000</td> <td>    2.701</td> <td> 0.007</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1062</td> <td>    0.022</td> <td>   -4.763</td> <td> 0.000</td> <td>   -0.150</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0205</td> <td>    0.006</td> <td>    3.709</td> <td> 0.000</td> <td>    0.010</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td> -1.33e-05</td> <td> 9.26e-06</td> <td>   -1.436</td> <td> 0.151</td> <td>-3.14e-05</td> <td> 4.85e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2_X_recog_effort</th>  <td>   -0.0471</td> <td>    0.037</td> <td>   -1.280</td> <td> 0.200</td> <td>   -0.119</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3_X_recog_effort</th>  <td>   -0.0015</td> <td>    0.039</td> <td>   -0.038</td> <td> 0.969</td> <td>   -0.077</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4_X_recog_effort</th>  <td>   -0.0790</td> <td>    0.041</td> <td>   -1.906</td> <td> 0.057</td> <td>   -0.160</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5_X_recog_effort</th>  <td>   -0.0853</td> <td>    0.052</td> <td>   -1.654</td> <td> 0.098</td> <td>   -0.186</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6_X_recog_effort</th>  <td>   -0.0735</td> <td>    0.071</td> <td>   -1.029</td> <td> 0.304</td> <td>   -0.213</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7_X_recog_effort</th>  <td>   -0.0379</td> <td>    0.074</td> <td>   -0.515</td> <td> 0.606</td> <td>   -0.182</td> <td>    0.106</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18716.431</td> <th>  Durbin-Watson:     </th> <td>   1.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 383.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.044</td>   <th>  Prob(JB):          </th> <td>6.61e-84</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.699</td>   <th>  Cond. No.          </th> <td>1.89e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.39e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.194\n",
       "Model:                            OLS   Adj. R-squared:                  0.190\n",
       "Method:                 Least Squares   F-statistic:                     321.1\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:07:48   Log-Likelihood:                -3339.9\n",
       "No. Observations:                5407   AIC:                             6728.\n",
       "Df Residuals:                    5383   BIC:                             6886.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0376      0.008      4.993      0.000       0.023       0.052\n",
       "rec2                     0.1519      0.022      6.938      0.000       0.109       0.195\n",
       "rec3                     0.1482      0.024      6.140      0.000       0.101       0.196\n",
       "rec4                     0.1223      0.026      4.790      0.000       0.072       0.172\n",
       "rec5                     0.1637      0.030      5.374      0.000       0.104       0.223\n",
       "rec6                     0.1758      0.046      3.818      0.000       0.086       0.266\n",
       "rec7                     0.0484      0.045      1.067      0.286      -0.041       0.137\n",
       "recog_effort             0.1508      0.027      5.590      0.000       0.098       0.204\n",
       "working_hours           -0.0010      0.001     -1.146      0.252      -0.003       0.001\n",
       "firmsize                -0.0118      0.002     -5.256      0.000      -0.016      -0.007\n",
       "tenure                  -0.0160      0.002     -7.223      0.000      -0.020      -0.012\n",
       "years_educ               0.0183      0.002      8.251      0.000       0.014       0.023\n",
       "gender                   0.0484      0.014      3.353      0.001       0.020       0.077\n",
       "commute_distance         0.0004      0.000      3.314      0.001       0.000       0.001\n",
       "age                      0.0438      0.006      7.239      0.000       0.032       0.056\n",
       "potential_experience     0.0007      0.000      2.701      0.007       0.000       0.001\n",
       "age_squared             -0.1062      0.022     -4.763      0.000      -0.150      -0.062\n",
       "tenure_squared           0.0205      0.006      3.709      0.000       0.010       0.031\n",
       "mincer_residuals      -1.33e-05   9.26e-06     -1.436      0.151   -3.14e-05    4.85e-06\n",
       "rec2_X_recog_effort     -0.0471      0.037     -1.280      0.200      -0.119       0.025\n",
       "rec3_X_recog_effort     -0.0015      0.039     -0.038      0.969      -0.077       0.074\n",
       "rec4_X_recog_effort     -0.0790      0.041     -1.906      0.057      -0.160       0.002\n",
       "rec5_X_recog_effort     -0.0853      0.052     -1.654      0.098      -0.186       0.016\n",
       "rec6_X_recog_effort     -0.0735      0.071     -1.029      0.304      -0.213       0.067\n",
       "rec7_X_recog_effort     -0.0379      0.074     -0.515      0.606      -0.182       0.106\n",
       "==============================================================================\n",
       "Omnibus:                    18716.431   Durbin-Watson:                   1.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              383.056\n",
       "Skew:                          -0.044   Prob(JB):                     6.61e-84\n",
       "Kurtosis:                       1.699   Cond. No.                     1.89e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.39e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_dummy = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay','year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'avg_rec','rec1', 'work_satisfaction'])\n",
    "# add interaction terms\n",
    "for col in ['rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7']:\n",
    "    dfrc_dummy = dfrc_dummy.assign(**{col + '_X_recog_effort': dfrc_dummy[col] * dfrc_dummy['recog_effort']})\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_dummy = dfrc_dummy.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_dummy[\"turnover_intention\"]\n",
    "X = dfrc_dummy.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness Check : Drop people whose job satisfaction level changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   391.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:08:02</td>      <th>  Log-Likelihood:    </th> <td> -2739.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  4346</td>       <th>  AIC:               </th> <td>   5508.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  4332</td>       <th>  BIC:               </th> <td>   5597.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0373</td> <td>    0.009</td> <td>    4.241</td> <td> 0.000</td> <td>    0.020</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.2054</td> <td>    0.035</td> <td>    5.795</td> <td> 0.000</td> <td>    0.136</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0008</td> <td>    0.001</td> <td>   -0.784</td> <td> 0.433</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0109</td> <td>    0.003</td> <td>   -4.305</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0148</td> <td>    0.003</td> <td>   -5.911</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0211</td> <td>    0.002</td> <td>    8.548</td> <td> 0.000</td> <td>    0.016</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0485</td> <td>    0.016</td> <td>    2.964</td> <td> 0.003</td> <td>    0.016</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    2.332</td> <td> 0.020</td> <td> 5.64e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0261</td> <td>    0.006</td> <td>    4.264</td> <td> 0.000</td> <td>    0.014</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0420</td> <td>    0.007</td> <td>    5.889</td> <td> 0.000</td> <td>    0.028</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0007</td> <td>    0.000</td> <td>    2.430</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1058</td> <td>    0.026</td> <td>   -4.069</td> <td> 0.000</td> <td>   -0.157</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0200</td> <td>    0.006</td> <td>    3.234</td> <td> 0.001</td> <td>    0.008</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-7.171e-06</td> <td> 1.07e-05</td> <td>   -0.669</td> <td> 0.504</td> <td>-2.82e-05</td> <td> 1.38e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0252</td> <td>    0.010</td> <td>   -2.436</td> <td> 0.015</td> <td>   -0.045</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>55777.257</td> <th>  Durbin-Watson:     </th> <td>   1.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 344.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.035</td>   <th>  Prob(JB):          </th> <td>1.94e-75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.623</td>   <th>  Cond. No.          </th> <td>3.56e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 3.09e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.171\n",
       "Model:                            OLS   Adj. R-squared:                  0.168\n",
       "Method:                 Least Squares   F-statistic:                     391.9\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:08:02   Log-Likelihood:                -2739.8\n",
       "No. Observations:                4346   AIC:                             5508.\n",
       "Df Residuals:                    4332   BIC:                             5597.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0373      0.009      4.241      0.000       0.020       0.055\n",
       "recog_effort             0.2054      0.035      5.795      0.000       0.136       0.275\n",
       "working_hours           -0.0008      0.001     -0.784      0.433      -0.003       0.001\n",
       "firmsize                -0.0109      0.003     -4.305      0.000      -0.016      -0.006\n",
       "tenure                  -0.0148      0.003     -5.911      0.000      -0.020      -0.010\n",
       "years_educ               0.0211      0.002      8.548      0.000       0.016       0.026\n",
       "gender                   0.0485      0.016      2.964      0.003       0.016       0.081\n",
       "commute_distance         0.0004      0.000      2.332      0.020    5.64e-05       0.001\n",
       "avg_rec                  0.0261      0.006      4.264      0.000       0.014       0.038\n",
       "age                      0.0420      0.007      5.889      0.000       0.028       0.056\n",
       "potential_experience     0.0007      0.000      2.430      0.015       0.000       0.001\n",
       "age_squared             -0.1058      0.026     -4.069      0.000      -0.157      -0.055\n",
       "tenure_squared           0.0200      0.006      3.234      0.001       0.008       0.032\n",
       "mincer_residuals     -7.171e-06   1.07e-05     -0.669      0.504   -2.82e-05    1.38e-05\n",
       "recXrecog_effort        -0.0252      0.010     -2.436      0.015      -0.045      -0.005\n",
       "==============================================================================\n",
       "Omnibus:                    55777.257   Durbin-Watson:                   1.843\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              344.065\n",
       "Skew:                           0.035   Prob(JB):                     1.94e-75\n",
       "Kurtosis:                       1.623   Cond. No.                     3.56e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 3.09e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfworksatisfation = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)),worksatisfaction = True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_rc_ws = dfworksatisfation.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month \"\"\"\n",
    "# add interaction term\n",
    "df_rc_ws[\"recXrecog_effort\"] = df_rc_ws[\"recog_effort\"] * df_rc_ws[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_rc_ws.dropna(inplace=True)\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = df_rc_ws[\"turnover_intention\"]\n",
    "X = df_rc_ws.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Check \n",
    "\n",
    "Avg reciprocity measure over years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/2835927587.py:253: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   539.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:09:15</td>      <th>  Log-Likelihood:    </th> <td> -3377.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6782.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5393</td>       <th>  BIC:               </th> <td>   6874.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0375</td> <td>    0.008</td> <td>    4.803</td> <td> 0.000</td> <td>    0.022</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1607</td> <td>    0.034</td> <td>    4.713</td> <td> 0.000</td> <td>    0.094</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0009</td> <td>    0.001</td> <td>   -1.066</td> <td> 0.286</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0114</td> <td>    0.002</td> <td>   -5.054</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0162</td> <td>    0.002</td> <td>   -7.264</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0207</td> <td>    0.002</td> <td>    9.286</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0505</td> <td>    0.015</td> <td>    3.459</td> <td> 0.001</td> <td>    0.022</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.048</td> <td> 0.002</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0436</td> <td>    0.006</td> <td>    6.844</td> <td> 0.000</td> <td>    0.031</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0007</td> <td>    0.000</td> <td>    2.612</td> <td> 0.009</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1058</td> <td>    0.023</td> <td>   -4.590</td> <td> 0.000</td> <td>   -0.151</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0212</td> <td>    0.006</td> <td>    3.835</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.218e-05</td> <td> 9.37e-06</td> <td>   -1.300</td> <td> 0.194</td> <td>-3.05e-05</td> <td> 6.18e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0267</td> <td>    0.006</td> <td>    4.248</td> <td> 0.000</td> <td>    0.014</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0150</td> <td>    0.010</td> <td>   -1.490</td> <td> 0.136</td> <td>   -0.035</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>81125.486</td> <th>  Durbin-Watson:     </th> <td>   1.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 400.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.034</td>   <th>  Prob(JB):          </th> <td>8.78e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.668</td>   <th>  Cond. No.          </th> <td>1.92e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.183\n",
       "Model:                            OLS   Adj. R-squared:                  0.181\n",
       "Method:                 Least Squares   F-statistic:                     539.5\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:09:15   Log-Likelihood:                -3377.0\n",
       "No. Observations:                5407   AIC:                             6782.\n",
       "Df Residuals:                    5393   BIC:                             6874.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0375      0.008      4.803      0.000       0.022       0.053\n",
       "recog_effort             0.1607      0.034      4.713      0.000       0.094       0.227\n",
       "working_hours           -0.0009      0.001     -1.066      0.286      -0.003       0.001\n",
       "firmsize                -0.0114      0.002     -5.054      0.000      -0.016      -0.007\n",
       "tenure                  -0.0162      0.002     -7.264      0.000      -0.021      -0.012\n",
       "years_educ               0.0207      0.002      9.286      0.000       0.016       0.025\n",
       "gender                   0.0505      0.015      3.459      0.001       0.022       0.079\n",
       "commute_distance         0.0004      0.000      3.048      0.002       0.000       0.001\n",
       "age                      0.0436      0.006      6.844      0.000       0.031       0.056\n",
       "potential_experience     0.0007      0.000      2.612      0.009       0.000       0.001\n",
       "age_squared             -0.1058      0.023     -4.590      0.000      -0.151      -0.061\n",
       "tenure_squared           0.0212      0.006      3.835      0.000       0.010       0.032\n",
       "mincer_residuals     -1.218e-05   9.37e-06     -1.300      0.194   -3.05e-05    6.18e-06\n",
       "avg_rec                  0.0267      0.006      4.248      0.000       0.014       0.039\n",
       "recXrecog_effort        -0.0150      0.010     -1.490      0.136      -0.035       0.005\n",
       "==============================================================================\n",
       "Omnibus:                    81125.486   Durbin-Watson:                   1.834\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              400.910\n",
       "Skew:                          -0.034   Prob(JB):                     8.78e-88\n",
       "Kurtosis:                       1.668   Cond. No.                     1.92e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.35e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS_avg = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS_avg = df_OLS_avg.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction','avg_rec'])\n",
    "# Load avg reciprocity measures over the years\n",
    "# Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/rec_avgyears.csv'  \n",
    "# Maxie '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/rec_avgyears.csv'\n",
    "avg_reciprocity = pd.read_csv('/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/rec_avgyears.csv')\n",
    "avg_reciprocity.reset_index(inplace=True)\n",
    "avg_reciprocity.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "avg_reciprocity.drop(\"index\",axis=1 ,inplace =True)\n",
    "\n",
    "df_avg_years = pd.merge(df_OLS_avg,avg_reciprocity, on=[\"pid\",\"hid\"])\n",
    "# add interaction term\n",
    "df_avg_years[\"recXrecog_effort\"] = df_avg_years[\"recog_effort\"] * df_avg_years[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_avg_years.dropna(inplace=True)\n",
    "\n",
    "\n",
    "Y = df_avg_years[\"turnover_intention\"]\n",
    "X = df_avg_years.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also does not change much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df7d47ce4f33ec65ca12ba7db2796b6cbc8620dcf8689ec69de714ca1293d9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
