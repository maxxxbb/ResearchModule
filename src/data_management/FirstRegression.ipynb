{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Regression (Turnover intention ~ unfair treatment x neg. reciprocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Read in SOEP Data:\n",
    "- vp : 2005 data : main variables of interest: questions on negative reciprocity\n",
    "- wp: 2006 data : main variables of interest: question on perceived recognition for work\n",
    "- xp: 2007 data : main variables of interest: turnover intentions, controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"/Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>syear</th>\n",
       "      <th>take_revenge</th>\n",
       "      <th>similar_problems</th>\n",
       "      <th>insult_back</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th>hid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <th>27</th>\n",
       "      <td>2005</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <th>60313</th>\n",
       "      <td>2005</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <th>60</th>\n",
       "      <td>2005</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[4] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           syear                    take_revenge similar_problems  \\\n",
       "pid hid                                                             \n",
       "201 27      2005  [1] Trifft ueberhaupt nicht zu    [5] Skala 1-7   \n",
       "203 60313   2005                   [2] Skala 1-7    [3] Skala 1-7   \n",
       "602 60      2005                   [5] Skala 1-7    [4] Skala 1-7   \n",
       "\n",
       "                              insult_back  rec1  rec2  rec3  rec4  rec5  rec6  \\\n",
       "pid hid                                                                         \n",
       "201 27     [1] Trifft ueberhaupt nicht zu     1     0     0     0     0     0   \n",
       "203 60313                   [2] Skala 1-7     0     1     0     0     0     0   \n",
       "602 60                      [3] Skala 1-7     0     0     0     0     1     0   \n",
       "\n",
       "           rec7  \n",
       "pid hid          \n",
       "201 27        0  \n",
       "203 60313     0  \n",
       "602 60        0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\", \"syear\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_2005 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})\n",
    "# create dummies for take_revenge question\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(df_2005['take_revenge'])\n",
    "\n",
    "# Join the dummy variables to the original dataframe\n",
    "df_2005 = pd.concat([df_2005, dummies], axis=1)\n",
    "# rename dummy\n",
    "df_05 = df_2005.rename(columns = {'[1] Trifft ueberhaupt nicht zu' : 'rec1' , '[2] Skala 1-7' : 'rec2' , '[3] Skala 1-7' : 'rec3' ,'[4] Skala 1-7' : 'rec4' ,'[5] Skala 1-7' : 'rec5' ,'[6] Skala 1-7' : 'rec6' ,'[7] Trifft voll zu' : 'rec7'})\n",
    "df_05 = df_05.drop(columns = [\"[-1] keine Angabe\"])\n",
    "df_05.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", \"syear\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08' ]).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2007 data\n",
    "# here left out 'xp8601' for school degree since we have it in another module also 'xp0102' : 'work_satisfaction' for the beginning\n",
    "#for outcome and all controls\n",
    "data3= pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\", \"syear\", 'xp13101' , 'xp13102', 'xp2701', 'xp7302','xp7202','xp28', 'xp3001' ,  'xp5701' , 'xp0102']).set_index(['pid', 'hid'])\n",
    "df_07 = data3.rename(columns= {'xp13101':'gender','xp13102': 'year_birth' ,'xp2701': 'turnover_intention' , 'xp7302': 'wage_lastmonth','xp7202': 'overtime','xp28': 'new_job', 'xp3001': 'reason_new_job',  'xp5701' : 'commute_distance' , \"xp0102\" : \"work_satisfaction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2007 data from work module\n",
    "\n",
    "# adapt path and merge\n",
    "hours07 = pd.read_stata(file_paths_2[2], columns=[\"pid\",\"hid\", \"syear\", \"xvebzeit\", \"xpsbil\", \"betr07\", \"xerwzeit\", \"xbilzeit\"]).set_index(['pid', 'hid'])\n",
    "work07 = hours07.rename(columns={'xvebzeit': 'working_hours', \"xpsbil\": \"school_degree\", \"betr07\": \"firmsize\", \"xerwzeit\": \"tenure\" , \"xbilzeit\" : \"years_educ\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Define Functions and mappings for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbststÃ¤ndig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for turnover intention: split up into binary with roughly equal value counts for simplicity: might change that later to categories\n",
    "satisfaction_mapping = {\n",
    "    '[0] 0 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[1] 1 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[2] 2 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[3] 3 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[4] 4 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[5] 5 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[6] 6 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[7] 7 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[8] 8 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[9] 9 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[10] 10 Zufrieden: Skala 0-Niedrig bis 10-Hoc': 1,\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention robustness check: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "# mapping for binary reciprocity measure\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 3:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group\n",
    "\n",
    "## function for recoding values and dropping missing\n",
    "\n",
    "def recode_categoricals(inputdf,rc_cardinal = 0):\n",
    "    \"\"\"\n",
    "        merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode job satisfaction\n",
    "    merged['work_satisfaction']= merged['work_satisfaction'].map(satisfaction_mapping)\n",
    "    # recode turnover intention variable\n",
    "    if rc_cardinal == 1:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping_cardinal)\n",
    "    else:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping)\n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output\n",
    "\n",
    "# Merge dataframes: a bit tough to read as its nested, merges 4 dataframes: 2005,2006,2007 and 2007gen\n",
    "\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df,rc_cardinal).astype('int')\n",
    "\n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan) \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"turnover_intention\", \"new_job\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add Mincer Wage Regression and adds its residuals to the Dataframe\n",
    "\n",
    "def add_mincer_residuals(cleaneddata):\n",
    "    \n",
    "    df_cleaned = cleaneddata\n",
    "    # specify which columns to drop from our dataframe\n",
    "    df_mincer = cleaneddata.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup', 'age', 'commute_distance', 'recog_effort', 'working_hours', 'turnover_intention', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "    # Convert 'gender' and 'sector' columns to categorical data type\n",
    "    for col in ['gender']:\n",
    "        df_mincer[col] = df_mincer[col].astype('category')\n",
    "    df_mincer = df_mincer.dropna()\n",
    "    # Define the dependent variable\n",
    "    y = df_mincer['wage_lastmonth']\n",
    "    # Define the independent variables\n",
    "    X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "    # Add a constant term to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the Mincer wage regression model\n",
    "    mincer_model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Create a new column in the dataframe with the same name as the residuals array/ delete relative wage entries\n",
    "    df_cleaned['mincer_residuals'] = None\n",
    "    # Match the rows of the dataframe with the values in the residuals array using the index\n",
    "    df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlcude People who switched their jobs in 2006-2007 with 2006 controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_jobchangers(data07,onlynewemployer=False,worksatisfaction=False):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "            df: finished 2007 dataframe\n",
    "            onlynewemployer: optional argument: If True only includes those who switched jobs to a new employer\n",
    "            worksatisfaction: if True drops observations where job satisfaction between 2006 and 2007 changed to check for our Assumption\n",
    "    \n",
    "    \"\"\"\n",
    "    df = data07\n",
    "    # read in cleaned 2006 dataset:\n",
    "    #  change path here : Maxie: '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv'\n",
    "    #                     Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv'  \n",
    "    observations_2006 = pd.read_csv('/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv')\n",
    "    # some initial datamanagement\n",
    "    observations_2006.reset_index(inplace=True)\n",
    "    observations_2006.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "    observations_2006.drop(columns=observations_2006.filter(regex='^syear').columns, inplace=True)\n",
    "    observations_2006.drop(\"index\",axis=1 ,inplace =True)\n",
    "    # drop s year columns from both dataframes\n",
    "    df.drop(columns=df.filter(regex='^syear').columns, inplace=True)\n",
    "    \n",
    "    # optional worksatisfaction robustness check\n",
    "    if worksatisfaction == True:\n",
    "        satisfaction = pd.DataFrame(df['work_satisfaction']).join(pd.DataFrame(observations_2006['work_satisfaction']), on = [\"pid\", \"hid\"], lsuffix = \"_07\" , rsuffix =\"_06\")\n",
    "        ID_keep_satis = satisfaction[satisfaction[\"work_satisfaction_07\"] == satisfaction[\"work_satisfaction_06\"]].index\n",
    "        df.drop(df[~df.index.isin(ID_keep_satis)].index, inplace=True)\n",
    "    \n",
    "    # create list of IDs of people who switched to a new employer in the last year in 2007\n",
    "    if onlynewemployer == True:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1) & (df[\"reason_new_job\"] == '[3] Stelle bei neuen Arbeitgeber')].index\n",
    "    # if True drops people whose work satisfaction changed between 2006 and 2007\n",
    "    else:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1)].index\n",
    "    \n",
    "    # drop all who changed their job in 2007 dataframe and replace 2007 controls with 2006 controls\n",
    "    df.drop(df[df[\"new_job\"] == 1].index, inplace = True)\n",
    "    observations_2006.drop(observations_2006[~observations_2006.index.isin(IDs_tokeep)].index, inplace=True)\n",
    "    #concat both dataframes\n",
    "    dfconcat = pd.concat([df,observations_2006])\n",
    "    \n",
    "    return dfconcat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis\n",
    "#### 1.Probit Regression\n",
    "\n",
    "- Probit Estimation: TurnoverIntention_{2005} = Constant + Neg-Rec + Unfair + Rec X Unfair + Controls + Error\n",
    "\n",
    "- As the measure for unfair treatment in the first regression i first used recog_effort -> decide for one later\n",
    "    - \"When I consider all my accomplishments and efforts, the recognition of I've received seems about right to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    }
   ],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS = df_OLS.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "df_OLS[\"recXrecog_effort\"] = df_OLS[\"recog_effort\"] * df_OLS[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_OLS.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578235\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>turnover_intention</td> <th>  No. Observations:  </th>   <td>  5962</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Probit</td>       <th>  Df Residuals:      </th>   <td>  5949</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>   <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Jan 2023</td>  <th>  Pseudo R-squ.:     </th>   <td>0.1628</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:53:03</td>      <th>  Log-Likelihood:    </th>  <td> -3447.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th>  <td> -4117.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.020e-279</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0500</td> <td>    0.193</td> <td>    0.259</td> <td> 0.795</td> <td>   -0.328</td> <td>    0.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.5002</td> <td>    0.089</td> <td>    5.611</td> <td> 0.000</td> <td>    0.325</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0028</td> <td>    0.002</td> <td>   -1.178</td> <td> 0.239</td> <td>   -0.007</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0340</td> <td>    0.006</td> <td>   -5.391</td> <td> 0.000</td> <td>   -0.046</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0311</td> <td>    0.002</td> <td>  -13.729</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0603</td> <td>    0.007</td> <td>    9.038</td> <td> 0.000</td> <td>    0.047</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.1464</td> <td>    0.042</td> <td>    3.509</td> <td> 0.000</td> <td>    0.065</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0013</td> <td>    0.000</td> <td>    3.255</td> <td> 0.001</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0697</td> <td>    0.016</td> <td>    4.421</td> <td> 0.000</td> <td>    0.039</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0010</td> <td>    0.000</td> <td>   -2.903</td> <td> 0.004</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0177</td> <td>    0.021</td> <td>    0.839</td> <td> 0.401</td> <td>   -0.024</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-5.588e-05</td> <td> 2.69e-05</td> <td>   -2.076</td> <td> 0.038</td> <td>   -0.000</td> <td>-3.13e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0569</td> <td>    0.026</td> <td>   -2.217</td> <td> 0.027</td> <td>   -0.107</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   No. Observations:                 5962\n",
       "Model:                         Probit   Df Residuals:                     5949\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Sun, 08 Jan 2023   Pseudo R-squ.:                  0.1628\n",
       "Time:                        18:53:03   Log-Likelihood:                -3447.4\n",
       "converged:                       True   LL-Null:                       -4117.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.020e-279\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0500      0.193      0.259      0.795      -0.328       0.428\n",
       "recog_effort             0.5002      0.089      5.611      0.000       0.325       0.675\n",
       "working_hours           -0.0028      0.002     -1.178      0.239      -0.007       0.002\n",
       "firmsize                -0.0340      0.006     -5.391      0.000      -0.046      -0.022\n",
       "tenure                  -0.0311      0.002    -13.729      0.000      -0.036      -0.027\n",
       "years_educ               0.0603      0.007      9.038      0.000       0.047       0.073\n",
       "gender                   0.1464      0.042      3.509      0.000       0.065       0.228\n",
       "commute_distance         0.0013      0.000      3.255      0.001       0.001       0.002\n",
       "avg_rec                  0.0697      0.016      4.421      0.000       0.039       0.101\n",
       "potential_experience    -0.0010      0.000     -2.903      0.004      -0.002      -0.000\n",
       "age_squared              0.0177      0.021      0.839      0.401      -0.024       0.059\n",
       "mincer_residuals     -5.588e-05   2.69e-05     -2.076      0.038      -0.000   -3.13e-06\n",
       "recXrecog_effort        -0.0569      0.026     -2.217      0.027      -0.107      -0.007\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit\n",
    "# Define Outcome variable\n",
    "Y = df_OLS[\"turnover_intention\"]\n",
    "# define X matrix\n",
    "X = df_OLS.drop(columns=[\"turnover_intention\"])\n",
    "# add constant \n",
    "X = sm.add_constant(X)\n",
    "# build model\n",
    "model = Probit(Y, X.astype(float))\n",
    "# estimate model\n",
    "probit_model = model.fit()\n",
    "# print summary table\n",
    "probit_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. OLS\n",
    "Now, instead of using a probit model, we use OLS.  linear probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.204</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.203</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   127.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>8.21e-284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:06</td>      <th>  Log-Likelihood:    </th> <td> -3631.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5962</td>       <th>  AIC:               </th> <td>   7289.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5949</td>       <th>  BIC:               </th> <td>   7376.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.5621</td> <td>    0.061</td> <td>    9.266</td> <td> 0.000</td> <td>    0.443</td> <td>    0.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1657</td> <td>    0.029</td> <td>    5.662</td> <td> 0.000</td> <td>    0.108</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0012</td> <td>    0.001</td> <td>   -1.487</td> <td> 0.137</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0113</td> <td>    0.002</td> <td>   -5.423</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0103</td> <td>    0.001</td> <td>  -14.227</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0202</td> <td>    0.002</td> <td>    9.356</td> <td> 0.000</td> <td>    0.016</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0505</td> <td>    0.014</td> <td>    3.680</td> <td> 0.000</td> <td>    0.024</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.288</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0234</td> <td>    0.005</td> <td>    4.486</td> <td> 0.000</td> <td>    0.013</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -2.583</td> <td> 0.010</td> <td>   -0.000</td> <td>-6.79e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0018</td> <td>    0.006</td> <td>    0.279</td> <td> 0.780</td> <td>   -0.011</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.581e-05</td> <td> 8.78e-06</td> <td>   -1.800</td> <td> 0.072</td> <td> -3.3e-05</td> <td>  1.4e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0188</td> <td>    0.008</td> <td>   -2.228</td> <td> 0.026</td> <td>   -0.035</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5684.832</td> <th>  Durbin-Watson:     </th> <td>   1.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 391.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.166</td>  <th>  Prob(JB):          </th> <td>8.54e-86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.789</td>  <th>  Cond. No.          </th> <td>9.88e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.88e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.204\n",
       "Model:                            OLS   Adj. R-squared:                  0.203\n",
       "Method:                 Least Squares   F-statistic:                     127.1\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          8.21e-284\n",
       "Time:                        18:53:06   Log-Likelihood:                -3631.6\n",
       "No. Observations:                5962   AIC:                             7289.\n",
       "Df Residuals:                    5949   BIC:                             7376.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.5621      0.061      9.266      0.000       0.443       0.681\n",
       "recog_effort             0.1657      0.029      5.662      0.000       0.108       0.223\n",
       "working_hours           -0.0012      0.001     -1.487      0.137      -0.003       0.000\n",
       "firmsize                -0.0113      0.002     -5.423      0.000      -0.015      -0.007\n",
       "tenure                  -0.0103      0.001    -14.227      0.000      -0.012      -0.009\n",
       "years_educ               0.0202      0.002      9.356      0.000       0.016       0.024\n",
       "gender                   0.0505      0.014      3.680      0.000       0.024       0.077\n",
       "commute_distance         0.0004      0.000      3.288      0.001       0.000       0.001\n",
       "avg_rec                  0.0234      0.005      4.486      0.000       0.013       0.034\n",
       "potential_experience    -0.0003      0.000     -2.583      0.010      -0.000   -6.79e-05\n",
       "age_squared              0.0018      0.006      0.279      0.780      -0.011       0.014\n",
       "mincer_residuals     -1.581e-05   8.78e-06     -1.800      0.072    -3.3e-05     1.4e-06\n",
       "recXrecog_effort        -0.0188      0.008     -2.228      0.026      -0.035      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                     5684.832   Durbin-Watson:                   1.757\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              391.756\n",
       "Skew:                          -0.166   Prob(JB):                     8.54e-86\n",
       "Kurtosis:                       1.789   Cond. No.                     9.88e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.88e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Checks\n",
    "\n",
    "\n",
    "#### 1. Recode turnover variable into cardinal variable: Optional argument in recode_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.118</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   67.27</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>1.98e-154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:12</td>      <th>  Log-Likelihood:    </th> <td> -27940.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5962</td>       <th>  AIC:               </th> <td>5.591e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5949</td>       <th>  BIC:               </th> <td>5.599e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   33.4064</td> <td>    3.578</td> <td>    9.337</td> <td> 0.000</td> <td>   26.392</td> <td>   40.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    7.8900</td> <td>    1.727</td> <td>    4.570</td> <td> 0.000</td> <td>    4.505</td> <td>   11.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0752</td> <td>    0.046</td> <td>   -1.622</td> <td> 0.105</td> <td>   -0.166</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.2829</td> <td>    0.123</td> <td>   -2.309</td> <td> 0.021</td> <td>   -0.523</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.3575</td> <td>    0.043</td> <td>   -8.335</td> <td> 0.000</td> <td>   -0.442</td> <td>   -0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.7148</td> <td>    0.127</td> <td>    5.612</td> <td> 0.000</td> <td>    0.465</td> <td>    0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    2.4616</td> <td>    0.809</td> <td>    3.044</td> <td> 0.002</td> <td>    0.876</td> <td>    4.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0142</td> <td>    0.007</td> <td>    2.097</td> <td> 0.036</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.7448</td> <td>    0.307</td> <td>    2.426</td> <td> 0.015</td> <td>    0.143</td> <td>    1.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0161</td> <td>    0.006</td> <td>    2.508</td> <td> 0.012</td> <td>    0.004</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -1.6599</td> <td>    0.382</td> <td>   -4.348</td> <td> 0.000</td> <td>   -2.408</td> <td>   -0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0007</td> <td>    0.001</td> <td>   -1.255</td> <td> 0.209</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.4278</td> <td>    0.497</td> <td>   -0.860</td> <td> 0.390</td> <td>   -1.403</td> <td>    0.547</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1184.351</td> <th>  Durbin-Watson:     </th> <td>   1.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2053.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.300</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.228</td>  <th>  Cond. No.          </th> <td>9.88e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.88e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.119\n",
       "Model:                            OLS   Adj. R-squared:                  0.118\n",
       "Method:                 Least Squares   F-statistic:                     67.27\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          1.98e-154\n",
       "Time:                        18:53:12   Log-Likelihood:                -27940.\n",
       "No. Observations:                5962   AIC:                         5.591e+04\n",
       "Df Residuals:                    5949   BIC:                         5.599e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   33.4064      3.578      9.337      0.000      26.392      40.421\n",
       "recog_effort             7.8900      1.727      4.570      0.000       4.505      11.275\n",
       "working_hours           -0.0752      0.046     -1.622      0.105      -0.166       0.016\n",
       "firmsize                -0.2829      0.123     -2.309      0.021      -0.523      -0.043\n",
       "tenure                  -0.3575      0.043     -8.335      0.000      -0.442      -0.273\n",
       "years_educ               0.7148      0.127      5.612      0.000       0.465       0.965\n",
       "gender                   2.4616      0.809      3.044      0.002       0.876       4.047\n",
       "commute_distance         0.0142      0.007      2.097      0.036       0.001       0.028\n",
       "avg_rec                  0.7448      0.307      2.426      0.015       0.143       1.347\n",
       "potential_experience     0.0161      0.006      2.508      0.012       0.004       0.029\n",
       "age_squared             -1.6599      0.382     -4.348      0.000      -2.408      -0.912\n",
       "mincer_residuals        -0.0007      0.001     -1.255      0.209      -0.002       0.000\n",
       "recXrecog_effort        -0.4278      0.497     -0.860      0.390      -1.403       0.547\n",
       "==============================================================================\n",
       "Omnibus:                     1184.351   Durbin-Watson:                   1.739\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2053.669\n",
       "Skew:                           1.300   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.228   Cond. No.                     9.88e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.88e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional argument ==1\n",
    "dfrc1 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal=1)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_cardinal = dfrc1.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age','rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "dfrc_cardinal[\"recXrecog_effort\"] = dfrc_cardinal[\"recog_effort\"] * dfrc_cardinal[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_cardinal = dfrc_cardinal.dropna()\n",
    "\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_cardinal[\"turnover_intention\"]\n",
    "X = dfrc_cardinal.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not change much. Coefficient on the interaction term becomes insignificant.\n",
    "\n",
    "#### 2. Different Reciprocity Specifications\n",
    "\n",
    "    1. Split into binary: High/ Low reciprocal\n",
    "    2. create dummies for each category and estimate regression for those\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.181</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.179</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   99.28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>4.18e-223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:16</td>      <th>  Log-Likelihood:    </th> <td> -3383.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6792.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5394</td>       <th>  BIC:               </th> <td>   6878.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>    0.5105</td> <td>    0.064</td> <td>    7.924</td> <td> 0.000</td> <td>    0.384</td> <td>    0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>           <td>    0.1516</td> <td>    0.019</td> <td>    7.909</td> <td> 0.000</td> <td>    0.114</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>          <td>   -0.0009</td> <td>    0.001</td> <td>   -1.104</td> <td> 0.270</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>               <td>   -0.0119</td> <td>    0.002</td> <td>   -5.359</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>                 <td>   -0.0086</td> <td>    0.001</td> <td>  -11.090</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>             <td>    0.0198</td> <td>    0.002</td> <td>    8.612</td> <td> 0.000</td> <td>    0.015</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                 <td>    0.0547</td> <td>    0.015</td> <td>    3.745</td> <td> 0.000</td> <td>    0.026</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>       <td>    0.0004</td> <td>    0.000</td> <td>    2.922</td> <td> 0.003</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>             <td>    0.0700</td> <td>    0.016</td> <td>    4.456</td> <td> 0.000</td> <td>    0.039</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th>   <td>   -0.0004</td> <td>    0.000</td> <td>   -3.095</td> <td> 0.002</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>            <td>    0.0067</td> <td>    0.007</td> <td>    0.937</td> <td> 0.349</td> <td>   -0.007</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>       <td>-1.347e-05</td> <td> 9.36e-06</td> <td>   -1.440</td> <td> 0.150</td> <td>-3.18e-05</td> <td> 4.88e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binaryrecXrecog_effort</th> <td>   -0.0686</td> <td>    0.026</td> <td>   -2.673</td> <td> 0.008</td> <td>   -0.119</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114950.168</td> <th>  Durbin-Watson:     </th> <td>   1.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 414.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.043</td>   <th>  Prob(JB):          </th> <td>1.13e-90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 1.647</td>   <th>  Cond. No.          </th> <td>1.01e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.01e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.181\n",
       "Model:                            OLS   Adj. R-squared:                  0.179\n",
       "Method:                 Least Squares   F-statistic:                     99.28\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          4.18e-223\n",
       "Time:                        18:53:16   Log-Likelihood:                -3383.2\n",
       "No. Observations:                5407   AIC:                             6792.\n",
       "Df Residuals:                    5394   BIC:                             6878.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                      0.5105      0.064      7.924      0.000       0.384       0.637\n",
       "recog_effort               0.1516      0.019      7.909      0.000       0.114       0.189\n",
       "working_hours             -0.0009      0.001     -1.104      0.270      -0.003       0.001\n",
       "firmsize                  -0.0119      0.002     -5.359      0.000      -0.016      -0.008\n",
       "tenure                    -0.0086      0.001    -11.090      0.000      -0.010      -0.007\n",
       "years_educ                 0.0198      0.002      8.612      0.000       0.015       0.024\n",
       "gender                     0.0547      0.015      3.745      0.000       0.026       0.083\n",
       "commute_distance           0.0004      0.000      2.922      0.003       0.000       0.001\n",
       "binary_rec                 0.0700      0.016      4.456      0.000       0.039       0.101\n",
       "potential_experience      -0.0004      0.000     -3.095      0.002      -0.001      -0.000\n",
       "age_squared                0.0067      0.007      0.937      0.349      -0.007       0.021\n",
       "mincer_residuals       -1.347e-05   9.36e-06     -1.440      0.150   -3.18e-05    4.88e-06\n",
       "binaryrecXrecog_effort    -0.0686      0.026     -2.673      0.008      -0.119      -0.018\n",
       "==============================================================================\n",
       "Omnibus:                   114950.168   Durbin-Watson:                   1.834\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              414.217\n",
       "Skew:                          -0.043   Prob(JB):                     1.13e-90\n",
       "Kurtosis:                       1.647   Cond. No.                     1.01e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.01e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1 . Split up from when average bigger than 3\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_binary = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age', 'avg_rec', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "# add interaction term\n",
    "dfrc_binary[\"binaryrecXrecog_effort\"] = dfrc_binary[\"recog_effort\"] * dfrc_binary[\"binary_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_binary = dfrc_binary.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_binary[\"turnover_intention\"]\n",
    "X = dfrc_binary.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### also does not change a lot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating dummies and include 7 interaction terms : Decide for one of the 3 questions for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.220</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.216</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   57.93</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>2.56e-264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:21</td>      <th>  Log-Likelihood:    </th> <td> -3230.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5372</td>       <th>  AIC:               </th> <td>   6515.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5345</td>       <th>  BIC:               </th> <td>   6693.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    26</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0184</td> <td>    0.191</td> <td>    0.097</td> <td> 0.923</td> <td>   -0.355</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec1</th>                 <td>    0.2005</td> <td>    0.182</td> <td>    1.100</td> <td> 0.271</td> <td>   -0.157</td> <td>    0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2</th>                 <td>    0.3284</td> <td>    0.182</td> <td>    1.804</td> <td> 0.071</td> <td>   -0.029</td> <td>    0.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3</th>                 <td>    0.3817</td> <td>    0.182</td> <td>    2.097</td> <td> 0.036</td> <td>    0.025</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4</th>                 <td>    0.3259</td> <td>    0.182</td> <td>    1.789</td> <td> 0.074</td> <td>   -0.031</td> <td>    0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5</th>                 <td>    0.3702</td> <td>    0.183</td> <td>    2.027</td> <td> 0.043</td> <td>    0.012</td> <td>    0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6</th>                 <td>    0.3824</td> <td>    0.185</td> <td>    2.069</td> <td> 0.039</td> <td>    0.020</td> <td>    0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7</th>                 <td>    0.2766</td> <td>    0.185</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.085</td> <td>    0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.5548</td> <td>    0.362</td> <td>    1.534</td> <td> 0.125</td> <td>   -0.154</td> <td>    1.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0014</td> <td>    0.001</td> <td>   -1.610</td> <td> 0.107</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0116</td> <td>    0.002</td> <td>   -5.289</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0086</td> <td>    0.001</td> <td>  -11.227</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0199</td> <td>    0.002</td> <td>    8.724</td> <td> 0.000</td> <td>    0.015</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0544</td> <td>    0.014</td> <td>    3.781</td> <td> 0.000</td> <td>    0.026</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0003</td> <td>    0.000</td> <td>    2.683</td> <td> 0.007</td> <td> 9.35e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work_satisfaction</th>    <td>    0.1945</td> <td>    0.015</td> <td>   13.093</td> <td> 0.000</td> <td>    0.165</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>           <td>   -0.0048</td> <td>    0.019</td> <td>   -0.252</td> <td> 0.801</td> <td>   -0.042</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0004</td> <td>    0.000</td> <td>   -3.221</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0071</td> <td>    0.007</td> <td>    1.002</td> <td> 0.316</td> <td>   -0.007</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td> -5.67e-06</td> <td> 9.21e-06</td> <td>   -0.616</td> <td> 0.538</td> <td>-2.37e-05</td> <td> 1.24e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec1_X_recog_effort</th>  <td>   -0.4467</td> <td>    0.363</td> <td>   -1.231</td> <td> 0.219</td> <td>   -1.158</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2_X_recog_effort</th>  <td>   -0.4592</td> <td>    0.363</td> <td>   -1.266</td> <td> 0.206</td> <td>   -1.170</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3_X_recog_effort</th>  <td>   -0.4546</td> <td>    0.363</td> <td>   -1.253</td> <td> 0.210</td> <td>   -1.166</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4_X_recog_effort</th>  <td>   -0.4839</td> <td>    0.363</td> <td>   -1.334</td> <td> 0.182</td> <td>   -1.195</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5_X_recog_effort</th>  <td>   -0.5391</td> <td>    0.364</td> <td>   -1.483</td> <td> 0.138</td> <td>   -1.252</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6_X_recog_effort</th>  <td>   -0.5039</td> <td>    0.365</td> <td>   -1.379</td> <td> 0.168</td> <td>   -1.220</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7_X_recog_effort</th>  <td>   -0.5133</td> <td>    0.366</td> <td>   -1.404</td> <td> 0.160</td> <td>   -1.230</td> <td>    0.203</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6951.807</td> <th>  Durbin-Watson:     </th> <td>   1.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 345.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.022</td>  <th>  Prob(JB):          </th> <td>1.20e-75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.759</td>  <th>  Cond. No.          </th> <td>1.67e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.67e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.220\n",
       "Model:                            OLS   Adj. R-squared:                  0.216\n",
       "Method:                 Least Squares   F-statistic:                     57.93\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          2.56e-264\n",
       "Time:                        18:53:21   Log-Likelihood:                -3230.7\n",
       "No. Observations:                5372   AIC:                             6515.\n",
       "Df Residuals:                    5345   BIC:                             6693.\n",
       "Df Model:                          26                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0184      0.191      0.097      0.923      -0.355       0.392\n",
       "rec1                     0.2005      0.182      1.100      0.271      -0.157       0.558\n",
       "rec2                     0.3284      0.182      1.804      0.071      -0.029       0.685\n",
       "rec3                     0.3817      0.182      2.097      0.036       0.025       0.739\n",
       "rec4                     0.3259      0.182      1.789      0.074      -0.031       0.683\n",
       "rec5                     0.3702      0.183      2.027      0.043       0.012       0.728\n",
       "rec6                     0.3824      0.185      2.069      0.039       0.020       0.745\n",
       "rec7                     0.2766      0.185      1.499      0.134      -0.085       0.638\n",
       "recog_effort             0.5548      0.362      1.534      0.125      -0.154       1.264\n",
       "working_hours           -0.0014      0.001     -1.610      0.107      -0.003       0.000\n",
       "firmsize                -0.0116      0.002     -5.289      0.000      -0.016      -0.007\n",
       "tenure                  -0.0086      0.001    -11.227      0.000      -0.010      -0.007\n",
       "years_educ               0.0199      0.002      8.724      0.000       0.015       0.024\n",
       "gender                   0.0544      0.014      3.781      0.000       0.026       0.083\n",
       "commute_distance         0.0003      0.000      2.683      0.007    9.35e-05       0.001\n",
       "work_satisfaction        0.1945      0.015     13.093      0.000       0.165       0.224\n",
       "binary_rec              -0.0048      0.019     -0.252      0.801      -0.042       0.032\n",
       "potential_experience    -0.0004      0.000     -3.221      0.001      -0.001      -0.000\n",
       "age_squared              0.0071      0.007      1.002      0.316      -0.007       0.021\n",
       "mincer_residuals      -5.67e-06   9.21e-06     -0.616      0.538   -2.37e-05    1.24e-05\n",
       "rec1_X_recog_effort     -0.4467      0.363     -1.231      0.219      -1.158       0.265\n",
       "rec2_X_recog_effort     -0.4592      0.363     -1.266      0.206      -1.170       0.252\n",
       "rec3_X_recog_effort     -0.4546      0.363     -1.253      0.210      -1.166       0.257\n",
       "rec4_X_recog_effort     -0.4839      0.363     -1.334      0.182      -1.195       0.227\n",
       "rec5_X_recog_effort     -0.5391      0.364     -1.483      0.138      -1.252       0.174\n",
       "rec6_X_recog_effort     -0.5039      0.365     -1.379      0.168      -1.220       0.213\n",
       "rec7_X_recog_effort     -0.5133      0.366     -1.404      0.160      -1.230       0.203\n",
       "==============================================================================\n",
       "Omnibus:                     6951.807   Durbin-Watson:                   1.841\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              345.017\n",
       "Skew:                          -0.022   Prob(JB):                     1.20e-75\n",
       "Kurtosis:                       1.759   Cond. No.                     1.67e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.67e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_dummy = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay','year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age', 'avg_rec'])\n",
    "# add interaction terms\n",
    "for col in ['rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7']:\n",
    "    dfrc_dummy = dfrc_dummy.assign(**{col + '_X_recog_effort': dfrc_dummy[col] * dfrc_dummy['recog_effort']})\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_dummy = dfrc_dummy.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_dummy[\"turnover_intention\"]\n",
    "X = dfrc_dummy.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness Check : Drop people whose job satisfaction level changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.169</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.167</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   67.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>2.81e-163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:25</td>      <th>  Log-Likelihood:    </th> <td> -2744.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  4346</td>       <th>  AIC:               </th> <td>   5516.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  4332</td>       <th>  BIC:               </th> <td>   5605.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.4405</td> <td>    0.076</td> <td>    5.827</td> <td> 0.000</td> <td>    0.292</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.2040</td> <td>    0.036</td> <td>    5.691</td> <td> 0.000</td> <td>    0.134</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0008</td> <td>    0.001</td> <td>   -0.863</td> <td> 0.388</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0113</td> <td>    0.003</td> <td>   -4.490</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0077</td> <td>    0.001</td> <td>   -8.781</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0211</td> <td>    0.003</td> <td>    8.212</td> <td> 0.000</td> <td>    0.016</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0495</td> <td>    0.016</td> <td>    3.002</td> <td> 0.003</td> <td>    0.017</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    2.379</td> <td> 0.017</td> <td> 6.46e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0266</td> <td>    0.009</td> <td>    2.954</td> <td> 0.003</td> <td>    0.009</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>           <td>   -0.0011</td> <td>    0.023</td> <td>   -0.048</td> <td> 0.962</td> <td>   -0.046</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -2.173</td> <td> 0.030</td> <td>   -0.001</td> <td>-2.85e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0024</td> <td>    0.008</td> <td>    0.300</td> <td> 0.764</td> <td>   -0.013</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-8.208e-06</td> <td> 1.06e-05</td> <td>   -0.775</td> <td> 0.438</td> <td> -2.9e-05</td> <td> 1.26e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0253</td> <td>    0.010</td> <td>   -2.428</td> <td> 0.015</td> <td>   -0.046</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45563.699</td> <th>  Durbin-Watson:     </th> <td>   1.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 352.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.029</td>   <th>  Prob(JB):          </th> <td>2.76e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.606</td>   <th>  Cond. No.          </th> <td>1.04e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.04e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.169\n",
       "Model:                            OLS   Adj. R-squared:                  0.167\n",
       "Method:                 Least Squares   F-statistic:                     67.79\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          2.81e-163\n",
       "Time:                        18:53:25   Log-Likelihood:                -2744.1\n",
       "No. Observations:                4346   AIC:                             5516.\n",
       "Df Residuals:                    4332   BIC:                             5605.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.4405      0.076      5.827      0.000       0.292       0.589\n",
       "recog_effort             0.2040      0.036      5.691      0.000       0.134       0.274\n",
       "working_hours           -0.0008      0.001     -0.863      0.388      -0.003       0.001\n",
       "firmsize                -0.0113      0.003     -4.490      0.000      -0.016      -0.006\n",
       "tenure                  -0.0077      0.001     -8.781      0.000      -0.009      -0.006\n",
       "years_educ               0.0211      0.003      8.212      0.000       0.016       0.026\n",
       "gender                   0.0495      0.016      3.002      0.003       0.017       0.082\n",
       "commute_distance         0.0004      0.000      2.379      0.017    6.46e-05       0.001\n",
       "avg_rec                  0.0266      0.009      2.954      0.003       0.009       0.044\n",
       "binary_rec              -0.0011      0.023     -0.048      0.962      -0.046       0.044\n",
       "potential_experience    -0.0003      0.000     -2.173      0.030      -0.001   -2.85e-05\n",
       "age_squared              0.0024      0.008      0.300      0.764      -0.013       0.018\n",
       "mincer_residuals     -8.208e-06   1.06e-05     -0.775      0.438    -2.9e-05    1.26e-05\n",
       "recXrecog_effort        -0.0253      0.010     -2.428      0.015      -0.046      -0.005\n",
       "==============================================================================\n",
       "Omnibus:                    45563.699   Durbin-Watson:                   1.845\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              352.570\n",
       "Skew:                           0.029   Prob(JB):                     2.76e-77\n",
       "Kurtosis:                       1.606   Cond. No.                     1.04e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.04e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfworksatisfation = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)),worksatisfaction = True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_rc_ws = dfworksatisfation.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month \"\"\"\n",
    "# add interaction term\n",
    "df_rc_ws[\"recXrecog_effort\"] = df_rc_ws[\"recog_effort\"] * df_rc_ws[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_rc_ws.dropna(inplace=True)\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = df_rc_ws[\"turnover_intention\"]\n",
    "X = df_rc_ws.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Check \n",
    "\n",
    "Avg reciprocity measure over years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:193: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_85345/2434218017.py:251: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.204</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.203</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   127.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 08 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>6.21e-284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:53:28</td>      <th>  Log-Likelihood:    </th> <td> -3631.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5962</td>       <th>  AIC:               </th> <td>   7289.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5949</td>       <th>  BIC:               </th> <td>   7376.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.5509</td> <td>    0.061</td> <td>    8.968</td> <td> 0.000</td> <td>    0.430</td> <td>    0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1604</td> <td>    0.032</td> <td>    5.021</td> <td> 0.000</td> <td>    0.098</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0012</td> <td>    0.001</td> <td>   -1.505</td> <td> 0.132</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0112</td> <td>    0.002</td> <td>   -5.382</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0104</td> <td>    0.001</td> <td>  -14.247</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0206</td> <td>    0.002</td> <td>    9.501</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0491</td> <td>    0.014</td> <td>    3.571</td> <td> 0.000</td> <td>    0.022</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.301</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -2.551</td> <td> 0.011</td> <td>   -0.000</td> <td>-6.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0016</td> <td>    0.006</td> <td>    0.253</td> <td> 0.801</td> <td>   -0.011</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.565e-05</td> <td> 8.78e-06</td> <td>   -1.782</td> <td> 0.075</td> <td>-3.29e-05</td> <td> 1.57e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0260</td> <td>    0.006</td> <td>    4.471</td> <td> 0.000</td> <td>    0.015</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0173</td> <td>    0.009</td> <td>   -1.850</td> <td> 0.064</td> <td>   -0.036</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5582.654</td> <th>  Durbin-Watson:     </th> <td>   1.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 390.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.165</td>  <th>  Prob(JB):          </th> <td>1.96e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.791</td>  <th>  Cond. No.          </th> <td>1.00e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  1e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.204\n",
       "Model:                            OLS   Adj. R-squared:                  0.203\n",
       "Method:                 Least Squares   F-statistic:                     127.2\n",
       "Date:                Sun, 08 Jan 2023   Prob (F-statistic):          6.21e-284\n",
       "Time:                        18:53:28   Log-Likelihood:                -3631.3\n",
       "No. Observations:                5962   AIC:                             7289.\n",
       "Df Residuals:                    5949   BIC:                             7376.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.5509      0.061      8.968      0.000       0.430       0.671\n",
       "recog_effort             0.1604      0.032      5.021      0.000       0.098       0.223\n",
       "working_hours           -0.0012      0.001     -1.505      0.132      -0.003       0.000\n",
       "firmsize                -0.0112      0.002     -5.382      0.000      -0.015      -0.007\n",
       "tenure                  -0.0104      0.001    -14.247      0.000      -0.012      -0.009\n",
       "years_educ               0.0206      0.002      9.501      0.000       0.016       0.025\n",
       "gender                   0.0491      0.014      3.571      0.000       0.022       0.076\n",
       "commute_distance         0.0004      0.000      3.301      0.001       0.000       0.001\n",
       "potential_experience    -0.0003      0.000     -2.551      0.011      -0.000   -6.44e-05\n",
       "age_squared              0.0016      0.006      0.253      0.801      -0.011       0.014\n",
       "mincer_residuals     -1.565e-05   8.78e-06     -1.782      0.075   -3.29e-05    1.57e-06\n",
       "avg_rec                  0.0260      0.006      4.471      0.000       0.015       0.037\n",
       "recXrecog_effort        -0.0173      0.009     -1.850      0.064      -0.036       0.001\n",
       "==============================================================================\n",
       "Omnibus:                     5582.654   Durbin-Watson:                   1.756\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              390.089\n",
       "Skew:                          -0.165   Prob(JB):                     1.96e-85\n",
       "Kurtosis:                       1.791   Cond. No.                     1.00e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  1e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS_avg = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS_avg = df_OLS_avg.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'age', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction','avg_rec'])\n",
    "# Load avg reciprocity measures over the years\n",
    "\n",
    "avg_reciprocity = pd.read_csv('/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/rec_avgyears.csv')\n",
    "avg_reciprocity.reset_index(inplace=True)\n",
    "avg_reciprocity.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "avg_reciprocity.drop(\"index\",axis=1 ,inplace =True)\n",
    "\n",
    "df_avg_years = pd.merge(df_OLS_avg,avg_reciprocity, on=[\"pid\",\"hid\"])\n",
    "# add interaction term\n",
    "df_avg_years[\"recXrecog_effort\"] = df_avg_years[\"recog_effort\"] * df_avg_years[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_avg_years.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = df_avg_years[\"turnover_intention\"]\n",
    "X = df_avg_years.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also does not change much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df7d47ce4f33ec65ca12ba7db2796b6cbc8620dcf8689ec69de714ca1293d9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
