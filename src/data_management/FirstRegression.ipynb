{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Regression (Turnover intention ~ unfair treatment x neg. reciprocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Read in SOEP Data:\n",
    "- vp : 2005 data : main variables of interest: questions on negative reciprocity\n",
    "- wp: 2006 data : main variables of interest: question on perceived recognition for work\n",
    "- xp: 2007 data : main variables of interest: turnover intentions, controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>syear</th>\n",
       "      <th>take_revenge</th>\n",
       "      <th>similar_problems</th>\n",
       "      <th>insult_back</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th>hid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <th>27</th>\n",
       "      <td>2005</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[1] Trifft ueberhaupt nicht zu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <th>60313</th>\n",
       "      <td>2005</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>[2] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <th>60</th>\n",
       "      <td>2005</td>\n",
       "      <td>[5] Skala 1-7</td>\n",
       "      <td>[4] Skala 1-7</td>\n",
       "      <td>[3] Skala 1-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           syear                    take_revenge similar_problems  \\\n",
       "pid hid                                                             \n",
       "201 27      2005  [1] Trifft ueberhaupt nicht zu    [5] Skala 1-7   \n",
       "203 60313   2005                   [2] Skala 1-7    [3] Skala 1-7   \n",
       "602 60      2005                   [5] Skala 1-7    [4] Skala 1-7   \n",
       "\n",
       "                              insult_back  rec1  rec2  rec3  rec4  rec5  rec6  \\\n",
       "pid hid                                                                         \n",
       "201 27     [1] Trifft ueberhaupt nicht zu     0     0     0     0     1     0   \n",
       "203 60313                   [2] Skala 1-7     0     0     1     0     0     0   \n",
       "602 60                      [3] Skala 1-7     0     0     0     1     0     0   \n",
       "\n",
       "           rec7  \n",
       "pid hid          \n",
       "201 27        0  \n",
       "203 60313     0  \n",
       "602 60        0  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\", \"syear\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_2005 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})\n",
    "# create dummies for take_revenge question\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(df_2005['similar_problems'])\n",
    "\n",
    "# Join the dummy variables to the original dataframe\n",
    "df_2005 = pd.concat([df_2005, dummies], axis=1)\n",
    "# rename dummy\n",
    "df_05 = df_2005.rename(columns = {'[1] Trifft ueberhaupt nicht zu' : 'rec1' , '[2] Skala 1-7' : 'rec2' , '[3] Skala 1-7' : 'rec3' ,'[4] Skala 1-7' : 'rec4' ,'[5] Skala 1-7' : 'rec5' ,'[6] Skala 1-7' : 'rec6' ,'[7] Trifft voll zu' : 'rec7'})\n",
    "df_05 = df_05.drop(columns = [\"[-1] keine Angabe\"])\n",
    "df_05.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", \"syear\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08' ]).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2007 data\n",
    "# here left out 'xp8601' for school degree since we have it in another module also 'xp0102' : 'work_satisfaction' for the beginning\n",
    "#for outcome and all controls\n",
    "data3= pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\", \"syear\", 'xp13101' , 'xp13102', 'xp2701', 'xp7302','xp7202','xp28', 'xp3001' ,  'xp5701' , 'xp0102']).set_index(['pid', 'hid'])\n",
    "df_07 = data3.rename(columns= {'xp13101':'gender','xp13102': 'year_birth' ,'xp2701': 'turnover_intention' , 'xp7302': 'wage_lastmonth','xp7202': 'overtime','xp28': 'new_job', 'xp3001': 'reason_new_job',  'xp5701' : 'commute_distance' , \"xp0102\" : \"work_satisfaction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2007 data from work module\n",
    "\n",
    "# adapt path and merge\n",
    "hours07 = pd.read_stata(file_paths_2[2], columns=[\"pid\",\"hid\", \"syear\", \"xvebzeit\", \"xpsbil\", \"betr07\", \"xerwzeit\", \"xbilzeit\"]).set_index(['pid', 'hid'])\n",
    "work07 = hours07.rename(columns={'xvebzeit': 'working_hours', \"xpsbil\": \"school_degree\", \"betr07\": \"firmsize\", \"xerwzeit\": \"tenure\" , \"xbilzeit\" : \"years_educ\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Define Functions and mappings for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbstständig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for turnover intention: split up into binary with roughly equal value counts for simplicity: might change that later to categories\n",
    "satisfaction_mapping = {\n",
    "    '[0] 0 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[1] 1 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[2] 2 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[3] 3 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[4] 4 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[5] 5 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[6] 6 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[7] 7 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[8] 8 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[9] 9 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[10] 10 Zufrieden: Skala 0-Niedrig bis 10-Hoc': 1,\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention robustness check: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "# mapping for binary reciprocity measure\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 2:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group\n",
    "\n",
    "## function for recoding values and dropping missing\n",
    "\n",
    "def recode_categoricals(inputdf,rc_cardinal = 0):\n",
    "    \"\"\"\n",
    "        merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode job satisfaction\n",
    "    merged['work_satisfaction']= merged['work_satisfaction'].map(satisfaction_mapping)\n",
    "    # recode turnover intention variable\n",
    "    if rc_cardinal == 1:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping_cardinal)\n",
    "    else:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping)\n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output\n",
    "\n",
    "# Merge dataframes: a bit tough to read as its nested, merges 4 dataframes: 2005,2006,2007 and 2007gen\n",
    "\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df,rc_cardinal).astype('int')\n",
    "\n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan) \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"turnover_intention\", \"new_job\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add Mincer Wage Regression and adds its residuals to the Dataframe\n",
    "\n",
    "def add_mincer_residuals(cleaneddata):\n",
    "    \n",
    "    df_cleaned = cleaneddata\n",
    "    # specify which columns to drop from our dataframe\n",
    "    df_mincer = cleaneddata.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup', 'age', 'commute_distance', 'recog_effort', 'working_hours', 'turnover_intention', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "    # Convert 'gender' and 'sector' columns to categorical data type\n",
    "    for col in ['gender']:\n",
    "        df_mincer[col] = df_mincer[col].astype('category')\n",
    "    df_mincer = df_mincer.dropna()\n",
    "    # Define the dependent variable\n",
    "    y = df_mincer['wage_lastmonth']\n",
    "    # Define the independent variables\n",
    "    X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "    # Add a constant term to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the Mincer wage regression model\n",
    "    mincer_model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Create a new column in the dataframe with the same name as the residuals array/ delete relative wage entries\n",
    "    df_cleaned['mincer_residuals'] = None\n",
    "    # Match the rows of the dataframe with the values in the residuals array using the index\n",
    "    df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlcude People who switched their jobs in 2006-2007 with 2006 controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_jobchangers(data07,onlynewemployer=False,worksatisfaction=False,rc_cardinal = False):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "            df: finished 2007 dataframe\n",
    "            onlynewemployer: optional argument: If True only includes those who switched jobs to a new employer\n",
    "            worksatisfaction: if True drops observations where job satisfaction between 2006 and 2007 changed to check for our Assumption\n",
    "    \n",
    "    \"\"\"\n",
    "    df = data07\n",
    "    # read in cleaned 2006 dataset:\n",
    "    #  change path here : Maxie: '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv'\n",
    "    #                     Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv'  \n",
    "    observations_2006 = pd.read_csv('C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv')\n",
    "    # some initial datamanagement\n",
    "    observations_2006.reset_index(inplace=True)\n",
    "    observations_2006.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "    observations_2006.drop(columns=observations_2006.filter(regex='^syear').columns, inplace=True)\n",
    "    observations_2006.drop(\"index\",axis=1 ,inplace =True)\n",
    "    # If cardinal turnover intentions are coded to 100\n",
    "    if rc_cardinal == True:\n",
    "        observations_2006[\"turnover_intention\"] = 100\n",
    "    # drop s year columns from both dataframes\n",
    "    df.drop(columns=df.filter(regex='^syear').columns, inplace=True)\n",
    "    \n",
    "    # optional worksatisfaction robustness check\n",
    "    if worksatisfaction == True:\n",
    "        satisfaction = pd.DataFrame(df['work_satisfaction']).join(pd.DataFrame(observations_2006['work_satisfaction']), on = [\"pid\", \"hid\"], lsuffix = \"_07\" , rsuffix =\"_06\")\n",
    "        ID_keep_satis = satisfaction[satisfaction[\"work_satisfaction_07\"] == satisfaction[\"work_satisfaction_06\"]].index\n",
    "        df.drop(df[~df.index.isin(ID_keep_satis)].index, inplace=True)\n",
    "    \n",
    "    # create list of IDs of people who switched to a new employer in the last year in 2007\n",
    "    if onlynewemployer == True:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1) & (df[\"reason_new_job\"] == '[3] Stelle bei neuen Arbeitgeber')].index\n",
    "    # if True drops people whose work satisfaction changed between 2006 and 2007\n",
    "    else:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1)].index\n",
    "    \n",
    "    # drop all who changed their job in 2007 dataframe and replace 2007 controls with 2006 controls\n",
    "    df.drop(df[df[\"new_job\"] == 1].index, inplace = True)\n",
    "    observations_2006.drop(observations_2006[~observations_2006.index.isin(IDs_tokeep)].index, inplace=True)\n",
    "    #concat both dataframes\n",
    "    dfconcat = pd.concat([df,observations_2006])\n",
    "    \n",
    "    return dfconcat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis\n",
    "#### 1.Probit Regression\n",
    "\n",
    "- Probit Estimation: TurnoverIntention_{2005} = Constant + Neg-Rec + Unfair + Rec X Unfair + Controls + Error\n",
    "\n",
    "- As the measure for unfair treatment in the first regression i first used recog_effort -> decide for one later\n",
    "    - \"When I consider all my accomplishments and efforts, the recognition of I've received seems about right to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS = df_OLS.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "df_OLS[\"recXrecog_effort\"] = df_OLS[\"recog_effort\"] * df_OLS[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_OLS.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit\n",
    "# Define Outcome variable\n",
    "Y = df_OLS[\"turnover_intention\"]\n",
    "# define X matrix\n",
    "X = df_OLS.drop(columns=[\"turnover_intention\"])\n",
    "# add constant \n",
    "X = sm.add_constant(X)\n",
    "# build model\n",
    "model = Probit(Y, X.astype(float))\n",
    "# estimate model\n",
    "probit_model = model.fit()\n",
    "# print summary table\n",
    "probit_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. OLS\n",
    "Now, instead of using a probit model, we use OLS.  linear probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Checks\n",
    "\n",
    "\n",
    "#### 1. Recode turnover variable into cardinal variable: Optional argument in recode_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-266-d2286a43623d>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mincer[col] = df_mincer[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.229</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.227</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   391.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:51:29</td>      <th>  Log-Likelihood:    </th> <td> -29024.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5962</td>       <th>  AIC:               </th> <td>5.807e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5949</td>       <th>  BIC:               </th> <td>5.816e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    8.1098</td> <td>    0.574</td> <td>   14.140</td> <td> 0.000</td> <td>    6.986</td> <td>    9.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    9.5588</td> <td>    2.093</td> <td>    4.568</td> <td> 0.000</td> <td>    5.458</td> <td>   13.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.2002</td> <td>    0.060</td> <td>   -3.353</td> <td> 0.001</td> <td>   -0.317</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.4913</td> <td>    0.151</td> <td>   -3.256</td> <td> 0.001</td> <td>   -0.787</td> <td>   -0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.9219</td> <td>    0.050</td> <td>  -18.468</td> <td> 0.000</td> <td>   -1.020</td> <td>   -0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    1.2507</td> <td>    0.149</td> <td>    8.406</td> <td> 0.000</td> <td>    0.959</td> <td>    1.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    3.1980</td> <td>    0.970</td> <td>    3.297</td> <td> 0.001</td> <td>    1.297</td> <td>    5.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0401</td> <td>    0.010</td> <td>    4.108</td> <td> 0.000</td> <td>    0.021</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.8916</td> <td>    0.363</td> <td>    2.454</td> <td> 0.014</td> <td>    0.179</td> <td>    1.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    6.9338</td> <td>    0.460</td> <td>   15.071</td> <td> 0.000</td> <td>    6.032</td> <td>    7.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.2529</td> <td>    0.020</td> <td>   12.832</td> <td> 0.000</td> <td>    0.214</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>  -23.7772</td> <td>    1.695</td> <td>  -14.026</td> <td> 0.000</td> <td>  -27.100</td> <td>  -20.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0019</td> <td>    0.001</td> <td>   -3.117</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.6603</td> <td>    0.604</td> <td>   -1.093</td> <td> 0.274</td> <td>   -1.844</td> <td>    0.524</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>512.954</td> <th>  Durbin-Watson:     </th> <td>   1.262</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 656.513</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.812</td>  <th>  Prob(JB):          </th> <td>2.75e-143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.062</td>  <th>  Cond. No.          </th> <td>1.18e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 3.73e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.229\n",
       "Model:                            OLS   Adj. R-squared:                  0.227\n",
       "Method:                 Least Squares   F-statistic:                     391.6\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:51:29   Log-Likelihood:                -29024.\n",
       "No. Observations:                5962   AIC:                         5.807e+04\n",
       "Df Residuals:                    5949   BIC:                         5.816e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    8.1098      0.574     14.140      0.000       6.986       9.234\n",
       "recog_effort             9.5588      2.093      4.568      0.000       5.458      13.660\n",
       "working_hours           -0.2002      0.060     -3.353      0.001      -0.317      -0.083\n",
       "firmsize                -0.4913      0.151     -3.256      0.001      -0.787      -0.196\n",
       "tenure                  -0.9219      0.050    -18.468      0.000      -1.020      -0.824\n",
       "years_educ               1.2507      0.149      8.406      0.000       0.959       1.542\n",
       "gender                   3.1980      0.970      3.297      0.001       1.297       5.099\n",
       "commute_distance         0.0401      0.010      4.108      0.000       0.021       0.059\n",
       "avg_rec                  0.8916      0.363      2.454      0.014       0.179       1.604\n",
       "age                      6.9338      0.460     15.071      0.000       6.032       7.835\n",
       "potential_experience     0.2529      0.020     12.832      0.000       0.214       0.292\n",
       "age_squared            -23.7772      1.695    -14.026      0.000     -27.100     -20.455\n",
       "mincer_residuals        -0.0019      0.001     -3.117      0.002      -0.003      -0.001\n",
       "recXrecog_effort        -0.6603      0.604     -1.093      0.274      -1.844       0.524\n",
       "==============================================================================\n",
       "Omnibus:                      512.954   Durbin-Watson:                   1.262\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              656.513\n",
       "Skew:                           0.812   Prob(JB):                    2.75e-143\n",
       "Kurtosis:                       3.062   Cond. No.                     1.18e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 3.73e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional argument ==1\n",
    "dfrc1 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal=1)),rc_cardinal=True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_cardinal = dfrc1.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth','rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "dfrc_cardinal[\"recXrecog_effort\"] = dfrc_cardinal[\"recog_effort\"] * dfrc_cardinal[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_cardinal = dfrc_cardinal.dropna()\n",
    "\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_cardinal[\"turnover_intention\"]\n",
    "X = dfrc_cardinal.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not change much. Coefficient on the interaction term becomes insignificant.\n",
    "\n",
    "#### 2. Different Reciprocity Specifications\n",
    "\n",
    "    1. Split into binary: High/ Low reciprocal\n",
    "    2. create dummies for each category and estimate regression for those\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-266-d2286a43623d>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mincer[col] = df_mincer[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   580.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:51:17</td>      <th>  Log-Likelihood:    </th> <td> -3366.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5407</td>       <th>  AIC:               </th> <td>   6759.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5394</td>       <th>  BIC:               </th> <td>   6845.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>    0.0407</td> <td>    0.008</td> <td>    5.420</td> <td> 0.000</td> <td>    0.026</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>           <td>    0.1356</td> <td>    0.030</td> <td>    4.455</td> <td> 0.000</td> <td>    0.076</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>          <td>   -0.0010</td> <td>    0.001</td> <td>   -1.134</td> <td> 0.257</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>               <td>   -0.0120</td> <td>    0.002</td> <td>   -5.347</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>                 <td>   -0.0087</td> <td>    0.001</td> <td>  -11.563</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>             <td>    0.0195</td> <td>    0.002</td> <td>    8.872</td> <td> 0.000</td> <td>    0.015</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                 <td>    0.0507</td> <td>    0.014</td> <td>    3.515</td> <td> 0.000</td> <td>    0.022</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>       <td>    0.0004</td> <td>    0.000</td> <td>    3.066</td> <td> 0.002</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>             <td>    0.1265</td> <td>    0.020</td> <td>    6.488</td> <td> 0.000</td> <td>    0.088</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                    <td>    0.0446</td> <td>    0.006</td> <td>    7.274</td> <td> 0.000</td> <td>    0.033</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th>   <td>    0.0009</td> <td>    0.000</td> <td>    3.318</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>            <td>   -0.1158</td> <td>    0.022</td> <td>   -5.225</td> <td> 0.000</td> <td>   -0.159</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>       <td>-1.395e-05</td> <td> 9.21e-06</td> <td>   -1.516</td> <td> 0.130</td> <td> -3.2e-05</td> <td> 4.09e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binaryrecXrecog_effort</th> <td>   -0.0299</td> <td>    0.033</td> <td>   -0.894</td> <td> 0.372</td> <td>   -0.095</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>91546.626</td> <th>  Durbin-Watson:     </th> <td>   1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 402.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.045</td>   <th>  Prob(JB):          </th> <td>4.28e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.667</td>   <th>  Cond. No.          </th> <td>8.22e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 7.33e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.186\n",
       "Model:                            OLS   Adj. R-squared:                  0.184\n",
       "Method:                 Least Squares   F-statistic:                     580.9\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:51:17   Log-Likelihood:                -3366.7\n",
       "No. Observations:                5407   AIC:                             6759.\n",
       "Df Residuals:                    5394   BIC:                             6845.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                      0.0407      0.008      5.420      0.000       0.026       0.055\n",
       "recog_effort               0.1356      0.030      4.455      0.000       0.076       0.195\n",
       "working_hours             -0.0010      0.001     -1.134      0.257      -0.003       0.001\n",
       "firmsize                  -0.0120      0.002     -5.347      0.000      -0.016      -0.008\n",
       "tenure                    -0.0087      0.001    -11.563      0.000      -0.010      -0.007\n",
       "years_educ                 0.0195      0.002      8.872      0.000       0.015       0.024\n",
       "gender                     0.0507      0.014      3.515      0.000       0.022       0.079\n",
       "commute_distance           0.0004      0.000      3.066      0.002       0.000       0.001\n",
       "binary_rec                 0.1265      0.020      6.488      0.000       0.088       0.165\n",
       "age                        0.0446      0.006      7.274      0.000       0.033       0.057\n",
       "potential_experience       0.0009      0.000      3.318      0.001       0.000       0.001\n",
       "age_squared               -0.1158      0.022     -5.225      0.000      -0.159      -0.072\n",
       "mincer_residuals       -1.395e-05   9.21e-06     -1.516      0.130    -3.2e-05    4.09e-06\n",
       "binaryrecXrecog_effort    -0.0299      0.033     -0.894      0.372      -0.095       0.036\n",
       "==============================================================================\n",
       "Omnibus:                    91546.626   Durbin-Watson:                   1.837\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              402.345\n",
       "Skew:                          -0.045   Prob(JB):                     4.28e-88\n",
       "Kurtosis:                       1.667   Cond. No.                     8.22e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 7.33e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1 . Split up from when average bigger than 3\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_binary = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth','avg_rec', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "# add interaction term\n",
    "dfrc_binary[\"binaryrecXrecog_effort\"] = dfrc_binary[\"recog_effort\"] * dfrc_binary[\"binary_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_binary = dfrc_binary.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_binary[\"turnover_intention\"]\n",
    "X = dfrc_binary.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### also does not change a lot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating dummies and include 7 interaction terms : Decide for one of the 3 questions for simplicity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When treating the categories as numerical: we are making assumptions about the differences between the scale items. If those distances can be considered equal at all levels, then it is reasonable to treat reciprocity as numerical. (i.e a one unit change from 1 to 2 is equivalent to a one unit change from 6 to 7)\n",
    "\n",
    "\n",
    "For dummy coding we need to exclude one of the categories in the dataframe and make it the reference category: This will be the lowest level of reciprocity 1 and will be coded as zero.  so rec2 rec3 rec4 , ... and their interaction terms with unfair treatment stay in the regression.\n",
    "\n",
    "rec2 is then interpreted as the mean of turnover intentions in the rec2 group - the mean of turnover intentions in the rec1 group (reference group) holding everything else constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-266-d2286a43623d>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mincer[col] = df_mincer[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   532.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:50:52</td>      <th>  Log-Likelihood:    </th> <td> -3471.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5918</td>       <th>  AIC:               </th> <td>   6991.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5894</td>       <th>  BIC:               </th> <td>   7152.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    23</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0300</td> <td>    0.007</td> <td>    4.528</td> <td> 0.000</td> <td>    0.017</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2</th>                 <td>    0.1488</td> <td>    0.021</td> <td>    7.129</td> <td> 0.000</td> <td>    0.108</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3</th>                 <td>    0.1379</td> <td>    0.023</td> <td>    6.092</td> <td> 0.000</td> <td>    0.094</td> <td>    0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4</th>                 <td>    0.1315</td> <td>    0.024</td> <td>    5.574</td> <td> 0.000</td> <td>    0.085</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5</th>                 <td>    0.1457</td> <td>    0.028</td> <td>    5.172</td> <td> 0.000</td> <td>    0.091</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6</th>                 <td>    0.1809</td> <td>    0.040</td> <td>    4.467</td> <td> 0.000</td> <td>    0.102</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7</th>                 <td>    0.0610</td> <td>    0.042</td> <td>    1.463</td> <td> 0.144</td> <td>   -0.021</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1160</td> <td>    0.026</td> <td>    4.501</td> <td> 0.000</td> <td>    0.065</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0016</td> <td>    0.001</td> <td>   -2.074</td> <td> 0.038</td> <td>   -0.003</td> <td>-8.93e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0107</td> <td>    0.002</td> <td>   -5.258</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0101</td> <td>    0.001</td> <td>  -14.094</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0207</td> <td>    0.002</td> <td>   10.009</td> <td> 0.000</td> <td>    0.017</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0519</td> <td>    0.013</td> <td>    3.847</td> <td> 0.000</td> <td>    0.025</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>  9.4e-05</td> <td>    3.894</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work_satisfaction</th>    <td>    0.1888</td> <td>    0.013</td> <td>   14.569</td> <td> 0.000</td> <td>    0.163</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0316</td> <td>    0.006</td> <td>    5.718</td> <td> 0.000</td> <td>    0.021</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0006</td> <td>    0.000</td> <td>    2.592</td> <td> 0.010</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.0858</td> <td>    0.020</td> <td>   -4.397</td> <td> 0.000</td> <td>   -0.124</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>  -7.9e-06</td> <td>  8.7e-06</td> <td>   -0.908</td> <td> 0.364</td> <td>-2.49e-05</td> <td> 9.15e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2_X_recog_effort</th>  <td>   -0.0578</td> <td>    0.035</td> <td>   -1.671</td> <td> 0.095</td> <td>   -0.126</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3_X_recog_effort</th>  <td>   -0.0143</td> <td>    0.036</td> <td>   -0.396</td> <td> 0.692</td> <td>   -0.085</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4_X_recog_effort</th>  <td>   -0.0888</td> <td>    0.039</td> <td>   -2.303</td> <td> 0.021</td> <td>   -0.164</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5_X_recog_effort</th>  <td>   -0.0688</td> <td>    0.047</td> <td>   -1.467</td> <td> 0.142</td> <td>   -0.161</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6_X_recog_effort</th>  <td>   -0.1051</td> <td>    0.064</td> <td>   -1.642</td> <td> 0.101</td> <td>   -0.231</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7_X_recog_effort</th>  <td>   -0.0332</td> <td>    0.065</td> <td>   -0.511</td> <td> 0.609</td> <td>   -0.161</td> <td>    0.094</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2943.247</td> <th>  Durbin-Watson:     </th> <td>   1.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 334.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.141</td>  <th>  Prob(JB):          </th> <td>2.63e-73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.870</td>  <th>  Cond. No.          </th> <td>6.95e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.06e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.239\n",
       "Model:                            OLS   Adj. R-squared:                  0.236\n",
       "Method:                 Least Squares   F-statistic:                     532.8\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:50:52   Log-Likelihood:                -3471.6\n",
       "No. Observations:                5918   AIC:                             6991.\n",
       "Df Residuals:                    5894   BIC:                             7152.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0300      0.007      4.528      0.000       0.017       0.043\n",
       "rec2                     0.1488      0.021      7.129      0.000       0.108       0.190\n",
       "rec3                     0.1379      0.023      6.092      0.000       0.094       0.182\n",
       "rec4                     0.1315      0.024      5.574      0.000       0.085       0.178\n",
       "rec5                     0.1457      0.028      5.172      0.000       0.091       0.201\n",
       "rec6                     0.1809      0.040      4.467      0.000       0.102       0.260\n",
       "rec7                     0.0610      0.042      1.463      0.144      -0.021       0.143\n",
       "recog_effort             0.1160      0.026      4.501      0.000       0.065       0.167\n",
       "working_hours           -0.0016      0.001     -2.074      0.038      -0.003   -8.93e-05\n",
       "firmsize                -0.0107      0.002     -5.258      0.000      -0.015      -0.007\n",
       "tenure                  -0.0101      0.001    -14.094      0.000      -0.011      -0.009\n",
       "years_educ               0.0207      0.002     10.009      0.000       0.017       0.025\n",
       "gender                   0.0519      0.013      3.847      0.000       0.025       0.078\n",
       "commute_distance         0.0004    9.4e-05      3.894      0.000       0.000       0.001\n",
       "work_satisfaction        0.1888      0.013     14.569      0.000       0.163       0.214\n",
       "age                      0.0316      0.006      5.718      0.000       0.021       0.042\n",
       "potential_experience     0.0006      0.000      2.592      0.010       0.000       0.001\n",
       "age_squared             -0.0858      0.020     -4.397      0.000      -0.124      -0.048\n",
       "mincer_residuals       -7.9e-06    8.7e-06     -0.908      0.364   -2.49e-05    9.15e-06\n",
       "rec2_X_recog_effort     -0.0578      0.035     -1.671      0.095      -0.126       0.010\n",
       "rec3_X_recog_effort     -0.0143      0.036     -0.396      0.692      -0.085       0.056\n",
       "rec4_X_recog_effort     -0.0888      0.039     -2.303      0.021      -0.164      -0.013\n",
       "rec5_X_recog_effort     -0.0688      0.047     -1.467      0.142      -0.161       0.023\n",
       "rec6_X_recog_effort     -0.1051      0.064     -1.642      0.101      -0.231       0.020\n",
       "rec7_X_recog_effort     -0.0332      0.065     -0.511      0.609      -0.161       0.094\n",
       "==============================================================================\n",
       "Omnibus:                     2943.247   Durbin-Watson:                   1.769\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              334.242\n",
       "Skew:                          -0.141   Prob(JB):                     2.63e-73\n",
       "Kurtosis:                       1.870   Cond. No.                     6.95e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.06e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1\n",
    "dfrc2 = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_dummy = dfrc2.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay','year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'avg_rec','rec1'])\n",
    "# add interaction terms\n",
    "for col in ['rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7']:\n",
    "    dfrc_dummy = dfrc_dummy.assign(**{col + '_X_recog_effort': dfrc_dummy[col] * dfrc_dummy['recog_effort']})\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_dummy = dfrc_dummy.dropna()\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_dummy[\"turnover_intention\"]\n",
    "X = dfrc_dummy.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness Check : Drop people whose job satisfaction level changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-266-d2286a43623d>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mincer[col] = df_mincer[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   597.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:50:40</td>      <th>  Log-Likelihood:    </th> <td> -2927.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  4732</td>       <th>  AIC:               </th> <td>   5882.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  4719</td>       <th>  BIC:               </th> <td>   5966.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0534</td> <td>    0.008</td> <td>    6.987</td> <td> 0.000</td> <td>    0.038</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1912</td> <td>    0.033</td> <td>    5.707</td> <td> 0.000</td> <td>    0.126</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0013</td> <td>    0.001</td> <td>   -1.440</td> <td> 0.150</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0104</td> <td>    0.002</td> <td>   -4.341</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0095</td> <td>    0.001</td> <td>  -11.565</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0209</td> <td>    0.002</td> <td>    8.946</td> <td> 0.000</td> <td>    0.016</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0514</td> <td>    0.015</td> <td>    3.316</td> <td> 0.001</td> <td>    0.021</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.339</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0237</td> <td>    0.006</td> <td>    4.072</td> <td> 0.000</td> <td>    0.012</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0546</td> <td>    0.006</td> <td>    8.637</td> <td> 0.000</td> <td>    0.042</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0013</td> <td>    0.000</td> <td>    4.970</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1535</td> <td>    0.023</td> <td>   -6.806</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.011e-05</td> <td> 1.01e-05</td> <td>   -1.000</td> <td> 0.317</td> <td>-2.99e-05</td> <td>  9.7e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0237</td> <td>    0.010</td> <td>   -2.432</td> <td> 0.015</td> <td>   -0.043</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11899.440</td> <th>  Durbin-Watson:     </th> <td>   1.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 334.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.098</td>   <th>  Prob(JB):          </th> <td>2.88e-73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.713</td>   <th>  Cond. No.          </th> <td>9.87e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 4.18e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.192\n",
       "Model:                            OLS   Adj. R-squared:                  0.190\n",
       "Method:                 Least Squares   F-statistic:                     597.5\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:50:40   Log-Likelihood:                -2927.9\n",
       "No. Observations:                4732   AIC:                             5882.\n",
       "Df Residuals:                    4719   BIC:                             5966.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0534      0.008      6.987      0.000       0.038       0.068\n",
       "recog_effort             0.1912      0.033      5.707      0.000       0.126       0.257\n",
       "working_hours           -0.0013      0.001     -1.440      0.150      -0.003       0.000\n",
       "firmsize                -0.0104      0.002     -4.341      0.000      -0.015      -0.006\n",
       "tenure                  -0.0095      0.001    -11.565      0.000      -0.011      -0.008\n",
       "years_educ               0.0209      0.002      8.946      0.000       0.016       0.026\n",
       "gender                   0.0514      0.015      3.316      0.001       0.021       0.082\n",
       "commute_distance         0.0004      0.000      3.339      0.001       0.000       0.001\n",
       "avg_rec                  0.0237      0.006      4.072      0.000       0.012       0.035\n",
       "age                      0.0546      0.006      8.637      0.000       0.042       0.067\n",
       "potential_experience     0.0013      0.000      4.970      0.000       0.001       0.002\n",
       "age_squared             -0.1535      0.023     -6.806      0.000      -0.198      -0.109\n",
       "mincer_residuals     -1.011e-05   1.01e-05     -1.000      0.317   -2.99e-05     9.7e-06\n",
       "recXrecog_effort        -0.0237      0.010     -2.432      0.015      -0.043      -0.005\n",
       "==============================================================================\n",
       "Omnibus:                    11899.440   Durbin-Watson:                   1.765\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              334.062\n",
       "Skew:                          -0.098   Prob(JB):                     2.88e-73\n",
       "Kurtosis:                       1.713   Cond. No.                     9.87e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 4.18e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfworksatisfation = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)),worksatisfaction = True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_rc_ws = dfworksatisfation.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month \"\"\"\n",
    "# add interaction term\n",
    "df_rc_ws[\"recXrecog_effort\"] = df_rc_ws[\"recog_effort\"] * df_rc_ws[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_rc_ws.dropna(inplace=True)\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = df_rc_ws[\"turnover_intention\"]\n",
    "X = df_rc_ws.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Check \n",
    "\n",
    "Avg reciprocity measure over years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-266-d2286a43623d>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mincer[col] = df_mincer[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   861.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 09 Jan 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:50:21</td>      <th>  Log-Likelihood:    </th> <td> -3631.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5962</td>       <th>  AIC:               </th> <td>   7289.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5949</td>       <th>  BIC:               </th> <td>   7376.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.0531</td> <td>    0.007</td> <td>    7.866</td> <td> 0.000</td> <td>    0.040</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1604</td> <td>    0.032</td> <td>    5.020</td> <td> 0.000</td> <td>    0.098</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0012</td> <td>    0.001</td> <td>   -1.504</td> <td> 0.133</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0112</td> <td>    0.002</td> <td>   -5.348</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0104</td> <td>    0.001</td> <td>  -14.357</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0206</td> <td>    0.002</td> <td>    9.830</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0491</td> <td>    0.014</td> <td>    3.573</td> <td> 0.000</td> <td>    0.022</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td> 9.78e-05</td> <td>    3.888</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0553</td> <td>    0.006</td> <td>    9.846</td> <td> 0.000</td> <td>    0.044</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0013</td> <td>    0.000</td> <td>    5.486</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1520</td> <td>    0.020</td> <td>   -7.648</td> <td> 0.000</td> <td>   -0.191</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.565e-05</td> <td> 8.84e-06</td> <td>   -1.770</td> <td> 0.077</td> <td> -3.3e-05</td> <td> 1.67e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0260</td> <td>    0.006</td> <td>    4.403</td> <td> 0.000</td> <td>    0.014</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0173</td> <td>    0.009</td> <td>   -1.853</td> <td> 0.064</td> <td>   -0.036</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5582.654</td> <th>  Durbin-Watson:     </th> <td>   1.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 390.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.165</td>  <th>  Prob(JB):          </th> <td>1.96e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.791</td>  <th>  Cond. No.          </th> <td>1.42e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 2.57e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.204\n",
       "Model:                            OLS   Adj. R-squared:                  0.203\n",
       "Method:                 Least Squares   F-statistic:                     861.3\n",
       "Date:                Mon, 09 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:50:21   Log-Likelihood:                -3631.3\n",
       "No. Observations:                5962   AIC:                             7289.\n",
       "Df Residuals:                    5949   BIC:                             7376.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.0531      0.007      7.866      0.000       0.040       0.066\n",
       "recog_effort             0.1604      0.032      5.020      0.000       0.098       0.223\n",
       "working_hours           -0.0012      0.001     -1.504      0.133      -0.003       0.000\n",
       "firmsize                -0.0112      0.002     -5.348      0.000      -0.015      -0.007\n",
       "tenure                  -0.0104      0.001    -14.357      0.000      -0.012      -0.009\n",
       "years_educ               0.0206      0.002      9.830      0.000       0.016       0.025\n",
       "gender                   0.0491      0.014      3.573      0.000       0.022       0.076\n",
       "commute_distance         0.0004   9.78e-05      3.888      0.000       0.000       0.001\n",
       "age                      0.0553      0.006      9.846      0.000       0.044       0.066\n",
       "potential_experience     0.0013      0.000      5.486      0.000       0.001       0.002\n",
       "age_squared             -0.1520      0.020     -7.648      0.000      -0.191      -0.113\n",
       "mincer_residuals     -1.565e-05   8.84e-06     -1.770      0.077    -3.3e-05    1.67e-06\n",
       "avg_rec                  0.0260      0.006      4.403      0.000       0.014       0.038\n",
       "recXrecog_effort        -0.0173      0.009     -1.853      0.064      -0.036       0.001\n",
       "==============================================================================\n",
       "Omnibus:                     5582.654   Durbin-Watson:                   1.756\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              390.089\n",
       "Skew:                          -0.165   Prob(JB):                     1.96e-85\n",
       "Kurtosis:                       1.791   Cond. No.                     1.42e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 2.57e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS_avg = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS_avg = df_OLS_avg.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction','avg_rec'])\n",
    "# Load avg reciprocity measures over the years\n",
    "# Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/rec_avgyears.csv'  \n",
    "avg_reciprocity = pd.read_csv('C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/rec_avgyears.csv')\n",
    "avg_reciprocity.reset_index(inplace=True)\n",
    "avg_reciprocity.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "avg_reciprocity.drop(\"index\",axis=1 ,inplace =True)\n",
    "\n",
    "df_avg_years = pd.merge(df_OLS_avg,avg_reciprocity, on=[\"pid\",\"hid\"])\n",
    "# add interaction term\n",
    "df_avg_years[\"recXrecog_effort\"] = df_avg_years[\"recog_effort\"] * df_avg_years[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_avg_years.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = df_avg_years[\"turnover_intention\"]\n",
    "X = df_avg_years.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit(cov_type= \"HC3\")\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also does not change much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df7d47ce4f33ec65ca12ba7db2796b6cbc8620dcf8689ec69de714ca1293d9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
