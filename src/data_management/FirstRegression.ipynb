{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Regression (Turnover intention ~ unfair treatment x neg. reciprocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in SOEP Data:\n",
    "- vp : 2005 data : main variables of interest: questions on negative reciprocity\n",
    "- wp: 2006 data : main variables of interest: question on perceived recognition for work\n",
    "- xp: 2007 data : main variables of interest: turnover intentions, controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"/Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\", \"syear\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_05 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", \"syear\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08' ]).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2007 data\n",
    "# here left out 'xp8601' for school degree since we have it in another module also 'xp0102' : 'work_satisfaction' for the beginning\n",
    "#for outcome and all controls\n",
    "data3= pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\", \"syear\", 'xp13101' , 'xp13102', 'xp2701', 'xp7302','xp7202','xp28', 'xp3001' ,  'xp5701']).set_index(['pid', 'hid'])\n",
    "df_07 = data3.rename(columns= {'xp13101':'gender','xp13102': 'year_birth' ,'xp2701': 'turnover_intention' , 'xp7302': 'wage_lastmonth','xp7202': 'overtime','xp28': 'new_job', 'xp3001': 'reason_new_job',  'xp5701' : 'commute_distance07'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2007 data from work module\n",
    "\n",
    "# adapt path and merge\n",
    "hours07 = pd.read_stata(file_paths_2[2], columns=[\"pid\",\"hid\", \"syear\", \"xvebzeit\", \"xpsbil\", \"nace07\", \"betr07\", \"xerwzeit\", \"xbilzeit\"]).set_index(['pid', 'hid'])\n",
    "work07 = hours07.rename(columns={'xvebzeit': 'working_hours', \"xpsbil\": \"school_degree\", \"nace07\": \"sector\", \"betr07\": \"firmsize\", \"xerwzeit\": \"tenure\" , \"xbilzeit\" : \"years_educ\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Mappings for categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbstständig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for turnover intention: split up into binary with roughly equal value counts for simplicity: might change that later to categories\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention robustness check: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for sectors: only to easier remove negatives\n",
    "sector_map = {\n",
    "    \"[1] Landwirtschaft und  Jagd\": 1,\n",
    "    \"[2] Forstwirtschaft\": 2,\n",
    "    \"[5] Fischerei und Fischzucht\": 5,\n",
    "    \"[10] Kohlenbergbau, Torfgewinnung\": 10,\n",
    "    \"[11] Gewinnung von Erdöl und Erdgas, Erbringung damit verbundener Dienstleistungen\": 11,\n",
    "    \"[12] Bergbau auf Uran- und Thoriumerze\": 12,\n",
    "    \"[13] Erzbergbau\": 13,\n",
    "    \"[14] Gewinnung von Steinen und Erden, sonstiger Bergbau\": 14,\n",
    "    \"[15] Herstellung von Nahrungs- und Futtermitteln sowie Getränken\": 15,\n",
    "    \"[16] Tabakverarbeitung\": 16,\n",
    "    \"[17] Herstellung von Textilien\": 17,\n",
    "    \"[18] Herstellung von Bekleidung\": 18,\n",
    "    \"[19] Herstellung von Leder und Lederwaren\": 19,\n",
    "    \"[20] Herstellung von Holz sowie Holz-, Kork- und Flechtwaren (ohne Herstellung von Möbeln)\": 20,\n",
    "    \"[21] Herstellung von Papier, Pappe und Waren daraus\": 21,\n",
    "    '[22] Herstellung von Verlags- und Druckerzeugnissen,  Vervielfältigung von bespielten Ton-, Bild- und Datenträgern': 22,\n",
    "    \"[23] Kokerei, Mineralölverarbeitung, Herstellung und Verarbeitung von Spalt- und Brutstoffen\": 23,\n",
    "    \"[24] Herstellung von chemischen Erzeugnissen\": 24,\n",
    "    \"[25] Herstellung von Gummi- und Kunststoffwaren\": 25,\n",
    "    \"[26] Herstellung von Glas und Glaswaren, Keramik, Verarbeitung von Steinen und Erden\": 26,\n",
    "    \"[27] Metallerzeugung und -bearbeitung\": 27,\n",
    "    \"[28] Herstellung von Metallerzeugnissen\": 28,\n",
    "    \"[29] Maschinenbau\": 29,\n",
    "    \"[31] Herstellung von Geräten der Elektrizitätserzeugung, -verteilung u. Ä.\": 31,\n",
    "    \"[30] Herstellung von Büromaschinen, Datenverarbeitungsgeräten und -einrichtungen\": 30,\n",
    "    \"[32] Rundfunk- und Nachrichtentechnik\": 32,\n",
    "    \"[33] Medizin-, Mess-, Steuer- und Regelungstechnik, Optik, Herstellung von Uhren\": 33,\n",
    "    \"[34] Herstellung von Kraftwagen und Kraftwagenteilen\": 34,\n",
    "    \"[35] Sonstiger Fahrzeugbau\": 35,\n",
    "    \"[36] Herstellung von Möbeln, Schmuck, Musikinstrumenten, Sportgeräten, Spielwaren und sonstigen Erzeugnissen\": 36,\n",
    "    \"[37] Rückgewinnung\": 37,\n",
    "    \"[40] Energieversorgung\": 40,\n",
    "    \"[41] Wasserversorgung\": 41,\n",
    "    \"[45] Bau\": 45,\n",
    "    \"[50] Kraftfahrzeughandel; Instandhaltung und Reparatur von Kraftfahrzeugen; Tankstellen\": 50,\n",
    "    \"[51] Handelsvermittlung und Großhandel (ohne Handel mit Kraftfahrzeugen)\": 51,\n",
    "    \"[52] Einzelhandel (ohne Handel mit Kraftfahrzeugen und ohne Tankstellen); Reparatur von Gebrauchsgütern\": 52,\n",
    "    \"[55] Beherbergungs- und Gaststätten\": 55,\n",
    "    \"[60] Landverkehr; Transport in Rohrfernleitungen\": 60,\n",
    "    \"[61] Schifffahrt\": 61,\n",
    "    \"[62] Luftfahrt\": 62,\n",
    "    \"[63] Hilfs- und Nebentätigkeiten für den Verkehr; Verkehrsvermittlung\": 63,\n",
    "    \"[64] Nachrichtenübermittlung\": 64,\n",
    "    \"[65] Kreditinstitute\": 65,\n",
    "    \"[66] Versicherungen (ohne Sozialversicherung)\": 66,\n",
    "    \"[67] Mit den Kreditinstituten und Versicherungen verbundene Tätigkeiten\": 67,\n",
    "    \"[70] Grundstücks- und Wohnungswesen\": 70,\n",
    "    \"[71] Vermietung beweglicher Sachen ohne Bedienungspersonal\": 71,\n",
    "    \"[72] Datenverarbeitung und Datenbanken\": 72,\n",
    "    \"[73] Forschung und Entwicklung\": 73,\n",
    "    \"[74] Erbringung von unternehmensbezogenen Dienstleistungen\": 74,\n",
    "    \"[75] Öffentliche Verwaltung, Verteidigung, Sozialversicherung\": 75,\n",
    "    \"[80] Erziehung und Unterricht\": 80,\n",
    "    \"[85] Gesundheits-, Veterinär- und Sozialwesen\": 85,\n",
    "    \"[90] Abwasser- und Abfallbeseitigung und sonstige Entsorgung\": 90,\n",
    "    \"[91] Interessenvertretungen sowie kirchliche und sonstige Vereinigungen (ohne Sozialwesen, Kultur und Sport)\": 91,\n",
    "    \"[92] Kultur, Sport und Unterhaltung\": 92,\n",
    "    \"[93] Erbringung von sonstigen Dienstleistungen\": 93,\n",
    "    \"[95] Private Haushalte mit Hauspersonal\": 95,\t\t\t\t\t\n",
    "    \"[96] Industrie - ohne weitere Zuordnung\": 96,\t\t\t\t\t\n",
    "    \"[97] Handwerk - ohne weitere Zuordnung\": 97,\t\t\t\t\t\n",
    "    \"[98] Dienstleistungen ohne weitere Zuordnung\": 98,\t\t\t\t\t\n",
    "    \"[99] Exterritoriale Organisationen und Körperschaften\": 99,\t\t\t\t\n",
    "    \"[100] Produzierendes Gewerbe ohne w.Zuordnung\": 100,\n",
    "    \"[-1] keine Angabe\": -1,\n",
    "    '[-2] trifft nicht zu': -2, \n",
    "    \"[-3] unplausibler Wert\": -3,\n",
    "    \"[-4] unzulaessige Mehrfachantwort\": -4, \n",
    "    \"[-5] in Fragebogenversion nicht enthalten\": -5,\n",
    "    \"[-6] Fragebogenversion mit geaenderter Filterfuehrung\": -6, \n",
    "    \"[-7] nur in weniger eingeschraenkter Edition verfuegbar\": -7,\n",
    "    \"[-8] Frage in diesem Jahr nicht Teil des Frageprogramms\": -8,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_sector = {v: k for k, v in sector_map.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "# mapping for binary reciprocity measure\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 3:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categoricals to numerical to drop them easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for recoding values and dropping missing\n",
    "\n",
    "def recode_categoricals(inputdf,rc_cardinal = 0):\n",
    "    \"\"\"\n",
    "        merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode turnover intention variable\n",
    "    if rc_cardinal == 1:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping_cardinal)\n",
    "    else:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping)\n",
    "    # recode sector\n",
    "    merged['sector'] = merged['sector'].map(sector_map)\n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Dataframes and apply recoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes: a bit tough to read as its nested, merges 4 dataframes: 2005,2006,2007 and 2007gen\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df,rc_cardinal).astype('int')\n",
    "\n",
    "    # construct indsutry-relative wage\n",
    "    sector_wage_averages = recoded.groupby('sector')['wage_lastmonth'].mean()\n",
    "    recoded[\"sector_avg_wage\"] = recoded[\"sector\"].map(sector_wage_averages)\n",
    "    recoded[\"relative_wage\"] = recoded[\"wage_lastmonth\"] / recoded[\"sector_avg_wage\"]\n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan) \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"sector\"]=recoded[\"sector\"].map(reversed_mapping_sector)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"turnover_intention\", \"new_job\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop negative values for important columns:\n",
    "- convert negatives to zeros and N.a.N\n",
    "- create industry-relative wage and age"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all respondents who changed their job in the last year\n",
    "    - Option 1: drop all which changed jobs\n",
    "    - Option 2: change turnover intention of those who changed jobs and have a new employer to 1.\n",
    "        - new job + new employer -> turnover intention to 1\n",
    "        - new job + other reason and initally no turnover intention -> stays at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option1\n",
    "\n",
    "\n",
    "# Option2\n",
    "\n",
    "\"\"\" def calculate_combined(row):\n",
    "    if (row['new_job'] == 1 and row['reason_new_job'] == '[3] Stelle bei neuen Arbeitgeber') or row['turnover_intention'] == 1:\n",
    "        return 1\n",
    "    elif (row['new_job'] == 1 or row['reason_new_job'] != '[3] Stelle bei neuen Arbeitgeber') and row['turnover_intention'] == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 'invalid'\n",
    "\n",
    "dfnan = dfnan.assign(all_turnover_intentions=df1.apply(calculate_combined, axis=1))\n",
    "\"\"\"\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "- Probit Estimation: TurnoverIntention_{2005} = Constant + Neg-Rec + Unfair + Rec X Unfair + Controls + Error\n",
    "\n",
    "- As the measure for unfair treatment in the first regression i first used recog_effort -> decide for one later\n",
    "    - \"When I consider all my accomplishments and efforts, the recognition of I've received seems about right to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_71872/3373283881.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n"
     ]
    }
   ],
   "source": [
    "dfnan = merge_and_clean(df_05,df_06,df_07,work07)\n",
    "## HERE STILL DROPPED EVERYONE WHO CHANGED THEIR JOB\n",
    "dfnan.drop(index=dfnan[dfnan[\"new_job\"] == 1].index , inplace=True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_regression = dfnan.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'sector_avg_wage', 'school_degree', 'sector','overtime', 'recog_sup','wage_lastmonth', 'age'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "df_regression[\"recXrecog_effort\"] = df_regression[\"recog_effort\"] * df_regression[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mincer Regression\n",
    "wage = b0 + b1education + b2experience + b3*age + error\n",
    "\n",
    "Instead of the relative wage variable we want to use the residuals from the Mincer wage regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mincer = dfnan.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'sector_avg_wage', 'school_degree','overtime', 'recog_sup', 'age', 'commute_distance07', 'relative_wage', 'recog_effort', 'working_hours', 'turnover_intention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'gender' and 'sector' columns to categorical data type\n",
    "for col in ['gender', 'sector']:\n",
    "    df_mincer[col] = df_mincer[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mincer = df_mincer.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dependent variable\n",
    "y = df_mincer['wage_lastmonth']\n",
    "\n",
    "# Define the independent variables\n",
    "X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the Mincer wage regression model\n",
    "mincer_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary statistics of the model\n",
    "#mincer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the residuals of the model\n",
    "residuals_mincer = mincer_model.resid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to replace the column \"relative_wage\" in our regression_df with our residuals from the mincer wage regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_71872/2951685048.py:5: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_regression.loc[df_regression.index, 'relative_wage'] = residuals_mincer\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the dataframe with the same name as the residuals array\n",
    "df_regression['relative_wage'] = None\n",
    "\n",
    "# Match the rows of the dataframe with the values in the residuals array using the index\n",
    "df_regression.loc[df_regression.index, 'relative_wage'] = residuals_mincer\n",
    "\n",
    "# Rename the column \"relative_wage\" to \"mincer_residuals\"\n",
    "df_regression = df_regression.rename(columns={'relative_wage': 'mincer_residuals'})\n",
    "\n",
    "df_regression = df_regression.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592378\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>turnover_intention</td> <th>  No. Observations:  </th>   <td>  5374</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Probit</td>       <th>  Df Residuals:      </th>   <td>  5361</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>   <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td>  <th>  Pseudo R-squ.:     </th>   <td>0.1449</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:17</td>      <th>  Log-Likelihood:    </th>  <td> -3183.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th>  <td> -3723.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.825e-223</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   -0.3778</td> <td>    0.206</td> <td>   -1.838</td> <td> 0.066</td> <td>   -0.781</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.5157</td> <td>    0.093</td> <td>    5.532</td> <td> 0.000</td> <td>    0.333</td> <td>    0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0021</td> <td>    0.003</td> <td>   -0.825</td> <td> 0.409</td> <td>   -0.007</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0360</td> <td>    0.007</td> <td>   -5.459</td> <td> 0.000</td> <td>   -0.049</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0259</td> <td>    0.002</td> <td>  -10.860</td> <td> 0.000</td> <td>   -0.031</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0585</td> <td>    0.007</td> <td>    8.393</td> <td> 0.000</td> <td>    0.045</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.1471</td> <td>    0.044</td> <td>    3.366</td> <td> 0.001</td> <td>    0.061</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance07</th>   <td>    0.0012</td> <td>    0.000</td> <td>    2.903</td> <td> 0.004</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td> -4.52e-05</td> <td> 2.81e-05</td> <td>   -1.609</td> <td> 0.108</td> <td>   -0.000</td> <td> 9.85e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0762</td> <td>    0.017</td> <td>    4.614</td> <td> 0.000</td> <td>    0.044</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0017</td> <td>    0.000</td> <td>   -4.396</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0547</td> <td>    0.023</td> <td>    2.425</td> <td> 0.015</td> <td>    0.010</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0601</td> <td>    0.027</td> <td>   -2.240</td> <td> 0.025</td> <td>   -0.113</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   No. Observations:                 5374\n",
       "Model:                         Probit   Df Residuals:                     5361\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Fri, 06 Jan 2023   Pseudo R-squ.:                  0.1449\n",
       "Time:                        15:21:17   Log-Likelihood:                -3183.4\n",
       "converged:                       True   LL-Null:                       -3723.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.825e-223\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   -0.3778      0.206     -1.838      0.066      -0.781       0.025\n",
       "recog_effort             0.5157      0.093      5.532      0.000       0.333       0.698\n",
       "working_hours           -0.0021      0.003     -0.825      0.409      -0.007       0.003\n",
       "firmsize                -0.0360      0.007     -5.459      0.000      -0.049      -0.023\n",
       "tenure                  -0.0259      0.002    -10.860      0.000      -0.031      -0.021\n",
       "years_educ               0.0585      0.007      8.393      0.000       0.045       0.072\n",
       "gender                   0.1471      0.044      3.366      0.001       0.061       0.233\n",
       "commute_distance07       0.0012      0.000      2.903      0.004       0.000       0.002\n",
       "mincer_residuals      -4.52e-05   2.81e-05     -1.609      0.108      -0.000    9.85e-06\n",
       "avg_rec                  0.0762      0.017      4.614      0.000       0.044       0.109\n",
       "potential_experience    -0.0017      0.000     -4.396      0.000      -0.002      -0.001\n",
       "age_squared              0.0547      0.023      2.425      0.015       0.010       0.099\n",
       "recXrecog_effort        -0.0601      0.027     -2.240      0.025      -0.113      -0.008\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit\n",
    "# Define Outcome variable\n",
    "Y = df_regression[\"turnover_intention\"]\n",
    "# define X matrix\n",
    "X = df_regression.drop(columns=[\"turnover_intention\"])\n",
    "# add constant \n",
    "X = sm.add_constant(X)\n",
    "# build model\n",
    "model = Probit(Y, X.astype(float))\n",
    "# estimate model\n",
    "probit_model = model.fit()\n",
    "# print summary table\n",
    "probit_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of using a probit model, we use OLS.  linear probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.181</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.179</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   98.93</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 06 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>3.18e-222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>15:22:09</td>      <th>  Log-Likelihood:    </th> <td> -3360.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5374</td>       <th>  AIC:               </th> <td>   6748.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5361</td>       <th>  BIC:               </th> <td>   6834.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.4594</td> <td>    0.067</td> <td>    6.850</td> <td> 0.000</td> <td>    0.328</td> <td>    0.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1724</td> <td>    0.031</td> <td>    5.487</td> <td> 0.000</td> <td>    0.111</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0010</td> <td>    0.001</td> <td>   -1.132</td> <td> 0.258</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0122</td> <td>    0.002</td> <td>   -5.454</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0085</td> <td>    0.001</td> <td>  -10.948</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0202</td> <td>    0.002</td> <td>    8.728</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>               <td>    0.0527</td> <td>    0.015</td> <td>    3.574</td> <td> 0.000</td> <td>    0.024</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance07</th>   <td>    0.0004</td> <td>    0.000</td> <td>    2.930</td> <td> 0.003</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>-1.367e-05</td> <td> 9.38e-06</td> <td>   -1.457</td> <td> 0.145</td> <td>-3.21e-05</td> <td> 4.72e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0255</td> <td>    0.006</td> <td>    4.572</td> <td> 0.000</td> <td>    0.015</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>   -0.0004</td> <td>    0.000</td> <td>   -3.199</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>    0.0075</td> <td>    0.007</td> <td>    1.051</td> <td> 0.293</td> <td>   -0.007</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0193</td> <td>    0.009</td> <td>   -2.131</td> <td> 0.033</td> <td>   -0.037</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>119364.393</td> <th>  Durbin-Watson:     </th> <td>   1.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 410.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.039</td>   <th>  Prob(JB):          </th> <td>6.36e-90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 1.648</td>   <th>  Cond. No.          </th> <td>1.05e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.05e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.181\n",
       "Model:                            OLS   Adj. R-squared:                  0.179\n",
       "Method:                 Least Squares   F-statistic:                     98.93\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):          3.18e-222\n",
       "Time:                        15:22:09   Log-Likelihood:                -3360.9\n",
       "No. Observations:                5374   AIC:                             6748.\n",
       "Df Residuals:                    5361   BIC:                             6834.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.4594      0.067      6.850      0.000       0.328       0.591\n",
       "recog_effort             0.1724      0.031      5.487      0.000       0.111       0.234\n",
       "working_hours           -0.0010      0.001     -1.132      0.258      -0.003       0.001\n",
       "firmsize                -0.0122      0.002     -5.454      0.000      -0.017      -0.008\n",
       "tenure                  -0.0085      0.001    -10.948      0.000      -0.010      -0.007\n",
       "years_educ               0.0202      0.002      8.728      0.000       0.016       0.025\n",
       "gender                   0.0527      0.015      3.574      0.000       0.024       0.082\n",
       "commute_distance07       0.0004      0.000      2.930      0.003       0.000       0.001\n",
       "mincer_residuals     -1.367e-05   9.38e-06     -1.457      0.145   -3.21e-05    4.72e-06\n",
       "avg_rec                  0.0255      0.006      4.572      0.000       0.015       0.036\n",
       "potential_experience    -0.0004      0.000     -3.199      0.001      -0.001      -0.000\n",
       "age_squared              0.0075      0.007      1.051      0.293      -0.007       0.022\n",
       "recXrecog_effort        -0.0193      0.009     -2.131      0.033      -0.037      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                   119364.393   Durbin-Watson:                   1.831\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              410.764\n",
       "Skew:                          -0.039   Prob(JB):                     6.36e-90\n",
       "Kurtosis:                       1.648   Cond. No.                     1.05e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.05e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Checks\n",
    "\n",
    "- first some preliminary coding until Minzer and Job changes are done\n",
    "\n",
    "#### 1. Recode turnover variable into cardinal variable: Optional argument in recode_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional argument ==1\n",
    "dfrc1 = merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal=1)\n",
    "\n",
    "dfrc1.drop(index=dfrc1[dfrc1[\"new_job\"] == 1].index , inplace=True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_cardinal = dfrc1.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'sector_avg_wage', 'school_degree', 'sector','overtime', 'recog_sup','wage_lastmonth', 'age'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "dfrc_cardinal[\"recXrecog_effort\"] = dfrc_cardinal[\"recog_effort\"] * dfrc_cardinal[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_cardinal = dfrc_cardinal.dropna()\n",
    "\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_cardinal[\"turnover_intention\"]\n",
    "X = dfrc_cardinal.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "\n",
    "lpm_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not change much. Coefficient on the interaction term becomes insignificant.\n",
    "\n",
    "#### 2. Different Reciprocity Specifications\n",
    "\n",
    "    1. Split into binary: High/ Low reciprocal\n",
    "    2. create dummies for each category and estimate regression for those\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-14-70809f8ba727>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfrc_binary[\"binaryrecXrecog_effort\"] = dfrc_binary[\"recog_effort\"] * dfrc_binary[\"binary_rec\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.181</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.179</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   99.68</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 06 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>5.32e-224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>13:32:27</td>      <th>  Log-Likelihood:    </th> <td> -3391.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5422</td>       <th>  AIC:               </th> <td>   6810.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5409</td>       <th>  BIC:               </th> <td>   6896.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    12</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>    0.5108</td> <td>    0.064</td> <td>    7.960</td> <td> 0.000</td> <td>    0.385</td> <td>    0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>           <td>    0.1548</td> <td>    0.019</td> <td>    8.110</td> <td> 0.000</td> <td>    0.117</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>          <td>   -0.0014</td> <td>    0.001</td> <td>   -1.789</td> <td> 0.074</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>               <td>   -0.0121</td> <td>    0.002</td> <td>   -5.451</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>                 <td>   -0.0085</td> <td>    0.001</td> <td>  -11.045</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>             <td>    0.0202</td> <td>    0.002</td> <td>    8.859</td> <td> 0.000</td> <td>    0.016</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                 <td>    0.0595</td> <td>    0.014</td> <td>    4.225</td> <td> 0.000</td> <td>    0.032</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance07</th>     <td>    0.0004</td> <td>    0.000</td> <td>    2.827</td> <td> 0.005</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relative_wage</th>          <td>    0.0009</td> <td>    0.001</td> <td>    0.607</td> <td> 0.544</td> <td>   -0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_rec</th>             <td>    0.0709</td> <td>    0.016</td> <td>    4.516</td> <td> 0.000</td> <td>    0.040</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th>   <td>   -0.0004</td> <td>    0.000</td> <td>   -3.248</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>            <td>    0.0077</td> <td>    0.007</td> <td>    1.080</td> <td> 0.280</td> <td>   -0.006</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binaryrecXrecog_effort</th> <td>   -0.0702</td> <td>    0.026</td> <td>   -2.737</td> <td> 0.006</td> <td>   -0.120</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>113010.811</td> <th>  Durbin-Watson:     </th> <td>   1.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 415.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.045</td>   <th>  Prob(JB):          </th> <td>5.08e-91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 1.646</td>   <th>  Cond. No.          </th> <td>9.99e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.99e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.181\n",
       "Model:                            OLS   Adj. R-squared:                  0.179\n",
       "Method:                 Least Squares   F-statistic:                     99.68\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):          5.32e-224\n",
       "Time:                        13:32:27   Log-Likelihood:                -3391.9\n",
       "No. Observations:                5422   AIC:                             6810.\n",
       "Df Residuals:                    5409   BIC:                             6896.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                      0.5108      0.064      7.960      0.000       0.385       0.637\n",
       "recog_effort               0.1548      0.019      8.110      0.000       0.117       0.192\n",
       "working_hours             -0.0014      0.001     -1.789      0.074      -0.003       0.000\n",
       "firmsize                  -0.0121      0.002     -5.451      0.000      -0.016      -0.008\n",
       "tenure                    -0.0085      0.001    -11.045      0.000      -0.010      -0.007\n",
       "years_educ                 0.0202      0.002      8.859      0.000       0.016       0.025\n",
       "gender                     0.0595      0.014      4.225      0.000       0.032       0.087\n",
       "commute_distance07         0.0004      0.000      2.827      0.005       0.000       0.001\n",
       "relative_wage              0.0009      0.001      0.607      0.544      -0.002       0.004\n",
       "binary_rec                 0.0709      0.016      4.516      0.000       0.040       0.102\n",
       "potential_experience      -0.0004      0.000     -3.248      0.001      -0.001      -0.000\n",
       "age_squared                0.0077      0.007      1.080      0.280      -0.006       0.022\n",
       "binaryrecXrecog_effort    -0.0702      0.026     -2.737      0.006      -0.120      -0.020\n",
       "==============================================================================\n",
       "Omnibus:                   113010.811   Durbin-Watson:                   1.831\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              415.821\n",
       "Skew:                          -0.045   Prob(JB):                     5.08e-91\n",
       "Kurtosis:                       1.646   Cond. No.                     9.99e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.99e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1\n",
    "dfrc2 = merge_and_clean(df_05,df_06,df_07,work07,rc_rec_binary=1)\n",
    "\n",
    "dfrc_binary = dfrc2.drop(index=dfrc2[dfrc2[\"new_job\"] == 1].index , inplace=True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_binary = dfrc2.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'sector_avg_wage', 'school_degree', 'sector','overtime', 'recog_sup','wage_lastmonth', 'age', 'avg_rec'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "dfrc_binary[\"binaryrecXrecog_effort\"] = dfrc_binary[\"recog_effort\"] * dfrc_binary[\"binary_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_binary = dfrc_binary.dropna()\n",
    "\n",
    "## OLS regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y = dfrc_binary[\"turnover_intention\"]\n",
    "X = dfrc_binary.drop(columns=[\"turnover_intention\"])\n",
    "X = sm.add_constant(X)\n",
    "model = OLS(Y, X.astype(float))\n",
    "lpm_model = model.fit()\n",
    "lpm_model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### also does not change a lot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating dummies and include 7 interaction terms : Decide for one of the 3 questions for simplicity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df7d47ce4f33ec65ca12ba7db2796b6cbc8620dcf8689ec69de714ca1293d9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
