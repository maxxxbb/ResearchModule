{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome number of days sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2005 measures of reciprocity\n",
    "### 2006 controls\n",
    "### 2007 days off work in 2006\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "\n",
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_2005 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})\n",
    "# create dummies for take_revenge question\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(df_2005['take_revenge'])\n",
    "\n",
    "# Join the dummy variables to the original dataframe\n",
    "df_2005 = pd.concat([df_2005, dummies], axis=1)\n",
    "# rename dummy\n",
    "df_05 = df_2005.rename(columns = {'[1] Trifft ueberhaupt nicht zu' : 'rec1' , '[2] Skala 1-7' : 'rec2' , '[3] Skala 1-7' : 'rec3' ,'[4] Skala 1-7' : 'rec4' ,'[5] Skala 1-7' : 'rec5' ,'[6] Skala 1-7' : 'rec6' ,'[7] Trifft voll zu' : 'rec7'})\n",
    "df_05 = df_05.drop(columns = [\"[-1] keine Angabe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08' ]).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay'})\n",
    "\n",
    "\n",
    "## this next one one has to include ALL of the following columns: done\n",
    "data2 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\",\"wp12402\", \"wp12401\", \"wp5802\",  \"wp5902\", \"wp4101\", \"wp17\", \"wp1901\", \"wp0102\" ]).set_index(['pid', 'hid'])\n",
    "df_06insteadof07 = data2.rename(columns={\"wp12401\": \"gender\", \"wp12402\": \"year_birth\", \"wp5902\": \"wage_lastmonth\", \"wp4101\": \"commute_distance\", 'wp5802': 'overtime', 'wp17': 'new_job', 'wp1901': 'reason_new_job' , \"wp0102\" : \"work_satisfaction\"})\n",
    "\n",
    "# change has to include all of the following\n",
    "hours06 = pd.read_stata(file_paths_2[1], columns=[\"pid\",\"hid\",\"wvebzeit\", \"betr06\", \"wpsbil\", \"werwzeit\", \"wbilzeit\", \"nace06\"]).set_index(['pid', 'hid'])\n",
    "df_work06insteadof07 = hours06.rename(columns={'wvebzeit': 'working_hours', \"betr06\": \"firmsize\", \"wpsbil\": \"school_degree\", \"werwzeit\": \"tenure\" , \"wbilzeit\" : \"years_educ\" , \"nace06\" : \"sector\"})\n",
    "\n",
    "absent_days =  pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\",'xp10402','xp103']).set_index(['pid', 'hid'])\n",
    "absent_days.rename(columns= {\"xp10402\" : \"days_absent\" , \"xp103\" : \"long\"}, inplace = True)\n",
    "\n",
    "\n",
    "long_term = absent_days[(absent_days[\"long\"] == '[1] Einmal') | (absent_days[\"long\"] == '[2] Mehrmals' )].index\n",
    "absent_days.drop(index=long_term, inplace = True)\n",
    "absent_days.drop(index=absent_days[absent_days['days_absent'] < 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbstst√§ndig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for turnover intention: split up into binary with roughly equal value counts for simplicity: might change that later to categories\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention ROBUSTNESS CHECK: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# work satisfaction mapping\n",
    "satisfaction_mapping = {\n",
    "    '[0] 0 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[1] 1 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[2] 2 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[3] 3 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[4] 4 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[5] 5 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[6] 6 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[7] 7 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[8] 8 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[9] 9 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[10] 10 Zufrieden: Skala 0-Niedrig bis 10-Hoc': 1,\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# sector_map\n",
    "sector_map = {\n",
    "    \"[1] Landwirtschaft und  Jagd\": 1,\n",
    "    \"[2] Forstwirtschaft\": 2,\n",
    "    \"[5] Fischerei und Fischzucht\": 5,\n",
    "    \"[10] Kohlenbergbau, Torfgewinnung\": 10,\n",
    "    \"[11] Gewinnung von Erd√∂l und Erdgas, Erbringung damit verbundener Dienstleistungen\": 11,\n",
    "    \"[12] Bergbau auf Uran- und Thoriumerze\": 12,\n",
    "    \"[13] Erzbergbau\": 13,\n",
    "    \"[14] Gewinnung von Steinen und Erden, sonstiger Bergbau\": 14,\n",
    "    \"[15] Herstellung von Nahrungs- und Futtermitteln sowie Getr√§nken\": 15,\n",
    "    \"[16] Tabakverarbeitung\": 16,\n",
    "    \"[17] Herstellung von Textilien\": 17,\n",
    "    \"[18] Herstellung von Bekleidung\": 18,\n",
    "    \"[19] Herstellung von Leder und Lederwaren\": 19,\n",
    "    \"[20] Herstellung von Holz sowie Holz-, Kork- und Flechtwaren (ohne Herstellung von M√∂beln)\": 20,\n",
    "    \"[21] Herstellung von Papier, Pappe und Waren daraus\": 21,\n",
    "    '[22] Herstellung von Verlags- und Druckerzeugnissen,  Vervielf√§ltigung von bespielten Ton-, Bild- und Datentr√§gern': 22,\n",
    "    \"[23] Kokerei, Mineral√∂lverarbeitung, Herstellung und Verarbeitung von Spalt- und Brutstoffen\": 23,\n",
    "    \"[24] Herstellung von chemischen Erzeugnissen\": 24,\n",
    "    \"[25] Herstellung von Gummi- und Kunststoffwaren\": 25,\n",
    "    \"[26] Herstellung von Glas und Glaswaren, Keramik, Verarbeitung von Steinen und Erden\": 26,\n",
    "    \"[27] Metallerzeugung und -bearbeitung\": 27,\n",
    "    \"[28] Herstellung von Metallerzeugnissen\": 28,\n",
    "    \"[29] Maschinenbau\": 29,\n",
    "    \"[31] Herstellung von Ger√§ten der Elektrizit√§tserzeugung, -verteilung u. √Ñ.\": 31,\n",
    "    \"[30] Herstellung von B√ºromaschinen, Datenverarbeitungsger√§ten und -einrichtungen\": 30,\n",
    "    \"[32] Rundfunk- und Nachrichtentechnik\": 32,\n",
    "    \"[33] Medizin-, Mess-, Steuer- und Regelungstechnik, Optik, Herstellung von Uhren\": 33,\n",
    "    \"[34] Herstellung von Kraftwagen und Kraftwagenteilen\": 34,\n",
    "    \"[35] Sonstiger Fahrzeugbau\": 35,\n",
    "    \"[36] Herstellung von M√∂beln, Schmuck, Musikinstrumenten, Sportger√§ten, Spielwaren und sonstigen Erzeugnissen\": 36,\n",
    "    \"[37] R√ºckgewinnung\": 37,\n",
    "    \"[40] Energieversorgung\": 40,\n",
    "    \"[41] Wasserversorgung\": 41,\n",
    "    \"[45] Bau\": 45,\n",
    "    \"[50] Kraftfahrzeughandel; Instandhaltung und Reparatur von Kraftfahrzeugen; Tankstellen\": 50,\n",
    "    \"[51] Handelsvermittlung und Gro√ühandel (ohne Handel mit Kraftfahrzeugen)\": 51,\n",
    "    \"[52] Einzelhandel (ohne Handel mit Kraftfahrzeugen und ohne Tankstellen); Reparatur von Gebrauchsg√ºtern\": 52,\n",
    "    \"[55] Beherbergungs- und Gastst√§tten\": 55,\n",
    "    \"[60] Landverkehr; Transport in Rohrfernleitungen\": 60,\n",
    "    \"[61] Schifffahrt\": 61,\n",
    "    \"[62] Luftfahrt\": 62,\n",
    "    \"[63] Hilfs- und Nebent√§tigkeiten f√ºr den Verkehr; Verkehrsvermittlung\": 63,\n",
    "    \"[64] Nachrichten√ºbermittlung\": 64,\n",
    "    \"[65] Kreditinstitute\": 65,\n",
    "    \"[66] Versicherungen (ohne Sozialversicherung)\": 66,\n",
    "    \"[67] Mit den Kreditinstituten und Versicherungen verbundene T√§tigkeiten\": 67,\n",
    "    \"[70] Grundst√ºcks- und Wohnungswesen\": 70,\n",
    "    \"[71] Vermietung beweglicher Sachen ohne Bedienungspersonal\": 71,\n",
    "    \"[72] Datenverarbeitung und Datenbanken\": 72,\n",
    "    \"[73] Forschung und Entwicklung\": 73,\n",
    "    \"[74] Erbringung von unternehmensbezogenen Dienstleistungen\": 74,\n",
    "    \"[75] √ñffentliche Verwaltung, Verteidigung, Sozialversicherung\": 75,\n",
    "    \"[80] Erziehung und Unterricht\": 80,\n",
    "    \"[85] Gesundheits-, Veterin√§r- und Sozialwesen\": 85,\n",
    "    \"[90] Abwasser- und Abfallbeseitigung und sonstige Entsorgung\": 90,\n",
    "    \"[91] Interessenvertretungen sowie kirchliche und sonstige Vereinigungen (ohne Sozialwesen, Kultur und Sport)\": 91,\n",
    "    \"[92] Kultur, Sport und Unterhaltung\": 92,\n",
    "    \"[93] Erbringung von sonstigen Dienstleistungen\": 93,\n",
    "    \"[95] Private Haushalte mit Hauspersonal\": 95,\t\t\t\t\t\n",
    "    \"[96] Industrie - ohne weitere Zuordnung\": 96,\t\t\t\t\t\n",
    "    \"[97] Handwerk - ohne weitere Zuordnung\": 97,\t\t\t\t\t\n",
    "    \"[98] Dienstleistungen ohne weitere Zuordnung\": 98,\t\t\t\t\t\n",
    "    \"[99] Exterritoriale Organisationen und K√∂rperschaften\": 99,\t\t\t\t\n",
    "    \"[100] Produzierendes Gewerbe ohne w.Zuordnung\": 100,\n",
    "    \"[-1] keine Angabe\": 3,\n",
    "    '[-2] trifft nicht zu': 0, \n",
    "    \"[-3] unplausibler Wert\": -3,\n",
    "    \"[-4] unzulaessige Mehrfachantwort\": -4, \n",
    "    \"[-5] in Fragebogenversion nicht enthalten\": -5,\n",
    "    \"[-6] Fragebogenversion mit geaenderter Filterfuehrung\": -6, \n",
    "    \"[-7] nur in weniger eingeschraenkter Edition verfuegbar\": -7,\n",
    "    \"[-8] Frage in diesem Jahr nicht Teil des Frageprogramms\": -8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "reversed_mapping_sector = {v: k for k, v in sector_map.items()}\n",
    "# mapping for binary reciprocity measure: ROBUSTNESS CHECK\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 3:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group\n",
    "\n",
    "def recode_categoricals(inputdf):\n",
    "    \"\"\"\n",
    "        recodes categoricals according to defined mappings\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode sector\n",
    "    merged['sector'] = merged['sector'].map(sector_map)\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode work-satisfaction\n",
    "    merged['work_satisfaction'] = merged['work_satisfaction'].map(satisfaction_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode turnover intention variable\n",
    "\n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output\n",
    "\n",
    "#def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),df_07,on=[\"pid\",\"hid\"]),work07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df).astype(float)\n",
    "    \n",
    "    \n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan)\n",
    "    recoded[\"wage_lastmonth\"] = np.log(recoded[\"wage_lastmonth\"])\n",
    "    recoded = recoded[recoded[\"wage_lastmonth\"] != -np.inf] \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    recoded[\"tenure_squared\"] = (recoded[\"tenure\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "    recoded[\"sector\"] = recoded[\"sector\"].map(reversed_mapping_sector)\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"new_job\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add Mincer Wage Regression and adds its residuals to the Dataframe\n",
    "\n",
    "def add_mincer_residuals(cleaneddata):\n",
    "    \n",
    "    df_cleaned = cleaneddata\n",
    "    # specify which columns to drop from our dataframe\n",
    "    df_mincer = cleaneddata.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup', 'age', 'commute_distance', 'recog_effort', 'working_hours','work_satisfaction','rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'sector'])\n",
    "    # Convert 'gender' and 'sector' columns to categorical data type\n",
    "    df_mincer['gender'] = df_mincer['gender'].astype('category')\n",
    "    df_mincer = df_mincer.dropna()\n",
    "    # Define the dependent variable\n",
    "    y = df_mincer['wage_lastmonth']\n",
    "    # Define the independent variables\n",
    "    X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "    # Add a constant term to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the Mincer wage regression model\n",
    "    mincer_model = sm.OLS(y, X).fit()\n",
    "    # Create a new column in the dataframe with the same name as the residuals array/ delete relative wage entries\n",
    "    df_cleaned['mincer_residuals'] = None\n",
    "    # Match the rows of the dataframe with the values in the residuals array using the index\n",
    "    df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2006 = add_mincer_residuals(merge_and_clean(df_05,df_06,df_06insteadof07,df_work06insteadof07))\n",
    "# drop n.a.ns.\n",
    "data_absenteism = pd.merge(data_2006, absent_days, on = [\"pid\",\"hid\"])\n",
    "data_absenteism.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>days_absent</td>   <th>  R-squared:         </th> <td>   0.046</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.043</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   479.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>6.54e-52</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:07:55</td>     <th>  Log-Likelihood:    </th> <td> -10953.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2990</td>      <th>  AIC:               </th> <td>2.193e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2979</td>      <th>  BIC:               </th> <td>2.199e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    1.6544</td> <td>    0.197</td> <td>    8.409</td> <td> 0.000</td> <td>    1.269</td> <td>    2.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    3.2904</td> <td>    1.087</td> <td>    3.026</td> <td> 0.002</td> <td>    1.159</td> <td>    5.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.2024</td> <td>    0.198</td> <td>    1.022</td> <td> 0.307</td> <td>   -0.186</td> <td>    0.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.6537</td> <td>    0.307</td> <td>   -2.131</td> <td> 0.033</td> <td>   -1.255</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>    0.0243</td> <td>    0.019</td> <td>    1.295</td> <td> 0.195</td> <td>   -0.012</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>    0.1678</td> <td>    0.078</td> <td>    2.150</td> <td> 0.032</td> <td>    0.015</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    1.5659</td> <td>    0.165</td> <td>    9.483</td> <td> 0.000</td> <td>    1.242</td> <td>    1.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -4.7960</td> <td>    0.579</td> <td>   -8.278</td> <td> 0.000</td> <td>   -5.931</td> <td>   -3.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>   -0.5867</td> <td>    0.053</td> <td>  -10.981</td> <td> 0.000</td> <td>   -0.691</td> <td>   -0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0051</td> <td>    0.003</td> <td>    1.817</td> <td> 0.069</td> <td>   -0.000</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0531</td> <td>    0.007</td> <td>    7.732</td> <td> 0.000</td> <td>    0.040</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -1.0740</td> <td>    0.426</td> <td>   -2.522</td> <td> 0.012</td> <td>   -1.909</td> <td>   -0.239</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2064.517</td> <th>  Durbin-Watson:     </th> <td>   1.928</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>40918.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.027</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>20.082</td>  <th>  Cond. No.          </th> <td>4.96e+17</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The smallest eigenvalue is 9.66e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            days_absent   R-squared:                       0.046\n",
       "Model:                            OLS   Adj. R-squared:                  0.043\n",
       "Method:                 Least Squares   F-statistic:                     479.4\n",
       "Date:                Mon, 16 Jan 2023   Prob (F-statistic):           6.54e-52\n",
       "Time:                        12:07:55   Log-Likelihood:                -10953.\n",
       "No. Observations:                2990   AIC:                         2.193e+04\n",
       "Df Residuals:                    2979   BIC:                         2.199e+04\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:              cluster                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                1.6544      0.197      8.409      0.000       1.269       2.040\n",
       "recog_effort             3.2904      1.087      3.026      0.002       1.159       5.422\n",
       "avg_rec                  0.2024      0.198      1.022      0.307      -0.186       0.591\n",
       "recXrecog_effort        -0.6537      0.307     -2.131      0.033      -1.255      -0.052\n",
       "working_hours            0.0243      0.019      1.295      0.195      -0.012       0.061\n",
       "firmsize                 0.1678      0.078      2.150      0.032       0.015       0.321\n",
       "age                      1.5659      0.165      9.483      0.000       1.242       1.890\n",
       "age_squared             -4.7960      0.579     -8.278      0.000      -5.931      -3.660\n",
       "years_educ              -0.5867      0.053    -10.981      0.000      -0.691      -0.482\n",
       "commute_distance         0.0051      0.003      1.817      0.069      -0.000       0.011\n",
       "potential_experience     0.0531      0.007      7.732      0.000       0.040       0.067\n",
       "mincer_residuals        -1.0740      0.426     -2.522      0.012      -1.909      -0.239\n",
       "==============================================================================\n",
       "Omnibus:                     2064.517   Durbin-Watson:                   1.928\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            40918.604\n",
       "Skew:                           3.027   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.082   Cond. No.                     4.96e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The smallest eigenvalue is 9.66e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_absenteism.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction', 'long' , 'tenure' , 'tenure_squared' ], inplace = True)\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month\n",
    "# add interaction term\n",
    "data_absenteism[\"recXrecog_effort\"] = data_absenteism[\"recog_effort\"] * data_absenteism[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "data_absenteism.dropna(inplace=True)\n",
    "formula_main = 'days_absent ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals'\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=data_absenteism).fit(cov_type='cluster', cov_kwds={'groups': data_absenteism['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "reg.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replication_ar2018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1c8bd4a427478b62670af9d3c11d8cb0bdaa7f04c3796cb12ca0eb11af97dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
