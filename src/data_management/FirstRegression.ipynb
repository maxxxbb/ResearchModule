{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Regression (Turnover intention ~ unfair treatment x neg. reciprocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Read in SOEP Data:\n",
    "- vp : 2005 data : main variables of interest: questions on negative reciprocity\n",
    "- wp: 2006 data : main variables of interest: question on perceived recognition for work\n",
    "- xp: 2007 data : main variables of interest: turnover intentions, controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path: insert the path where the SOEP data is stored on your computer here\n",
    "from pathlib import Path\n",
    "## copy your path in here:\n",
    "# Path Max: \n",
    "# Path Maxie: /Volumes/dohmen_soep/SOEP-CORE.v36eu_STATA/Stata/raw\n",
    "\n",
    "data_folder = Path(\"C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/SOEP-Data/Stata/raw\")\n",
    "# define relevant subsets of SOEP-data\n",
    "file_names = ['vp', 'wp', 'xp']\n",
    "\n",
    "file_paths = [data_folder / f\"{file_name}.dta\" for file_name in file_names]\n",
    "# some controls are in gen data\n",
    "file_paths_2 = [data_folder / f\"{file_name}gen.dta\" for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2005 data for the reciprocity measures\n",
    "data05 = pd.read_stata(file_paths[0], columns=[\"pid\",\"hid\", \"syear\",\"vp12602\", \"vp12603\", \"vp12605\"]).set_index(['pid', 'hid'])\n",
    "df_2005 = data05.rename(columns={ 'vp12602': 'take_revenge', 'vp12603': 'similar_problems', 'vp12605': 'insult_back'})\n",
    "# create dummies for take_revenge question\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(df_2005['similar_problems'])\n",
    "\n",
    "# Join the dummy variables to the original dataframe\n",
    "df_2005 = pd.concat([df_2005, dummies], axis=1)\n",
    "# rename dummy\n",
    "df_05 = df_2005.rename(columns = {'[1] Trifft ueberhaupt nicht zu' : 'rec1' , '[2] Skala 1-7' : 'rec2' , '[3] Skala 1-7' : 'rec3' ,'[4] Skala 1-7' : 'rec4' ,'[5] Skala 1-7' : 'rec5' ,'[6] Skala 1-7' : 'rec6' ,'[7] Trifft voll zu' : 'rec7'})\n",
    "df_05 = df_05.drop(columns = [\"[-1] keine Angabe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [2] Skala 1-7\n",
       "Name: insult_back, dtype: category\n",
       "Categories (8, object): ['[-1] keine Angabe' < '[1] Trifft ueberhaupt nicht zu' < '[2] Skala 1-7' < '[3] Skala 1-7' < '[4] Skala 1-7' < '[5] Skala 1-7' < '[6] Skala 1-7' < '[7] Trifft voll zu']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_05[\"insult_back\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2006 data\n",
    "# personal = personal advancement\n",
    "# still includes all unfair treat\n",
    "data06 = pd.read_stata(file_paths[1], columns=[\"pid\", \"hid\", \"syear\", 'wp43b01', 'wp43b02', 'wp43b03', 'wp43b04', 'wp43b05', 'wp43b06', 'wp43b07','wp43b08', 'wp43a11']).set_index(['pid', 'hid'])\n",
    "df_06 = data06.rename(columns={ 'wp43b01': 'recog_sup', 'wp43b02': 'felt_recog_sup',\"wp43b03\": \"recog_effort\",  'wp43b04': 'felt_recog_effort', \"wp43b05\": \"recog_personal\", \"wp43b06\" :\"felt_recog_personal\" ,\"wp43b07\": \"recog_pay\",'wp43b08': 'felt_recog_pay' , 'wp43a11': 'jobatrisk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2007 data\n",
    "# here left out 'xp8601' for school degree since we have it in another module also 'xp0102' : 'work_satisfaction' for the beginning\n",
    "#for outcome and all controls\n",
    "data3= pd.read_stata(file_paths[2], columns=[\"pid\", \"hid\", \"syear\", 'xp13101' , 'xp13102', 'xp2701', 'xp7302','xp7202','xp28', 'xp3001' ,  'xp5701' , 'xp0102' , 'xp2702']).set_index(['pid', 'hid'])\n",
    "df_07 = data3.rename(columns= {'xp13101':'gender','xp13102': 'year_birth' ,'xp2701': 'turnover_intention' , 'xp7302': 'wage_lastmonth','xp7202': 'overtime','xp28': 'new_job', 'xp3001': 'reason_new_job',  'xp5701' : 'commute_distance' , \"xp0102\" : \"work_satisfaction\" , 'xp2702' : \"fear_losingjob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2007 data from work module\n",
    "\n",
    "# adapt path and merge\n",
    "hours07 = pd.read_stata(file_paths_2[2], columns=[\"pid\",\"hid\", \"syear\", \"xvebzeit\", \"xpsbil\",\"nace07\" ,\"betr07\", \"xerwzeit\", \"xbilzeit\"]).set_index(['pid', 'hid'])\n",
    "work07 = hours07.rename(columns={'xvebzeit': 'working_hours', \"xpsbil\": \"school_degree\", \"nace07\": \"sector\",\"betr07\": \"firmsize\", \"xerwzeit\": \"tenure\" , \"xbilzeit\" : \"years_educ\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Define Functions and mappings for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for reciprocity questions: same scale for all\n",
    "reciprocity_questions_mapping = {\n",
    "    '[1] Trifft ueberhaupt nicht zu': 1,\n",
    "    '[2] Skala 1-7': 2,\n",
    "    '[3] Skala 1-7': 3,\n",
    "    '[4] Skala 1-7': 4,\n",
    "    '[5] Skala 1-7': 5,\n",
    "    '[6] Skala 1-7': 6,\n",
    "    '[7] Trifft voll zu': 7,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "## mapping for recognition questions: binary -> binary -> unfair treatment: No -> later 1 fair treatment: Yes -> 0\n",
    "recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Ja': 2,\n",
    "    '[2] Nein': 1,\n",
    "}\n",
    "# felt recog mapping\n",
    "felt_recog_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Gar nicht': 1,\n",
    "    '[2] Maessig': 2,\n",
    "    '[3] Stark': 3,\n",
    "    '[4] Sehr stark': 4,\n",
    "}\n",
    "# mapping for firmsize -> we need to recode this in a sensible way: jumps are the same: first change: selbstst√§ndig to 0\n",
    "firmsize_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "    '[1] Unter  5': 1,\n",
    "    '[2] 5 bis 10': 2,\n",
    "    '[3] 11 bis unter 20': 3,\n",
    "    '[4] bis 90: unter 20': 4,\n",
    "    '[5] 91-04: 5 bis unter 20': 5,\n",
    "    '[6] 20 bis unter 100': 6,\n",
    "    '[7] 100 bis unter 200': 7,\n",
    "    '[8] bis 98: 20 bis unter 200': 8,\n",
    "    '[9] 200 bis unter 2000': 9,\n",
    "    '[10] 2000 und mehr': 10,\n",
    "    '[11] Selbstaendig-ohne Mitarb.': 0,\n",
    "}\n",
    "# mapping new job into binary variable\n",
    "new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1, \n",
    "    '[1] Ja': 1, \n",
    "    '[2] Nein': 2,\n",
    "    '[3] Ja, nach Datenpruefung': 1,\n",
    "}\n",
    "# mapping for job satisfaction: split up into binary with roughly equal value counts for simplicity: might change that later to categories,\n",
    "satisfaction_mapping = {\n",
    "    '[0] 0 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[1] 1 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[2] 2 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[3] 3 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[4] 4 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[5] 5 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 2,\n",
    "    '[6] 6 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[7] 7 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[8] 8 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[9] 9 Zufrieden: Skala 0-Niedrig bis 10-Hoch': 1,\n",
    "    '[10] 10 Zufrieden: Skala 0-Niedrig bis 10-Hoc': 1,\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe': -1,\n",
    "}\n",
    "turnover_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 2,\n",
    "    '[10] 10% wahrscheinlich': 1,\n",
    "    '[20] 20% wahrscheinlich': 1,\n",
    "    '[30] 30% wahrscheinlich': 1,\n",
    "    '[40] 40% wahrscheinlich': 1, \n",
    "    '[50] 50% wahrscheinlich': 1,\n",
    "    '[60] 60% wahrscheinlich': 1,\n",
    "    '[70] 70% wahrscheinlich': 1,\n",
    "    '[80] 80% wahrscheinlich': 1,\n",
    "    '[90] 90% wahrscheinlich': 1,\n",
    "    '[100] 100% wahrscheinlich': 1,\n",
    "}\n",
    "# mapping for turnover intention robustness check: Cardinal\n",
    "turnover_mapping_cardinal = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[0] 0% wahrscheinlich': 0,\n",
    "    '[10] 10% wahrscheinlich': 10,\n",
    "    '[20] 20% wahrscheinlich': 20,\n",
    "    '[30] 30% wahrscheinlich': 30,\n",
    "    '[40] 40% wahrscheinlich': 40, \n",
    "    '[50] 50% wahrscheinlich': 50,\n",
    "    '[60] 60% wahrscheinlich': 60,\n",
    "    '[70] 70% wahrscheinlich': 70,\n",
    "    '[80] 80% wahrscheinlich': 80,\n",
    "    '[90] 90% wahrscheinlich': 90,\n",
    "    '[100] 100% wahrscheinlich': 100,\n",
    "}\n",
    "# mapping for new job to easier remove negatives\n",
    "reason_new_job_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1, \n",
    "    '[1] Erstmals erwerbstaetig': 1,\n",
    "    '[2] Wieder erwerbstaetig': 2,\n",
    "    '[3] Stelle bei neuen Arbeitgeber': 3,  \n",
    "    '[4] Uerbnommen von Betrieb': 4,\n",
    "    '[5] Stellenwechsel im Betrieb': 5, \n",
    "    '[6] Selbstaendig geworden': 6,\n",
    "}\n",
    "# mapping for school degree: to easier remove negatives\n",
    "school_degree_mapping = {\n",
    "    '[-2] trifft nicht zu': -2,\n",
    "    '[-1] keine Angabe':-1,\n",
    "    '[1] Hauptschulabschluss': 1,\n",
    "    '[2] Realschulabschluss': 2,\n",
    "    '[3] Fachhochschulreife': 3,\n",
    "    '[4] Abitur': 4,\n",
    "    '[5] Anderer Abschluss': 5,\n",
    "    '[6] Ohne Abschluss verlassen': 6,\n",
    "    '[7] Noch kein Abschluss': 7,\n",
    "    '[8] Keine Schule besucht': 8,\n",
    "}\n",
    "# sector_map\n",
    "sector_map = {\n",
    "    \"[1] Landwirtschaft und  Jagd\": 1,\n",
    "    \"[2] Forstwirtschaft\": 2,\n",
    "    \"[5] Fischerei und Fischzucht\": 5,\n",
    "    \"[10] Kohlenbergbau, Torfgewinnung\": 10,\n",
    "    \"[11] Gewinnung von Erd√∂l und Erdgas, Erbringung damit verbundener Dienstleistungen\": 11,\n",
    "    \"[12] Bergbau auf Uran- und Thoriumerze\": 12,\n",
    "    \"[13] Erzbergbau\": 13,\n",
    "    \"[14] Gewinnung von Steinen und Erden, sonstiger Bergbau\": 14,\n",
    "    \"[15] Herstellung von Nahrungs- und Futtermitteln sowie Getr√§nken\": 15,\n",
    "    \"[16] Tabakverarbeitung\": 16,\n",
    "    \"[17] Herstellung von Textilien\": 17,\n",
    "    \"[18] Herstellung von Bekleidung\": 18,\n",
    "    \"[19] Herstellung von Leder und Lederwaren\": 19,\n",
    "    \"[20] Herstellung von Holz sowie Holz-, Kork- und Flechtwaren (ohne Herstellung von M√∂beln)\": 20,\n",
    "    \"[21] Herstellung von Papier, Pappe und Waren daraus\": 21,\n",
    "    '[22] Herstellung von Verlags- und Druckerzeugnissen,  Vervielf√§ltigung von bespielten Ton-, Bild- und Datentr√§gern': 22,\n",
    "    \"[23] Kokerei, Mineral√∂lverarbeitung, Herstellung und Verarbeitung von Spalt- und Brutstoffen\": 23,\n",
    "    \"[24] Herstellung von chemischen Erzeugnissen\": 24,\n",
    "    \"[25] Herstellung von Gummi- und Kunststoffwaren\": 25,\n",
    "    \"[26] Herstellung von Glas und Glaswaren, Keramik, Verarbeitung von Steinen und Erden\": 26,\n",
    "    \"[27] Metallerzeugung und -bearbeitung\": 27,\n",
    "    \"[28] Herstellung von Metallerzeugnissen\": 28,\n",
    "    \"[29] Maschinenbau\": 29,\n",
    "    \"[31] Herstellung von Ger√§ten der Elektrizit√§tserzeugung, -verteilung u. √Ñ.\": 31,\n",
    "    \"[30] Herstellung von B√ºromaschinen, Datenverarbeitungsger√§ten und -einrichtungen\": 30,\n",
    "    \"[32] Rundfunk- und Nachrichtentechnik\": 32,\n",
    "    \"[33] Medizin-, Mess-, Steuer- und Regelungstechnik, Optik, Herstellung von Uhren\": 33,\n",
    "    \"[34] Herstellung von Kraftwagen und Kraftwagenteilen\": 34,\n",
    "    \"[35] Sonstiger Fahrzeugbau\": 35,\n",
    "    \"[36] Herstellung von M√∂beln, Schmuck, Musikinstrumenten, Sportger√§ten, Spielwaren und sonstigen Erzeugnissen\": 36,\n",
    "    \"[37] R√ºckgewinnung\": 37,\n",
    "    \"[40] Energieversorgung\": 40,\n",
    "    \"[41] Wasserversorgung\": 41,\n",
    "    \"[45] Bau\": 45,\n",
    "    \"[50] Kraftfahrzeughandel; Instandhaltung und Reparatur von Kraftfahrzeugen; Tankstellen\": 50,\n",
    "    \"[51] Handelsvermittlung und Gro√ühandel (ohne Handel mit Kraftfahrzeugen)\": 51,\n",
    "    \"[52] Einzelhandel (ohne Handel mit Kraftfahrzeugen und ohne Tankstellen); Reparatur von Gebrauchsg√ºtern\": 52,\n",
    "    \"[55] Beherbergungs- und Gastst√§tten\": 55,\n",
    "    \"[60] Landverkehr; Transport in Rohrfernleitungen\": 60,\n",
    "    \"[61] Schifffahrt\": 61,\n",
    "    \"[62] Luftfahrt\": 62,\n",
    "    \"[63] Hilfs- und Nebent√§tigkeiten f√ºr den Verkehr; Verkehrsvermittlung\": 63,\n",
    "    \"[64] Nachrichten√ºbermittlung\": 64,\n",
    "    \"[65] Kreditinstitute\": 65,\n",
    "    \"[66] Versicherungen (ohne Sozialversicherung)\": 66,\n",
    "    \"[67] Mit den Kreditinstituten und Versicherungen verbundene T√§tigkeiten\": 67,\n",
    "    \"[70] Grundst√ºcks- und Wohnungswesen\": 70,\n",
    "    \"[71] Vermietung beweglicher Sachen ohne Bedienungspersonal\": 71,\n",
    "    \"[72] Datenverarbeitung und Datenbanken\": 72,\n",
    "    \"[73] Forschung und Entwicklung\": 73,\n",
    "    \"[74] Erbringung von unternehmensbezogenen Dienstleistungen\": 74,\n",
    "    \"[75] √ñffentliche Verwaltung, Verteidigung, Sozialversicherung\": 75,\n",
    "    \"[80] Erziehung und Unterricht\": 80,\n",
    "    \"[85] Gesundheits-, Veterin√§r- und Sozialwesen\": 85,\n",
    "    \"[90] Abwasser- und Abfallbeseitigung und sonstige Entsorgung\": 90,\n",
    "    \"[91] Interessenvertretungen sowie kirchliche und sonstige Vereinigungen (ohne Sozialwesen, Kultur und Sport)\": 91,\n",
    "    \"[92] Kultur, Sport und Unterhaltung\": 92,\n",
    "    \"[93] Erbringung von sonstigen Dienstleistungen\": 93,\n",
    "    \"[95] Private Haushalte mit Hauspersonal\": 95,\t\t\t\t\t\n",
    "    \"[96] Industrie - ohne weitere Zuordnung\": 96,\t\t\t\t\t\n",
    "    \"[97] Handwerk - ohne weitere Zuordnung\": 97,\t\t\t\t\t\n",
    "    \"[98] Dienstleistungen ohne weitere Zuordnung\": 98,\t\t\t\t\t\n",
    "    \"[99] Exterritoriale Organisationen und K√∂rperschaften\": 99,\t\t\t\t\n",
    "    \"[100] Produzierendes Gewerbe ohne w.Zuordnung\": 100,\n",
    "    \"[-1] keine Angabe\": 3,\n",
    "    '[-2] trifft nicht zu': 0, \n",
    "    \"[-3] unplausibler Wert\": -3,\n",
    "    \"[-4] unzulaessige Mehrfachantwort\": -4, \n",
    "    \"[-5] in Fragebogenversion nicht enthalten\": -5,\n",
    "    \"[-6] Fragebogenversion mit geaenderter Filterfuehrung\": -6, \n",
    "    \"[-7] nur in weniger eingeschraenkter Edition verfuegbar\": -7,\n",
    "    \"[-8] Frage in diesem Jahr nicht Teil des Frageprogramms\": -8,\n",
    "}\n",
    "# reversed mapping to redo changes\n",
    "reversed_mapping_reason = {v: k for k, v in reason_new_job_mapping.items()}\n",
    "reversed_mapping_schoold = {v: k for k, v in school_degree_mapping.items()}\n",
    "reversed_mapping_sector = {v: k for k, v in sector_map.items()}\n",
    "# mapping for binary reciprocity measure\n",
    "def binary_reciprocity(x):\n",
    "    if x >= 3:\n",
    "        return 1 # High Group\n",
    "    else:\n",
    "        return 0 # Low Group\n",
    "\n",
    "## function for recoding values and dropping missing\n",
    "\n",
    "def recode_categoricals(inputdf,rc_cardinal = 0):\n",
    "    \"\"\"\n",
    "        merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "        Input:\n",
    "            - inputdf : merged dataframe\n",
    "            - rc_cardinal: optional argument: if == 1 turnover intentions will be coded as cardinal instead of binary \n",
    "            - rc_rec_binary: optional argument: if == 1 neg. reciprocity will be split into 2 groups: high and low\n",
    "        Output:\n",
    "            - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    merged = inputdf  \n",
    "    \n",
    "    # recode Gender variable\n",
    "    merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
    "    merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
    "    # recode reciprocity variables\n",
    "    merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]] = merged[[\"similar_problems\",\"take_revenge\",\"insult_back\"]].apply(lambda x: x.map(reciprocity_questions_mapping))\n",
    "    # recode recognition variables\n",
    "    merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\",\"jobatrisk\"]] = merged[[\"recog_sup\",\"recog_effort\",\"recog_personal\",\"recog_pay\",\"jobatrisk\"]].apply(lambda x: x.map(recog_mapping))\n",
    "    # recode felt recognition variables\n",
    "    merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]] = merged[[\"felt_recog_sup\",\"felt_recog_effort\",\"felt_recog_personal\",\"felt_recog_pay\"]].apply(lambda x: x.map(felt_recog_mapping))\n",
    "    # recode firm size\n",
    "    merged['firmsize'] = merged['firmsize'].map(firmsize_mapping)\n",
    "    # recode new job reason variable\n",
    "    merged['reason_new_job'] = merged['reason_new_job'].map(reason_new_job_mapping)\n",
    "    # recode job change variable\n",
    "    merged['new_job']= merged['new_job'].map(new_job_mapping)\n",
    "    # recode sector\n",
    "    merged['sector'] = merged['sector'].map(sector_map)\n",
    "    # recode job satisfaction\n",
    "    merged['work_satisfaction']= merged['work_satisfaction'].map(satisfaction_mapping)\n",
    "    # recode turnover intention variable\n",
    "    merged['fear_losingjob'] = merged['fear_losingjob'].map(turnover_mapping_cardinal)\n",
    "    if rc_cardinal == 1:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping_cardinal)\n",
    "    else:\n",
    "        merged['turnover_intention'] = merged['turnover_intention'].map(turnover_mapping)\n",
    "    \n",
    "    # recode school degree\n",
    "    merged['school_degree'] = merged['school_degree'].map(school_degree_mapping)\n",
    "    \n",
    "    output = merged\n",
    "    return output\n",
    "\n",
    "# Merge dataframes: a bit tough to read as its nested, merges 4 dataframes: 2005,2006,2007 and 2007gen\n",
    "\n",
    "def merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal = 0,rc_rec_binary=0):\n",
    "    \"\"\"\n",
    "    merges data from different years, applies recoding to categoricals and constructs additional variables.\n",
    "\n",
    "    Input:\n",
    "        - df_05 : Pd.Dataframe contains reciprocity measures\n",
    "        - df_06 : Pd.Dataframe contains unfair treatment measures\n",
    "        - df_07 : Pd.Dataframe contains outcome and controls\n",
    "        - work07 : Pd.Dataframe contains additional controls\n",
    "\n",
    "    Output:\n",
    "        - df : cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
    "    recoded = recode_categoricals(allmerged_df,rc_cardinal).astype('int')\n",
    "    # replaces negative values with n.a.n \n",
    "    recoded = recoded.mask(recoded < 0, np.nan)\n",
    "    # recode sector back intro category\n",
    "    \n",
    "    recoded[\"wage_lastmonth\"] = np.log(recoded[\"wage_lastmonth\"])\n",
    "    recoded = recoded[recoded[\"wage_lastmonth\"] != -np.inf] \n",
    "    # construct avg reciprocity measure\n",
    "    recoded['avg_rec'] = recoded[['take_revenge', 'similar_problems', 'insult_back']].mean(axis=1)\n",
    "    # For robustness check: option to construct binary reciprocity measure.\n",
    "    if rc_rec_binary == 1:\n",
    "        recoded['binary_rec'] = recoded['avg_rec'].apply(binary_reciprocity)\n",
    "    \n",
    "    # construct age, potential experience and age^2\n",
    "    recoded['age'] = 2007 - recoded['year_birth']\n",
    "    recoded[\"potential_experience\"] = pow((recoded[\"age\"] - 18), 2)\n",
    "    recoded[\"age_squared\"] = (recoded[\"age\"] ** 2) / 100\n",
    "    recoded[\"tenure_squared\"] = (recoded[\"tenure\"] ** 2) / 100\n",
    "    # recode categoricals back to make it better readable\n",
    "    recoded[\"reason_new_job\"] = recoded[\"reason_new_job\"].map(reversed_mapping_reason)\n",
    "    recoded[\"school_degree\"] = recoded[\"school_degree\"].map(reversed_mapping_schoold)\n",
    "    recoded[\"sector\"] = recoded[\"sector\"].map(reversed_mapping_sector)\n",
    "    # transform binary variables with 1 and 2 into 1 and 0\n",
    "    columns_to_transform = [\"recog_sup\",\"recog_effort\", \"recog_pay\", \"recog_personal\" ,\"gender\", \"turnover_intention\", \"new_job\" , \"jobatrisk\"]\n",
    "\n",
    "    # Iterate over the columns and replace the values 2 with 0 \n",
    "    for col in columns_to_transform:\n",
    "        recoded[col] = recoded[col].replace({2: 0})\n",
    "\n",
    "    # save df somewhere so its not muted when repeatedly executing this cell: Can later transform that into functions\n",
    "    df = recoded\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add Mincer Wage Regression and adds its residuals to the Dataframe\n",
    "\n",
    "def add_mincer_residuals(cleaneddata):\n",
    "    \n",
    "    df_cleaned = cleaneddata\n",
    "    # specify which columns to drop from our dataframe\n",
    "    df_mincer = cleaneddata.drop(columns=['syear_x', 'similar_problems', 'take_revenge', 'insult_back','syear_y', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'syear_y', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup', 'age', 'commute_distance', 'recog_effort', 'working_hours', 'turnover_intention', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction' , 'sector' , 'tenure_squared' , 'fear_losingjob' , 'jobatrisk'])\n",
    "    # Convert 'gender' and 'sector' columns to categorical data type\n",
    "    for col in ['gender']:\n",
    "        df_mincer[col] = df_mincer[col].astype('category')\n",
    "    df_mincer = df_mincer.dropna()\n",
    "    # Define the dependent variable\n",
    "    y = df_mincer['wage_lastmonth']\n",
    "    # Define the independent variables\n",
    "    X = df_mincer[['gender', 'firmsize', 'tenure', 'years_educ', 'potential_experience', 'age_squared']]\n",
    "\n",
    "    # Add a constant term to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the Mincer wage regression model\n",
    "    mincer_model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Create a new column in the dataframe with the same name as the residuals array/ delete relative wage entries\n",
    "    df_cleaned['mincer_residuals'] = None\n",
    "    # Match the rows of the dataframe with the values in the residuals array using the index\n",
    "    df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlcude People who switched their jobs in 2006-2007 with 2006 controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_jobchangers(data07,onlynewemployer=True,worksatisfaction=False,rc_cardinal = False):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "            df: finished 2007 dataframe\n",
    "            onlynewemployer: optional argument: If True only includes those who switched jobs to a new employer\n",
    "            worksatisfaction: if True drops observations where job satisfaction between 2006 and 2007 changed to check for our Assumption\n",
    "    \n",
    "    \"\"\"\n",
    "    df = data07\n",
    "    # read in cleaned 2006 dataset:\n",
    "    #  change path here : Maxie: '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv'\n",
    "    #                     Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv'  \n",
    "    observations_2006 = pd.read_csv('C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv')\n",
    "    # some initial datamanagement\n",
    "    observations_2006.reset_index(inplace=True)\n",
    "    observations_2006.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "    observations_2006.drop(columns=observations_2006.filter(regex='^syear').columns, inplace=True)\n",
    "    observations_2006.drop(\"index\",axis=1 ,inplace =True)\n",
    "    # If cardinal turnover intentions are coded to 100\n",
    "    if rc_cardinal == True:\n",
    "        observations_2006[\"turnover_intention\"] = 100\n",
    "    \n",
    "    # drop s year columns from both dataframes\n",
    "    df.drop(columns=df.filter(regex='^syear').columns, inplace=True)\n",
    "    \n",
    "    # optional worksatisfaction robustness check\n",
    "    if worksatisfaction == True:\n",
    "        satisfaction = pd.DataFrame(df['work_satisfaction']).join(pd.DataFrame(observations_2006['work_satisfaction']), on = [\"pid\", \"hid\"], lsuffix = \"_07\" , rsuffix =\"_06\")\n",
    "        # list of IDs where job satisfaction changed over the past year\n",
    "        ID_keep_satis = satisfaction[satisfaction[\"work_satisfaction_07\"] == satisfaction[\"work_satisfaction_06\"]].index\n",
    "        # drops all persons from 2007 dataframe where job satisfaction changed\n",
    "        df.drop(df[~df.index.isin(ID_keep_satis)].index, inplace=True)\n",
    "    \n",
    "    # create list of IDs of people who switched to a new employer in the last year in 2007\n",
    "    if onlynewemployer == True:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1) & (df[\"reason_new_job\"] == '[3] Stelle bei neuen Arbeitgeber')].index\n",
    "    # if True drops people whose work satisfaction changed between 2006 and 2007\n",
    "    else:\n",
    "        IDs_tokeep = df[(df[\"new_job\"] == 1)].index\n",
    "    \n",
    "    # drop all who changed their job in 2007 dataframe and replace 2007 controls with 2006 controls\n",
    "    df.drop(df[df[\"new_job\"] == 1].index, inplace = True)\n",
    "    observations_2006.drop(observations_2006[~observations_2006.index.isin(IDs_tokeep)].index, inplace=True)\n",
    "    #concat both dataframes\n",
    "    dfconcat = pd.concat([df,observations_2006])\n",
    "    \n",
    "    return dfconcat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis\n",
    "#### OLS\n",
    "\n",
    "- Probit Estimation: TurnoverIntention_{2005} = Constant + Neg-Rec + Unfair + Rec X Unfair + Controls + Error\n",
    "\n",
    "- As the measure for unfair treatment in the first regression i first used recog_effort -> decide for one later\n",
    "    - \"When I consider all my accomplishments and efforts, the recognition of I've received seems about right to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:226: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:227: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
      "c:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:226: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:227: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
      "c:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   606.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 16 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>1.37e-56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:03:15</td>      <th>  Log-Likelihood:    </th> <td> -3309.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5373</td>       <th>  AIC:               </th> <td>   6648.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5359</td>       <th>  BIC:               </th> <td>   6740.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>cluster</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0459</td> <td>    0.008</td> <td>    5.437</td> <td> 0.000</td> <td>    0.029</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1498</td> <td>    0.030</td> <td>    4.989</td> <td> 0.000</td> <td>    0.091</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0255</td> <td>    0.006</td> <td>    4.206</td> <td> 0.000</td> <td>    0.014</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0179</td> <td>    0.010</td> <td>   -1.819</td> <td> 0.069</td> <td>   -0.037</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>    0.0019</td> <td>    0.001</td> <td>    1.680</td> <td> 0.093</td> <td>   -0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0114</td> <td>    0.004</td> <td>   -2.962</td> <td> 0.003</td> <td>   -0.019</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0159</td> <td>    0.002</td> <td>   -8.000</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0199</td> <td>    0.004</td> <td>    4.475</td> <td> 0.000</td> <td>    0.011</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0514</td> <td>    0.007</td> <td>    7.296</td> <td> 0.000</td> <td>    0.038</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1302</td> <td>    0.025</td> <td>   -5.221</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0208</td> <td>    0.007</td> <td>    2.951</td> <td> 0.003</td> <td>    0.007</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.439</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0010</td> <td>    0.000</td> <td>    3.311</td> <td> 0.001</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0708</td> <td>    0.020</td> <td>   -3.508</td> <td> 0.000</td> <td>   -0.110</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jobatrisk</th>            <td>   -0.1453</td> <td>    0.019</td> <td>   -7.595</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16862.186</td> <th>  Durbin-Watson:     </th> <td>   1.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 377.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.035</td>   <th>  Prob(JB):          </th> <td>9.78e-83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.703</td>   <th>  Cond. No.          </th> <td>6.65e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The smallest eigenvalue is 1.1e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.197\n",
       "Model:                            OLS   Adj. R-squared:                  0.195\n",
       "Method:                 Least Squares   F-statistic:                     606.6\n",
       "Date:                Mon, 16 Jan 2023   Prob (F-statistic):           1.37e-56\n",
       "Time:                        16:03:15   Log-Likelihood:                -3309.9\n",
       "No. Observations:                5373   AIC:                             6648.\n",
       "Df Residuals:                    5359   BIC:                             6740.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:              cluster                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0459      0.008      5.437      0.000       0.029       0.062\n",
       "recog_effort             0.1498      0.030      4.989      0.000       0.091       0.209\n",
       "avg_rec                  0.0255      0.006      4.206      0.000       0.014       0.037\n",
       "recXrecog_effort        -0.0179      0.010     -1.819      0.069      -0.037       0.001\n",
       "working_hours            0.0019      0.001      1.680      0.093      -0.000       0.004\n",
       "firmsize                -0.0114      0.004     -2.962      0.003      -0.019      -0.004\n",
       "tenure                  -0.0159      0.002     -8.000      0.000      -0.020      -0.012\n",
       "tenure_squared           0.0199      0.004      4.475      0.000       0.011       0.029\n",
       "age                      0.0514      0.007      7.296      0.000       0.038       0.065\n",
       "age_squared             -0.1302      0.025     -5.221      0.000      -0.179      -0.081\n",
       "years_educ               0.0208      0.007      2.951      0.003       0.007       0.035\n",
       "commute_distance         0.0004      0.000      3.439      0.001       0.000       0.001\n",
       "potential_experience     0.0010      0.000      3.311      0.001       0.000       0.002\n",
       "mincer_residuals        -0.0708      0.020     -3.508      0.000      -0.110      -0.031\n",
       "jobatrisk               -0.1453      0.019     -7.595      0.000      -0.183      -0.108\n",
       "==============================================================================\n",
       "Omnibus:                    16862.186   Durbin-Watson:                   1.841\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              377.668\n",
       "Skew:                          -0.035   Prob(JB):                     9.78e-83\n",
       "Kurtosis:                       1.703   Cond. No.                     6.65e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The smallest eigenvalue is 1.1e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# add interaction term\n",
    "df_OLS[\"recXrecog_effort\"] = df_OLS[\"recog_effort\"] * df_OLS[\"avg_rec\"]\n",
    "\n",
    "## Drop n.a.n.s\n",
    "df_OLS.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'], inplace=True)\n",
    "df_OLS.dropna(inplace=True)\n",
    "# drop missing data in regression dataframe\n",
    "\n",
    "\n",
    "# Specify model\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=df_OLS).fit(cov_type='cluster', cov_kwds={'groups': df_OLS['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg.summary()\n",
    "#print(summary.as_latex())\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Checks\n",
    "\n",
    "\n",
    "#### 1. Recode turnover variable into cardinal variable: Optional argument in recode_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/Users/maxieschulze/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:335: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    }
   ],
   "source": [
    "# optional argument ==1\n",
    "df_card = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07,rc_cardinal=1)),rc_cardinal=True)\n",
    "## drop n.a.ns\n",
    "df_card.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth','rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'work_satisfaction'], inplace = True)\n",
    "# add interaction term\n",
    "df_card[\"recXrecog_effort\"] = df_card[\"recog_effort\"] * df_card[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_card.dropna(inplace=True)\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Specify model\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg_cardinal = smf.ols(formula_main, data=df_card).fit(cov_type='cluster', cov_kwds={'groups': df_card['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg_cardinal.summary()\n",
    "#print(summary.as_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating dummies and include 7 interaction terms : Decide for one of the 3 questions for simplicity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When treating the categories as numerical: we are making assumptions about the differences between the scale items. If those distances can be considered equal at all levels, then it is reasonable to treat reciprocity as numerical. (i.e a one unit change from 1 to 2 is equivalent to a one unit change from 6 to 7)\n",
    "\n",
    "\n",
    "For dummy coding we need to exclude one of the categories in the dataframe and make it the reference category: This will be the lowest level of reciprocity 1 and will be coded as zero.  so rec2 rec3 rec4 , ... and their interaction terms with unfair treatment stay in the regression.\n",
    "\n",
    "rec2 is then interpreted as the mean of turnover intentions in the rec2 group - the mean of turnover intentions in the rec1 group (reference group) holding everything else constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:226: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:227: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
      "c:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   456.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 16 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>1.28e-56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:45:11</td>      <th>  Log-Likelihood:    </th> <td> -3268.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5373</td>       <th>  AIC:               </th> <td>   6585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5349</td>       <th>  BIC:               </th> <td>   6743.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    23</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>cluster</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0452</td> <td>    0.008</td> <td>    5.813</td> <td> 0.000</td> <td>    0.030</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1286</td> <td>    0.024</td> <td>    5.438</td> <td> 0.000</td> <td>    0.082</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2</th>                 <td>    0.1559</td> <td>    0.016</td> <td>    9.532</td> <td> 0.000</td> <td>    0.124</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3</th>                 <td>    0.1561</td> <td>    0.021</td> <td>    7.500</td> <td> 0.000</td> <td>    0.115</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4</th>                 <td>    0.1246</td> <td>    0.028</td> <td>    4.512</td> <td> 0.000</td> <td>    0.070</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5</th>                 <td>    0.1698</td> <td>    0.027</td> <td>    6.295</td> <td> 0.000</td> <td>    0.117</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6</th>                 <td>    0.2029</td> <td>    0.044</td> <td>    4.564</td> <td> 0.000</td> <td>    0.116</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7</th>                 <td>    0.0475</td> <td>    0.050</td> <td>    0.950</td> <td> 0.342</td> <td>   -0.050</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec2_X_recog_effort</th>  <td>   -0.0412</td> <td>    0.038</td> <td>   -1.095</td> <td> 0.274</td> <td>   -0.115</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec3_X_recog_effort</th>  <td>   -0.0041</td> <td>    0.038</td> <td>   -0.110</td> <td> 0.912</td> <td>   -0.078</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec4_X_recog_effort</th>  <td>   -0.0765</td> <td>    0.045</td> <td>   -1.714</td> <td> 0.087</td> <td>   -0.164</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec5_X_recog_effort</th>  <td>   -0.0862</td> <td>    0.045</td> <td>   -1.921</td> <td> 0.055</td> <td>   -0.174</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec6_X_recog_effort</th>  <td>   -0.0893</td> <td>    0.076</td> <td>   -1.178</td> <td> 0.239</td> <td>   -0.238</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rec7_X_recog_effort</th>  <td>   -0.0301</td> <td>    0.079</td> <td>   -0.381</td> <td> 0.703</td> <td>   -0.185</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>    0.0017</td> <td>    0.001</td> <td>    1.492</td> <td> 0.136</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0118</td> <td>    0.004</td> <td>   -3.115</td> <td> 0.002</td> <td>   -0.019</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0159</td> <td>    0.002</td> <td>   -8.055</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0195</td> <td>    0.004</td> <td>    4.538</td> <td> 0.000</td> <td>    0.011</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0509</td> <td>    0.006</td> <td>    8.049</td> <td> 0.000</td> <td>    0.038</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1283</td> <td>    0.023</td> <td>   -5.563</td> <td> 0.000</td> <td>   -0.173</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0189</td> <td>    0.007</td> <td>    2.771</td> <td> 0.006</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.862</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0009</td> <td>    0.000</td> <td>    3.473</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0714</td> <td>    0.020</td> <td>   -3.579</td> <td> 0.000</td> <td>   -0.111</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jobatrisk</th>            <td>   -0.1492</td> <td>    0.018</td> <td>   -8.264</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>9294.741</td> <th>  Durbin-Watson:     </th> <td>   1.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 359.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.045</td>  <th>  Prob(JB):          </th> <td>1.03e-78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.737</td>  <th>  Cond. No.          </th> <td>2.37e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The smallest eigenvalue is 8.65e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.209\n",
       "Model:                            OLS   Adj. R-squared:                  0.206\n",
       "Method:                 Least Squares   F-statistic:                     456.9\n",
       "Date:                Mon, 16 Jan 2023   Prob (F-statistic):           1.28e-56\n",
       "Time:                        16:45:11   Log-Likelihood:                -3268.5\n",
       "No. Observations:                5373   AIC:                             6585.\n",
       "Df Residuals:                    5349   BIC:                             6743.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:              cluster                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0452      0.008      5.813      0.000       0.030       0.061\n",
       "recog_effort             0.1286      0.024      5.438      0.000       0.082       0.175\n",
       "rec2                     0.1559      0.016      9.532      0.000       0.124       0.188\n",
       "rec3                     0.1561      0.021      7.500      0.000       0.115       0.197\n",
       "rec4                     0.1246      0.028      4.512      0.000       0.070       0.179\n",
       "rec5                     0.1698      0.027      6.295      0.000       0.117       0.223\n",
       "rec6                     0.2029      0.044      4.564      0.000       0.116       0.290\n",
       "rec7                     0.0475      0.050      0.950      0.342      -0.050       0.145\n",
       "rec2_X_recog_effort     -0.0412      0.038     -1.095      0.274      -0.115       0.033\n",
       "rec3_X_recog_effort     -0.0041      0.038     -0.110      0.912      -0.078       0.069\n",
       "rec4_X_recog_effort     -0.0765      0.045     -1.714      0.087      -0.164       0.011\n",
       "rec5_X_recog_effort     -0.0862      0.045     -1.921      0.055      -0.174       0.002\n",
       "rec6_X_recog_effort     -0.0893      0.076     -1.178      0.239      -0.238       0.059\n",
       "rec7_X_recog_effort     -0.0301      0.079     -0.381      0.703      -0.185       0.124\n",
       "working_hours            0.0017      0.001      1.492      0.136      -0.001       0.004\n",
       "firmsize                -0.0118      0.004     -3.115      0.002      -0.019      -0.004\n",
       "tenure                  -0.0159      0.002     -8.055      0.000      -0.020      -0.012\n",
       "tenure_squared           0.0195      0.004      4.538      0.000       0.011       0.028\n",
       "age                      0.0509      0.006      8.049      0.000       0.038       0.063\n",
       "age_squared             -0.1283      0.023     -5.563      0.000      -0.173      -0.083\n",
       "years_educ               0.0189      0.007      2.771      0.006       0.006       0.032\n",
       "commute_distance         0.0004      0.000      3.862      0.000       0.000       0.001\n",
       "potential_experience     0.0009      0.000      3.473      0.001       0.000       0.001\n",
       "mincer_residuals        -0.0714      0.020     -3.579      0.000      -0.111      -0.032\n",
       "jobatrisk               -0.1492      0.018     -8.264      0.000      -0.185      -0.114\n",
       "==============================================================================\n",
       "Omnibus:                     9294.741   Durbin-Watson:                   1.843\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              359.141\n",
       "Skew:                          -0.045   Prob(JB):                     1.03e-78\n",
       "Kurtosis:                       1.737   Cond. No.                     2.37e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The smallest eigenvalue is 8.65e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. optional argument:  rc_binary ==1\n",
    "dfrc_dummy = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "dfrc_dummy.drop(columns=['similar_problems', 'take_revenge', 'insult_back','felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay','year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'avg_rec','rec1', 'work_satisfaction'], inplace = True)\n",
    "# add interaction terms\n",
    "for col in ['rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7']:\n",
    "    dfrc_dummy = dfrc_dummy.assign(**{col + '_X_recog_effort': dfrc_dummy[col] * dfrc_dummy['recog_effort']})\n",
    "# drop missing data in regression dataframe\n",
    "dfrc_dummy = dfrc_dummy.dropna()\n",
    "\n",
    "\n",
    "# Specify model\n",
    "formula_main = 'turnover_intention ~ recog_effort + rec2 + rec3 + rec4 + rec5 + rec6 + rec7 + rec2_X_recog_effort + rec3_X_recog_effort + rec4_X_recog_effort + rec5_X_recog_effort + rec6_X_recog_effort + rec7_X_recog_effort+ working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=dfrc_dummy).fit(cov_type='cluster', cov_kwds={'groups': dfrc_dummy['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg.summary()\n",
    "#print(summary.as_latex())\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness Check : Drop people whose job satisfaction level changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/Users/maxieschulze/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:335: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    }
   ],
   "source": [
    "dfworksatisfation = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)),worksatisfaction = True)\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "\n",
    "df_rc_ws = dfworksatisfation.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' ,'work_satisfaction'])\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month \"\"\"\n",
    "# add interaction term\n",
    "df_rc_ws[\"recXrecog_effort\"] = df_rc_ws[\"recog_effort\"] * df_rc_ws[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_rc_ws.dropna(inplace=True)\n",
    "\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=df_rc_ws).fit(cov_type='cluster', cov_kwds={'groups': df_rc_ws['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg.summary()\n",
    "#print(summary.as_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Check \n",
    "\n",
    "Avg reciprocity measure over years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "/Users/maxieschulze/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/7l/hw861dtx52z8nxgtzjvpp8_h0000gn/T/ipykernel_99188/1153709134.py:335: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[df_cleaned.index, 'mincer_residuals'] = mincer_model.resid\n"
     ]
    }
   ],
   "source": [
    "df_OLS_avg = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# specify columns which we need for regression by dropping everything else\n",
    "df_OLS_avg.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction','avg_rec'], inplace = True)\n",
    "# Load avg reciprocity measures over the years\n",
    "\n",
    "\n",
    "# Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/rec_avgyears.csv'\n",
    "# Maxie '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/rec_avgyears.csv'\n",
    "avg_reciprocity = pd.read_csv('/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/rec_avgyears.csv')\n",
    "avg_reciprocity.reset_index(inplace=True)\n",
    "avg_reciprocity.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "avg_reciprocity.drop(\"index\",axis=1 ,inplace =True)\n",
    "\n",
    "df_avg_years = pd.merge(df_OLS_avg,avg_reciprocity, on=[\"pid\",\"hid\"])\n",
    "\n",
    "# add interaction term\n",
    "df_avg_years[\"recXrecog_effort\"] = df_avg_years[\"recog_effort\"] * df_avg_years[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_avg_years.dropna(inplace=True)\n",
    "\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=df_avg_years).fit(cov_type='cluster', cov_kwds={'groups': df_avg_years['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg.summary()\n",
    "#print(summary.as_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also does not change much"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Realized Turnover in 2007 -> turnover intentions = 1 else 0 with 2006 controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizedturnover(df_07):\n",
    "    # gets people who realized turnover in 2006-2007\n",
    "    jobchangers = df_07[df_07[\"new_job\"] == '[1] Ja'].index\n",
    "\n",
    "    observations_2006 = pd.read_csv('C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv')\n",
    "    # Max 'C:/Users/max-admin/Desktop/Masterstudium/WiSe_22_23/Research_Module/finalproj/src/data_management/2006jobchange.csv'\n",
    "    # Maxie '/Users/maxieschulze/Documents/Dokumente - MacBook Pro von Maxie/5. Semester/Research Module/ResearchModule/src/data_management/2006jobchange.csv'\n",
    "    # some initial datamanagement\n",
    "    observations_2006.reset_index(inplace=True)\n",
    "    observations_2006.set_index([\"pid\",\"hid\"], inplace=True)\n",
    "    observations_2006.drop(columns=observations_2006.filter(regex='^syear').columns, inplace=True)\n",
    "    observations_2006.drop(\"index\",axis=1 ,inplace =True)\n",
    "    # define people who changed their jobs\n",
    "    jobstayers = observations_2006[~observations_2006.index.isin(jobchangers)]\n",
    "    jobstayers[\"turnover_intention\"] = 0\n",
    "    # drop all to concatenate both: not elegant all which did not change job\n",
    "    observations_2006.drop(observations_2006[~observations_2006.index.isin(jobchangers)].index, inplace=True)\n",
    "\n",
    "    subset_2006 = pd.concat([jobstayers,observations_2006])\n",
    "\n",
    "    return subset_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\3458904763.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jobstayers[\"turnover_intention\"] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   143.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 16 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>4.70e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>18:15:15</td>      <th>  Log-Likelihood:    </th> <td> -227.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  6568</td>       <th>  AIC:               </th> <td>   482.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  6554</td>       <th>  BIC:               </th> <td>   577.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>cluster</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0198</td> <td>    0.005</td> <td>    3.866</td> <td> 0.000</td> <td>    0.010</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.0074</td> <td>    0.016</td> <td>    0.457</td> <td> 0.648</td> <td>   -0.025</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0009</td> <td>    0.003</td> <td>    0.310</td> <td> 0.756</td> <td>   -0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0015</td> <td>    0.004</td> <td>   -0.352</td> <td> 0.725</td> <td>   -0.010</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>   -0.0004</td> <td>    0.000</td> <td>   -1.021</td> <td> 0.307</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0029</td> <td>    0.001</td> <td>   -2.007</td> <td> 0.045</td> <td>   -0.006</td> <td>-6.83e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0145</td> <td>    0.002</td> <td>   -9.327</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0344</td> <td>    0.004</td> <td>    9.080</td> <td> 0.000</td> <td>    0.027</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0197</td> <td>    0.004</td> <td>    5.124</td> <td> 0.000</td> <td>    0.012</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.0569</td> <td>    0.015</td> <td>   -3.748</td> <td> 0.000</td> <td>   -0.087</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0055</td> <td>    0.001</td> <td>    5.403</td> <td> 0.000</td> <td>    0.004</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0002</td> <td> 9.72e-05</td> <td>    1.830</td> <td> 0.067</td> <td>-1.26e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0005</td> <td>    0.000</td> <td>    3.007</td> <td> 0.003</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0154</td> <td>    0.008</td> <td>   -1.924</td> <td> 0.054</td> <td>   -0.031</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jobatrisk</th>            <td>   -0.0451</td> <td>    0.009</td> <td>   -5.183</td> <td> 0.000</td> <td>   -0.062</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3836.183</td> <th>  Durbin-Watson:     </th> <td>   0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>24393.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.900</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.449</td>  <th>  Cond. No.          </th> <td>1.11e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The smallest eigenvalue is 4.69e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.076\n",
       "Model:                            OLS   Adj. R-squared:                  0.074\n",
       "Method:                 Least Squares   F-statistic:                     143.4\n",
       "Date:                Mon, 16 Jan 2023   Prob (F-statistic):           4.70e-39\n",
       "Time:                        18:15:15   Log-Likelihood:                -227.11\n",
       "No. Observations:                6568   AIC:                             482.2\n",
       "Df Residuals:                    6554   BIC:                             577.3\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:              cluster                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0198      0.005      3.866      0.000       0.010       0.030\n",
       "recog_effort             0.0074      0.016      0.457      0.648      -0.025       0.039\n",
       "avg_rec                  0.0009      0.003      0.310      0.756      -0.005       0.006\n",
       "recXrecog_effort        -0.0015      0.004     -0.352      0.725      -0.010       0.007\n",
       "working_hours           -0.0004      0.000     -1.021      0.307      -0.001       0.000\n",
       "firmsize                -0.0029      0.001     -2.007      0.045      -0.006   -6.83e-05\n",
       "tenure                  -0.0145      0.002     -9.327      0.000      -0.018      -0.011\n",
       "tenure_squared           0.0344      0.004      9.080      0.000       0.027       0.042\n",
       "age                      0.0197      0.004      5.124      0.000       0.012       0.027\n",
       "age_squared             -0.0569      0.015     -3.748      0.000      -0.087      -0.027\n",
       "years_educ               0.0055      0.001      5.403      0.000       0.004       0.008\n",
       "commute_distance         0.0002   9.72e-05      1.830      0.067   -1.26e-05       0.000\n",
       "potential_experience     0.0005      0.000      3.007      0.003       0.000       0.001\n",
       "mincer_residuals        -0.0154      0.008     -1.924      0.054      -0.031       0.000\n",
       "jobatrisk               -0.0451      0.009     -5.183      0.000      -0.062      -0.028\n",
       "==============================================================================\n",
       "Omnibus:                     3836.183   Durbin-Watson:                   0.144\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            24393.568\n",
       "Skew:                           2.900   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.449   Cond. No.                     1.11e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The smallest eigenvalue is 4.69e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real = realizedturnover(df_07)\n",
    "df_real.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'], inplace = True)\n",
    "#  included 'recog_effort'again , excluded overtime due to sample size and wage last month \"\"\"\n",
    "# add interaction term\n",
    "df_real[\"recXrecog_effort\"] = df_real[\"recog_effort\"] * df_real[\"avg_rec\"]\n",
    "# drop missing data in regression dataframe\n",
    "df_real.dropna(inplace=True)\n",
    "\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=df_real).fit(cov_type='cluster', cov_kwds={'groups': df_real['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "reg.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other measure for unfair treatment : take additional information into account how much they are bothered by it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:273: FutureWarning: Passing 'suffixes' which cause duplicate columns {'syear_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  allmerged_df = pd.merge(pd.merge(pd.merge(df_05,df_06,on=[\"pid\", \"hid\"]),work07,on=[\"pid\",\"hid\"]),df_07,on=[\"pid\", \"hid\"])\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:226: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[2] Weiblich', 2,inplace=True)\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\1153709134.py:227: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged['gender'].replace('[1] Maennlich', 1,inplace=True)\n",
      "c:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\max-admin\\AppData\\Local\\Temp\\ipykernel_4476\\57617764.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_OLS['recog_effort'][~df_OLS.index.isin(idstostayat1)] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>turnover_intention</td> <th>  R-squared:         </th> <td>   0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   604.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 16 Jan 2023</td>  <th>  Prob (F-statistic):</th> <td>1.50e-56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>14:37:54</td>      <th>  Log-Likelihood:    </th> <td> -3324.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  5402</td>       <th>  AIC:               </th> <td>   6677.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  5388</td>       <th>  BIC:               </th> <td>   6769.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>cluster</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0461</td> <td>    0.008</td> <td>    5.491</td> <td> 0.000</td> <td>    0.030</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recog_effort</th>         <td>    0.1715</td> <td>    0.030</td> <td>    5.704</td> <td> 0.000</td> <td>    0.113</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rec</th>              <td>    0.0246</td> <td>    0.005</td> <td>    4.618</td> <td> 0.000</td> <td>    0.014</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recXrecog_effort</th>     <td>   -0.0201</td> <td>    0.010</td> <td>   -2.029</td> <td> 0.042</td> <td>   -0.039</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>working_hours</th>        <td>    0.0019</td> <td>    0.001</td> <td>    1.664</td> <td> 0.096</td> <td>   -0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>firmsize</th>             <td>   -0.0114</td> <td>    0.004</td> <td>   -2.940</td> <td> 0.003</td> <td>   -0.019</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>               <td>   -0.0160</td> <td>    0.002</td> <td>   -8.562</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure_squared</th>       <td>    0.0204</td> <td>    0.004</td> <td>    5.073</td> <td> 0.000</td> <td>    0.012</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                  <td>    0.0517</td> <td>    0.007</td> <td>    7.398</td> <td> 0.000</td> <td>    0.038</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_squared</th>          <td>   -0.1308</td> <td>    0.025</td> <td>   -5.270</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_educ</th>           <td>    0.0204</td> <td>    0.007</td> <td>    2.830</td> <td> 0.005</td> <td>    0.006</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>commute_distance</th>     <td>    0.0004</td> <td>    0.000</td> <td>    3.453</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_experience</th> <td>    0.0010</td> <td>    0.000</td> <td>    3.332</td> <td> 0.001</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mincer_residuals</th>     <td>   -0.0719</td> <td>    0.020</td> <td>   -3.575</td> <td> 0.000</td> <td>   -0.111</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jobatrisk</th>            <td>   -0.1432</td> <td>    0.019</td> <td>   -7.546</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15251.177</td> <th>  Durbin-Watson:     </th> <td>   1.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 376.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.031</td>   <th>  Prob(JB):          </th> <td>1.67e-82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.708</td>   <th>  Cond. No.          </th> <td>1.21e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The smallest eigenvalue is 3.32e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     turnover_intention   R-squared:                       0.198\n",
       "Model:                            OLS   Adj. R-squared:                  0.196\n",
       "Method:                 Least Squares   F-statistic:                     604.5\n",
       "Date:                Mon, 16 Jan 2023   Prob (F-statistic):           1.50e-56\n",
       "Time:                        14:37:54   Log-Likelihood:                -3324.4\n",
       "No. Observations:                5402   AIC:                             6677.\n",
       "Df Residuals:                    5388   BIC:                             6769.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:              cluster                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0461      0.008      5.491      0.000       0.030       0.063\n",
       "recog_effort             0.1715      0.030      5.704      0.000       0.113       0.230\n",
       "avg_rec                  0.0246      0.005      4.618      0.000       0.014       0.035\n",
       "recXrecog_effort        -0.0201      0.010     -2.029      0.042      -0.039      -0.001\n",
       "working_hours            0.0019      0.001      1.664      0.096      -0.000       0.004\n",
       "firmsize                -0.0114      0.004     -2.940      0.003      -0.019      -0.004\n",
       "tenure                  -0.0160      0.002     -8.562      0.000      -0.020      -0.012\n",
       "tenure_squared           0.0204      0.004      5.073      0.000       0.012       0.028\n",
       "age                      0.0517      0.007      7.398      0.000       0.038       0.065\n",
       "age_squared             -0.1308      0.025     -5.270      0.000      -0.179      -0.082\n",
       "years_educ               0.0204      0.007      2.830      0.005       0.006       0.035\n",
       "commute_distance         0.0004      0.000      3.453      0.001       0.000       0.001\n",
       "potential_experience     0.0010      0.000      3.332      0.001       0.000       0.002\n",
       "mincer_residuals        -0.0719      0.020     -3.575      0.000      -0.111      -0.032\n",
       "jobatrisk               -0.1432      0.019     -7.546      0.000      -0.180      -0.106\n",
       "==============================================================================\n",
       "Omnibus:                    15251.177   Durbin-Watson:                   1.850\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              376.600\n",
       "Skew:                          -0.031   Prob(JB):                     1.67e-82\n",
       "Kurtosis:                       1.708   Cond. No.                     1.21e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "[2] The smallest eigenvalue is 3.32e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS = include_jobchangers(add_mincer_residuals(merge_and_clean(df_05,df_06,df_07,work07)))\n",
    "# add interaction term\n",
    "idstostayat1 = df_OLS[(df_OLS[\"felt_recog_effort\"] == 3.0) | (df_OLS[\"felt_recog_effort\"] == 4.0) | (df_OLS[\"felt_recog_effort\"] == 2.0)].index\n",
    "df_OLS['recog_effort'][~df_OLS.index.isin(idstostayat1)] = 0\n",
    "df_OLS[\"recXrecog_effort\"] = df_OLS[\"recog_effort\"] * df_OLS[\"avg_rec\"]\n",
    "## Drop n.a.n.s\n",
    "df_OLS.drop(columns=['similar_problems', 'take_revenge', 'insult_back', 'felt_recog_sup', 'felt_recog_effort',\n",
    "       'recog_personal', 'felt_recog_personal', 'recog_pay', 'felt_recog_pay', 'year_birth', 'new_job',\n",
    "       'reason_new_job', 'school_degree','overtime', 'recog_sup','wage_lastmonth', 'rec1' , 'rec2' , 'rec3' , 'rec4', 'rec5' , 'rec6' , 'rec7' , 'work_satisfaction'], inplace=True)\n",
    "df_OLS.dropna(inplace=True)\n",
    "## change all which are unbothered to unfair treatment 0\n",
    "\n",
    " \n",
    "## add interaction term and reestimate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specify model\n",
    "formula_main = 'turnover_intention ~ recog_effort + avg_rec + recXrecog_effort + working_hours + firmsize + tenure + tenure_squared + age + age_squared + years_educ + commute_distance + potential_experience + mincer_residuals + jobatrisk'\n",
    "\n",
    "# Fit the regression and cluster on the sector variable\n",
    "reg = smf.ols(formula_main, data=df_OLS).fit(cov_type='cluster', cov_kwds={'groups': df_OLS['sector']})\n",
    "\n",
    "# Print the regression results\n",
    "summary = reg.summary()\n",
    "#print(summary.as_latex())\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replication_ar2018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1c8bd4a427478b62670af9d3c11d8cb0bdaa7f04c3796cb12ca0eb11af97dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
